{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koukyo1994/kaggle-bengali-ai/blob/master/notebook/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-LYW6ekKQ-x",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyICnC_QKQ-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n",
        "pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n",
        "pip install pretrainedmodels==0.7.4 >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2m_PlwpKQ-5",
        "colab_type": "text"
      },
      "source": [
        "## Integration with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsPLSeVuKQ-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7cdf267e-8f98-4b53-a809-7d5ab69db1ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FN8jiWKQ--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "mkdir input\n",
        "cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Iv5BnEKQ_B",
        "colab_type": "text"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYrCK0t6KQ_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as A\n",
        "import catalyst as ct\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pretrainedmodels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as torchdata\n",
        "import torchvision.models as models\n",
        "import yaml\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Union, Optional, List\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
        "from catalyst.dl.callbacks import MixupCallback\n",
        "from easydict import EasyDict as edict\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from skimage.transform import AffineTransform, warp\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n",
        "                                      CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tszhN7oGKQ_H",
        "colab_type": "text"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqfUxJd6KQ_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "trial = \"resnet18_init\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXUZcRAGKQ_L",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S16TliO4KQ_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_string = '''\n",
        "dataset:\n",
        "  train:\n",
        "    affine: True\n",
        "    morphology: False\n",
        "  val:\n",
        "    affine: False\n",
        "    morphology: False\n",
        "  test:\n",
        "    affine: False\n",
        "    morphology: False\n",
        "\n",
        "data:\n",
        "  train_df_path: input/bengaliai-cv19/train.csv\n",
        "  train_images_path: input/bengaliai-cv19/train_images\n",
        "  test_images_path: input/bengaliai-cv19/test_images\n",
        "  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n",
        "\n",
        "model:\n",
        "  model_name: resnet18\n",
        "  pretrained: True\n",
        "  num_classes: 186\n",
        "  head: custom\n",
        "  in_channels: 3\n",
        "\n",
        "train:\n",
        "  batch_size: 128\n",
        "  num_epochs: 30\n",
        "\n",
        "test:\n",
        "  batch_size: 128\n",
        "\n",
        "loss:\n",
        "  name: cross_entropy\n",
        "  params:\n",
        "    n_grapheme: 168\n",
        "    n_vowel: 11\n",
        "    n_consonant: 7\n",
        "\n",
        "optimizer:\n",
        "  name: Adam\n",
        "  params:\n",
        "    lr: 0.001\n",
        "\n",
        "scheduler:\n",
        "  name: cosine\n",
        "  params:\n",
        "    T_max: 10\n",
        "\n",
        "transforms:\n",
        "  Noise: False\n",
        "  Contrast: False\n",
        "  Rotate: True\n",
        "  RandomScale: True\n",
        "  Cutout:\n",
        "    num_holes: 0\n",
        "\n",
        "val:\n",
        "  name: kfold\n",
        "  params:\n",
        "    random_state: 42\n",
        "    n_splits: 5\n",
        "\n",
        "log_dir: log/\n",
        "num_workers: 2\n",
        "seed: 1213\n",
        "img_size: 128\n",
        "checkpoints:\n",
        "mixup: False\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piePmxjjKQ_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_default():\n",
        "    cfg = edict()\n",
        "\n",
        "    # dataset\n",
        "    cfg.dataset = edict()\n",
        "    cfg.dataset.train = edict()\n",
        "    cfg.dataset.val = edict()\n",
        "    cfg.dataset.test = edict()\n",
        "    cfg.dataset.train.affine = False\n",
        "    cfg.dataset.train.morphology = False\n",
        "    cfg.dataset.val.affine = False\n",
        "    cfg.dataset.val.morphology = False\n",
        "    cfg.dataset.test.affine = False\n",
        "    cfg.dataset.test.morphology = False\n",
        "\n",
        "    # dataset\n",
        "    cfg.data = edict()\n",
        "\n",
        "    # model\n",
        "    cfg.model = edict()\n",
        "    cfg.model.model_name = \"resnet18\"\n",
        "    cfg.model.num_classes = 186\n",
        "    cfg.model.pretrained = True\n",
        "    cfg.model.head = \"linear\"\n",
        "    cfg.model.in_channels = 3\n",
        "\n",
        "    # train\n",
        "    cfg.train = edict()\n",
        "\n",
        "    # test\n",
        "    cfg.test = edict()\n",
        "\n",
        "    # loss\n",
        "    cfg.loss = edict()\n",
        "    cfg.loss.params = edict()\n",
        "\n",
        "    # optimizer\n",
        "    cfg.optimizer = edict()\n",
        "    cfg.optimizer.params = edict()\n",
        "\n",
        "    # scheduler\n",
        "    cfg.scheduler = edict()\n",
        "    cfg.scheduler.params = edict()\n",
        "\n",
        "    # transforms:\n",
        "    cfg.transforms = edict()\n",
        "    cfg.transforms.HorizontalFlip = False\n",
        "    cfg.transforms.VerticalFlip = False\n",
        "    cfg.transforms.Noise = False\n",
        "    cfg.transforms.Contrast = False\n",
        "    cfg.transforms.Rotate = False\n",
        "    cfg.transforms.RandomScale = False\n",
        "    cfg.transforms.Cutout = edict()\n",
        "    cfg.transforms.Cutout.num_holes = 0\n",
        "    cfg.transforms.mean = [0.485, 0.456, 0.406]\n",
        "    cfg.transforms.std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # val\n",
        "    cfg.val = edict()\n",
        "    cfg.val.params = edict()\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def _merge_config(src: edict, dst: edict):\n",
        "    if not isinstance(src, edict):\n",
        "        return\n",
        "    for k, v in src.items():\n",
        "        if isinstance(v, edict):\n",
        "            _merge_config(src[k], dst[k])\n",
        "        else:\n",
        "            dst[k] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOq2Hol4KQ_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n",
        "config = _get_default()\n",
        "_merge_config(cfg, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iinSUuVEKQ_V",
        "colab_type": "text"
      },
      "source": [
        "## Environmental settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5V5VT5KQ_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "ab7fc1ea-a2cd-4f1f-bcad-7d333ff26cf3"
      },
      "source": [
        "ct.utils.set_global_seed(config.seed)\n",
        "ct.utils.prepare_cudnn(deterministic=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHv73-KuKQ_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_base_dir = Path(\"output\")\n",
        "output_base_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_images_path = Path(config.data.train_images_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nowCCU9GKQ_b",
        "colab_type": "text"
      },
      "source": [
        "## Data and utilities preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAy9mKC1KQ_c",
        "colab_type": "text"
      },
      "source": [
        "### validation utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wcJQJEKQ_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def no_fold(df: pd.DataFrame,\n",
        "            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    idx = np.arange(len(df))\n",
        "    trn_idx, val_idx = train_test_split(idx, **params)\n",
        "    return [(trn_idx, val_idx)]\n",
        "\n",
        "\n",
        "def kfold(df: pd.DataFrame,\n",
        "          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    kf = KFold(shuffle=True, **params)\n",
        "    splits = list(kf.split(df))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def get_validation(df: pd.DataFrame,\n",
        "                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    name: str = config.val.name\n",
        "\n",
        "    func = globals().get(name)\n",
        "    if func is None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return func(df, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE5iD2HAKQ_f",
        "colab_type": "text"
      },
      "source": [
        "### transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvCvJ5ScKQ_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_transforms(config: edict):\n",
        "    list_transforms = []\n",
        "    if config.transforms.HorizontalFlip:\n",
        "        list_transforms.append(A.HorizontalFrip())\n",
        "    if config.transforms.VerticalFlip:\n",
        "        list_transforms.append(A.VerticalFlip())\n",
        "    if config.transforms.Rotate:\n",
        "        list_transforms.append(A.Rotate(limit=15))\n",
        "    if config.transforms.RandomScale:\n",
        "        list_transforms.append(A.RandomScale())\n",
        "    if config.transforms.Noise:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n",
        "    if config.transforms.Contrast:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.RandomContrast(0.5),\n",
        "                 A.RandomGamma(),\n",
        "                 A.RandomBrightness()],\n",
        "                p=0.5))\n",
        "    if config.transforms.Cutout.num_holes > 0:\n",
        "        list_transforms.append(A.Cutout(**config.Cutout))\n",
        "\n",
        "    list_transforms.append(\n",
        "        A.Normalize(\n",
        "            mean=config.transforms.mean, std=config.transforms.std, p=1))\n",
        "\n",
        "    return A.Compose(list_transforms, p=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mQCOAtuLtV3",
        "colab_type": "text"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdTnGd0aLu-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(config.data.train_df_path)\n",
        "splits = get_validation(df, config)\n",
        "transforms = get_transforms(config)\n",
        "\n",
        "cls_levels = {\n",
        "    \"grapheme\": df.grapheme_root.nunique(),\n",
        "    \"vowel\": df.vowel_diacritic.nunique(),\n",
        "    \"consonant\": df.consonant_diacritic.nunique()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3X2245OKQ_j",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj6MHrqXKQ_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseDataset(torchdata.Dataset):\n",
        "    def __init__(self, image_dir: Path, df: pd.DataFrame, transforms,\n",
        "                 size: Tuple[int, int]):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.size = size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df.loc[idx, \"image_id\"]\n",
        "        image_path = self.image_dir / f\"{image_id}.png\"\n",
        "\n",
        "        image = cv2.imread(str(image_path))\n",
        "        # image = crop_resize(image[:, :, 0], self.size)\n",
        "        # image = np.moveaxis(np.stack([image, image, image]), 0, -1)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)[\"image\"]\n",
        "        image = cv2.resize(image, self.size)\n",
        "        if image.shape[2] == 3:\n",
        "            image = np.moveaxis(image, -1, 0)\n",
        "        grapheme = self.df.loc[idx, \"grapheme_root\"]\n",
        "        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n",
        "        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n",
        "        label = np.zeros(3, dtype=int)\n",
        "        label[0] = grapheme\n",
        "        label[1] = vowel\n",
        "        label[2] = consonant\n",
        "        return {\"images\": image, \"targets\": label}\n",
        "    \n",
        "    \n",
        "def get_base_loader(df: pd.DataFrame,\n",
        "                    image_dir: Path,\n",
        "                    phase: str = \"train\",\n",
        "                    size: Tuple[int, int] = (128, 128),\n",
        "                    batch_size=256,\n",
        "                    num_workers=2,\n",
        "                    transforms=None):\n",
        "    assert phase in [\"train\", \"valid\"]\n",
        "    if phase == \"train\":\n",
        "        is_shuffle = True\n",
        "        drop_last = True\n",
        "    else:\n",
        "        is_shuffle = False\n",
        "        drop_last = False\n",
        "\n",
        "    dataset = BaseDataset(  # type: ignore\n",
        "        image_dir, df, transforms, size)\n",
        "    return torchdata.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=drop_last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc6F3Pu5KQ_m",
        "colab_type": "text"
      },
      "source": [
        "## Model and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjBhyu98KQ_n",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wABhZZ9LKQ_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
        "    return F.avg_pool2d(x.clamp(min=eps).pow(p),\n",
        "                        (x.size(-2), x.size(-1))).pow(1. / p)\n",
        "\n",
        "\n",
        "def mish(input):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    See additional documentation for mish class.\n",
        "    '''\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "    Examples:\n",
        "        >>> m = Mish()\n",
        "        >>> input = torch.randn(2)\n",
        "        >>> output = m(input)\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Init method.\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Forward pass of the function.\n",
        "        '''\n",
        "        return mish(input)\n",
        "\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return gem(x, p=self.p, eps=self.eps).squeeze(-1).squeeze(-1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(\n",
        "            self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_name: str,\n",
        "                 num_classes: int,\n",
        "                 pretrained=False,\n",
        "                 head=\"linear\",\n",
        "                 in_channels=3):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.base = getattr(models, model_name)(pretrained=pretrained)\n",
        "        self.head = head\n",
        "        assert in_channels in [1, 3]\n",
        "        assert head in [\"linear\", \"custom\"]\n",
        "        if in_channels == 1:\n",
        "            if pretrained:\n",
        "                weight = self.base.conv1.weight\n",
        "                self.base.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "                self.base.conv1.weight = nn.Parameter(\n",
        "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
        "                    requires_grad=True)\n",
        "            else:\n",
        "                self.base.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        if head == \"linear\":\n",
        "            n_in_features = self.base.fc.in_features\n",
        "            self.base.fc = nn.Linear(n_in_features, self.num_classes)\n",
        "        elif head == \"custom\":\n",
        "            n_in_features = self.base.fc.in_features\n",
        "            arch = list(self.base.children())\n",
        "            for _ in range(2):\n",
        "                arch.pop()\n",
        "            self.base = nn.Sequential(*arch)\n",
        "            self.grapheme_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 168))\n",
        "            self.vowel_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 11))\n",
        "            self.consonant_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 7))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.head == \"linear\":\n",
        "            return self.base(x)\n",
        "        elif self.head == \"custom\":\n",
        "            x = self.base(x)\n",
        "            grapheme = self.grapheme_head(x)\n",
        "            vowel = self.vowel_head(x)\n",
        "            consonant = self.consonant_head(x)\n",
        "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "def get_model(config: edict):\n",
        "    params = config.model\n",
        "    if \"resnet\" in params.model_name:\n",
        "        return Resnet(**params)\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IPNqFE5KQ_q",
        "colab_type": "text"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXKZUtQdKQ_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengaliCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, 0]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, 1]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, 2]\n",
        "\n",
        "        return self.cross_entropy(grapheme_pred, grapheme_true) + \\\n",
        "            self.cross_entropy(vowel_pred, vowel_true) + \\\n",
        "            self.cross_entropy(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "class BengaliBCELoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, head:tail]\n",
        "\n",
        "        return self.bce(grapheme_pred, grapheme_true) + \\\n",
        "            self.bce(vowel_pred, vowel_true) + \\\n",
        "            self.bce(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "def get_loss(config: edict):\n",
        "    name = config.loss.name\n",
        "    params = config.loss.params\n",
        "    if name == \"bce\":\n",
        "        criterion = BengaliBCELoss(**params)\n",
        "    elif name == \"cross_entropy\":\n",
        "        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4aJX5V_KQ_t",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thU1KR2NKQ_u",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWo_pBvzKQ_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Optimizer = Union[Adam, SGD]\n",
        "\n",
        "\n",
        "def get_optimizer(model, config: edict) -> Optimizer:\n",
        "    name = config.optimizer.name\n",
        "    params = config.optimizer.params\n",
        "    if name == \"Adam\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    elif name == \"SGD\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmA47o80KQ_z",
        "colab_type": "text"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA7gtPiyKQ_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Scheduler = Optional[\n",
        "    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, config: edict) -> Scheduler:\n",
        "    params = config.scheduler.params\n",
        "    name = config.scheduler.name\n",
        "    scheduler: Scheduler = None\n",
        "    if name == \"plateau\":\n",
        "        scheduler = ReduceLROnPlateau(optimizer, **params)\n",
        "    elif name == \"cosine\":\n",
        "        scheduler = CosineAnnealingLR(optimizer, **params)\n",
        "    elif name == \"cosine_warmup\":\n",
        "        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n",
        "\n",
        "    return scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB5qDnQIKQ_2",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IwyscXBKQ_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MacroAverageRecall(Callback):\n",
        "    def __init__(self,\n",
        "                 n_grapheme=168,\n",
        "                 n_vowel=11,\n",
        "                 n_consonant=7,\n",
        "                 loss_type: str = \"bce\",\n",
        "                 prefix: str = \"mar\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 target_key: str = \"targets\"):\n",
        "        self.prefix = prefix\n",
        "        self.output_key = output_key\n",
        "        self.target_key = target_key\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.loss_type = loss_type\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "    def on_batch_end(self, state: RunnerState):\n",
        "        targ = state.input[self.target_key].detach()\n",
        "        out = state.output[self.output_key]\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme = torch.sigmoid(out[:, head:tail])\n",
        "        grapheme_np = torch.argmax(grapheme, dim=1).detach().cpu().numpy()\n",
        "        if self.loss_type == \"bce\":\n",
        "            grapheme_target = torch.argmax(\n",
        "                targ[:, head:tail], dim=1).cpu().numpy()\n",
        "        else:\n",
        "            grapheme_target = targ[:, 0].cpu().numpy()\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel = torch.sigmoid(out[:, head:tail])\n",
        "        vowel_np = torch.argmax(vowel, dim=1).detach().cpu().numpy()\n",
        "        if self.loss_type == \"bce\":\n",
        "            vowel_target = torch.argmax(\n",
        "                targ[:, head:tail], dim=1).cpu().numpy()\n",
        "        else:\n",
        "            vowel_target = targ[:, 1].cpu().numpy()\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant = torch.sigmoid(out[:, head:tail])\n",
        "        consonant_np = torch.argmax(consonant, dim=1).detach().cpu().numpy()\n",
        "        if self.loss_type == \"bce\":\n",
        "            consonant_target = torch.argmax(\n",
        "                targ[:, head:tail], dim=1).cpu().numpy()\n",
        "        else:\n",
        "            consonant_target = targ[:, 2].cpu().numpy()\n",
        "\n",
        "        scores = []\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                grapheme_target, grapheme_np, average=\"macro\",\n",
        "                zero_division=0))\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                vowel_target, vowel_np, average=\"macro\", zero_division=0))\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                consonant_target,\n",
        "                consonant_np,\n",
        "                average=\"macro\",\n",
        "                zero_division=0))\n",
        "        final_score = np.average(scores, weights=[2, 1, 1])\n",
        "        state.metrics.add_batch_value(name=self.prefix, value=final_score)\n",
        "\n",
        "\n",
        "class SaveWeightsCallback(Callback):\n",
        "    def __init__(self, to: Optional[Path] = None, name: str=\"\"):\n",
        "        self.to = to\n",
        "        self.name = name\n",
        "        super().__init__(CallbackOrder.External)\n",
        "\n",
        "    def on_epoch_end(self, state: RunnerState):\n",
        "        weights = state.model.state_dict()\n",
        "        logdir = state.logdir / \"checkpoints\"\n",
        "        logdir.mkdir(exist_ok=True, parents=True)\n",
        "        if self.name == \"\":\n",
        "            torch.save(weights, logdir / \"temp.pth\")\n",
        "        else:\n",
        "            torch.save(weights, logdir / f\"{self.name}.pth\")\n",
        "\n",
        "        if self.to is not None:\n",
        "            if self.name == \"\":\n",
        "                torch.save(weights, self.to / \"temp.pth\")\n",
        "            else:\n",
        "                torch.save(weights, self.to / f\"{self.name}.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYS5rgoKQ_5",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-QhaJoMKQ_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "633a1a0a-ed41-4818-dccd-34317a3aefc2"
      },
      "source": [
        "trn_idx, val_idx = splits[i]\n",
        "\n",
        "print(f\"Fold: {i}\")\n",
        "\n",
        "output_dir = output_base_dir / f\"fold{i}\"\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n",
        "val_df = df.loc[val_idx, :].reset_index(drop=True)\n",
        "data_loaders = {\n",
        "    phase: get_base_loader(\n",
        "        df,\n",
        "        train_images_path,\n",
        "        phase=phase,\n",
        "        size=(config.img_size, config.img_size),\n",
        "        batch_size=config.train.batch_size,\n",
        "        num_workers=config.num_workers,\n",
        "        transforms=transforms)\n",
        "    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
        "}\n",
        "model = get_model(config)\n",
        "criterion = get_loss(config)\n",
        "optimizer = get_optimizer(model, config)\n",
        "scheduler = get_scheduler(optimizer, config)\n",
        "callbacks = [\n",
        "    MacroAverageRecall(\n",
        "        n_grapheme=cls_levels[\"grapheme\"],\n",
        "        n_vowel=cls_levels[\"vowel\"],\n",
        "        n_consonant=cls_levels[\"consonant\"],\n",
        "        loss_type=config.loss.name),\n",
        "    SaveWeightsCallback(\n",
        "        to=Path(config.checkpoints\n",
        "                ) if config.checkpoints is not None else None,\n",
        "        name=trial)\n",
        "]\n",
        "\n",
        "if config.mixup:\n",
        "    callbacks.append(MixupCallback(fields=[\n",
        "        \"images\",\n",
        "    ]))\n",
        "\n",
        "runner = SupervisedRunner(\n",
        "    device=ct.utils.get_device(),\n",
        "    input_key=\"images\",\n",
        "    input_target_key=\"targets\",\n",
        "    output_key=\"logits\")\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    loaders=data_loaders,\n",
        "    logdir=output_dir,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=config.train.num_epochs,\n",
        "    callbacks=callbacks,\n",
        "    main_metric=\"mar\",\n",
        "    minimize_metric=False,\n",
        "    monitoring_params=None,\n",
        "    verbose=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 0\n",
            "[2020-01-28 22:34:54,512] \n",
            "1/30 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=3700.2952 | _timers/batch_time=0.1062 | _timers/data_time=0.0938 | _timers/model_time=0.0124 | loss=1.4340 | mar=0.7633\n",
            "1/30 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=6477.0689 | _timers/batch_time=0.1449 | _timers/data_time=0.1381 | _timers/model_time=0.0067 | loss=0.7406 | mar=0.8556\n",
            "[2020-01-28 22:39:53,525] \n",
            "2/30 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=3836.4569 | _timers/batch_time=0.1091 | _timers/data_time=0.0963 | _timers/model_time=0.0127 | loss=0.5747 | mar=0.8882\n",
            "2/30 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=6789.8067 | _timers/batch_time=0.1487 | _timers/data_time=0.1417 | _timers/model_time=0.0069 | loss=0.5424 | mar=0.8971\n",
            "[2020-01-28 22:44:54,179] \n",
            "3/30 * Epoch 3 (train): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=3947.4224 | _timers/batch_time=0.1109 | _timers/data_time=0.0980 | _timers/model_time=0.0129 | loss=0.4288 | mar=0.9150\n",
            "3/30 * Epoch 3 (valid): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=5108.5864 | _timers/batch_time=0.1484 | _timers/data_time=0.1412 | _timers/model_time=0.0072 | loss=0.5137 | mar=0.9009\n",
            "[2020-01-28 22:49:45,599] \n",
            "4/30 * Epoch 4 (train): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=3994.4070 | _timers/batch_time=0.1050 | _timers/data_time=0.0926 | _timers/model_time=0.0123 | loss=0.3311 | mar=0.9325\n",
            "4/30 * Epoch 4 (valid): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=5160.9362 | _timers/batch_time=0.1421 | _timers/data_time=0.1352 | _timers/model_time=0.0068 | loss=0.5307 | mar=0.9059\n",
            "[2020-01-28 22:54:34,459] \n",
            "5/30 * Epoch 5 (train): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=3740.1021 | _timers/batch_time=0.1034 | _timers/data_time=0.0912 | _timers/model_time=0.0122 | loss=0.2529 | mar=0.9478\n",
            "5/30 * Epoch 5 (valid): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=5953.9113 | _timers/batch_time=0.1399 | _timers/data_time=0.1331 | _timers/model_time=0.0068 | loss=0.4311 | mar=0.9212\n",
            "[2020-01-28 22:59:17,072] \n",
            "6/30 * Epoch 6 (train): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=4063.5124 | _timers/batch_time=0.0992 | _timers/data_time=0.0871 | _timers/model_time=0.0121 | loss=0.1809 | mar=0.9611\n",
            "6/30 * Epoch 6 (valid): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=6305.5099 | _timers/batch_time=0.1372 | _timers/data_time=0.1304 | _timers/model_time=0.0067 | loss=0.3970 | mar=0.9291\n",
            "[2020-01-28 23:03:57,743] \n",
            "7/30 * Epoch 7 (train): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=4189.9228 | _timers/batch_time=0.0975 | _timers/data_time=0.0860 | _timers/model_time=0.0115 | loss=0.1213 | mar=0.9732\n",
            "7/30 * Epoch 7 (valid): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=7640.9898 | _timers/batch_time=0.1359 | _timers/data_time=0.1292 | _timers/model_time=0.0066 | loss=0.3667 | mar=0.9365\n",
            "[2020-01-28 23:08:41,346] \n",
            "8/30 * Epoch 8 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4179.3396 | _timers/batch_time=0.0994 | _timers/data_time=0.0876 | _timers/model_time=0.0118 | loss=0.0753 | mar=0.9830\n",
            "8/30 * Epoch 8 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4334.1033 | _timers/batch_time=0.1380 | _timers/data_time=0.1316 | _timers/model_time=0.0063 | loss=0.3625 | mar=0.9413\n",
            "[2020-01-28 23:13:23,053] \n",
            "9/30 * Epoch 9 (train): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=4178.4756 | _timers/batch_time=0.0986 | _timers/data_time=0.0868 | _timers/model_time=0.0117 | loss=0.0457 | mar=0.9896\n",
            "9/30 * Epoch 9 (valid): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=4606.8695 | _timers/batch_time=0.1355 | _timers/data_time=0.1293 | _timers/model_time=0.0062 | loss=0.3485 | mar=0.9453\n",
            "[2020-01-28 23:18:06,877] \n",
            "10/30 * Epoch 10 (train): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=3957.4400 | _timers/batch_time=0.1000 | _timers/data_time=0.0882 | _timers/model_time=0.0118 | loss=0.0321 | mar=0.9932\n",
            "10/30 * Epoch 10 (valid): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=6711.7447 | _timers/batch_time=0.1373 | _timers/data_time=0.1308 | _timers/model_time=0.0064 | loss=0.3421 | mar=0.9482\n",
            "[2020-01-28 23:22:48,166] \n",
            "11/30 * Epoch 11 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=4165.5779 | _timers/batch_time=0.0994 | _timers/data_time=0.0874 | _timers/model_time=0.0120 | loss=0.0288 | mar=0.9941\n",
            "11/30 * Epoch 11 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=6235.2119 | _timers/batch_time=0.1356 | _timers/data_time=0.1292 | _timers/model_time=0.0063 | loss=0.3442 | mar=0.9475\n",
            "[2020-01-28 23:27:27,793] \n",
            "12/30 * Epoch 12 (train): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=3951.8056 | _timers/batch_time=0.0980 | _timers/data_time=0.0863 | _timers/model_time=0.0117 | loss=0.0290 | mar=0.9939\n",
            "12/30 * Epoch 12 (valid): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=5496.7095 | _timers/batch_time=0.1352 | _timers/data_time=0.1284 | _timers/model_time=0.0068 | loss=0.3522 | mar=0.9472\n",
            "[2020-01-28 23:32:08,686] \n",
            "13/30 * Epoch 13 (train): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=3868.3960 | _timers/batch_time=0.0988 | _timers/data_time=0.0871 | _timers/model_time=0.0116 | loss=0.0321 | mar=0.9933\n",
            "13/30 * Epoch 13 (valid): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=5804.1712 | _timers/batch_time=0.1366 | _timers/data_time=0.1301 | _timers/model_time=0.0064 | loss=0.3749 | mar=0.9453\n",
            "[2020-01-28 23:36:48,772] \n",
            "14/30 * Epoch 14 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=3928.6890 | _timers/batch_time=0.0982 | _timers/data_time=0.0865 | _timers/model_time=0.0116 | loss=0.0527 | mar=0.9884\n",
            "14/30 * Epoch 14 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=6911.5279 | _timers/batch_time=0.1360 | _timers/data_time=0.1292 | _timers/model_time=0.0067 | loss=0.4167 | mar=0.9381\n",
            "[2020-01-28 23:41:29,536] \n",
            "15/30 * Epoch 15 (train): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=4087.5264 | _timers/batch_time=0.0989 | _timers/data_time=0.0871 | _timers/model_time=0.0117 | loss=0.0877 | mar=0.9799\n",
            "15/30 * Epoch 15 (valid): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=6118.6191 | _timers/batch_time=0.1350 | _timers/data_time=0.1287 | _timers/model_time=0.0063 | loss=0.4387 | mar=0.9348\n",
            "[2020-01-28 23:46:11,301] \n",
            "16/30 * Epoch 16 (train): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=3791.2503 | _timers/batch_time=0.0987 | _timers/data_time=0.0869 | _timers/model_time=0.0118 | loss=0.1154 | mar=0.9736\n",
            "16/30 * Epoch 16 (valid): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=5641.2679 | _timers/batch_time=0.1380 | _timers/data_time=0.1314 | _timers/model_time=0.0066 | loss=0.4483 | mar=0.9278\n",
            "[2020-01-28 23:50:54,286] \n",
            "17/30 * Epoch 17 (train): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=3964.4500 | _timers/batch_time=0.0998 | _timers/data_time=0.0879 | _timers/model_time=0.0119 | loss=0.1472 | mar=0.9664\n",
            "17/30 * Epoch 17 (valid): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=6089.4208 | _timers/batch_time=0.1382 | _timers/data_time=0.1315 | _timers/model_time=0.0066 | loss=0.4554 | mar=0.9263\n",
            "[2020-01-28 23:55:38,216] \n",
            "18/30 * Epoch 18 (train): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=3947.9175 | _timers/batch_time=0.1008 | _timers/data_time=0.0888 | _timers/model_time=0.0120 | loss=0.1652 | mar=0.9640\n",
            "18/30 * Epoch 18 (valid): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=6360.2972 | _timers/batch_time=0.1381 | _timers/data_time=0.1315 | _timers/model_time=0.0065 | loss=0.4795 | mar=0.9215\n",
            "[2020-01-29 00:00:23,025] \n",
            "19/30 * Epoch 19 (train): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=3787.8189 | _timers/batch_time=0.1011 | _timers/data_time=0.0892 | _timers/model_time=0.0118 | loss=0.1733 | mar=0.9621\n",
            "19/30 * Epoch 19 (valid): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=5204.6680 | _timers/batch_time=0.1387 | _timers/data_time=0.1319 | _timers/model_time=0.0067 | loss=0.4790 | mar=0.9220\n",
            "[2020-01-29 00:05:06,622] \n",
            "20/30 * Epoch 20 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=3766.9978 | _timers/batch_time=0.1001 | _timers/data_time=0.0882 | _timers/model_time=0.0118 | loss=0.1656 | mar=0.9631\n",
            "20/30 * Epoch 20 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=7709.5927 | _timers/batch_time=0.1388 | _timers/data_time=0.1322 | _timers/model_time=0.0066 | loss=0.4656 | mar=0.9229\n",
            "[2020-01-29 00:09:52,460] \n",
            "21/30 * Epoch 21 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=3849.7636 | _timers/batch_time=0.1019 | _timers/data_time=0.0897 | _timers/model_time=0.0121 | loss=0.1546 | mar=0.9658\n",
            "21/30 * Epoch 21 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=6073.2961 | _timers/batch_time=0.1399 | _timers/data_time=0.1331 | _timers/model_time=0.0068 | loss=0.4406 | mar=0.9266\n",
            "[2020-01-29 00:14:36,660] \n",
            "22/30 * Epoch 22 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=3837.3146 | _timers/batch_time=0.1009 | _timers/data_time=0.0888 | _timers/model_time=0.0121 | loss=0.1306 | mar=0.9712\n",
            "22/30 * Epoch 22 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=4267.9649 | _timers/batch_time=0.1384 | _timers/data_time=0.1318 | _timers/model_time=0.0065 | loss=0.4476 | mar=0.9289\n",
            "[2020-01-29 00:19:22,277] \n",
            "23/30 * Epoch 23 (train): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=4057.2528 | _timers/batch_time=0.1019 | _timers/data_time=0.0902 | _timers/model_time=0.0116 | loss=0.1119 | mar=0.9747\n",
            "23/30 * Epoch 23 (valid): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=6090.8209 | _timers/batch_time=0.1379 | _timers/data_time=0.1313 | _timers/model_time=0.0065 | loss=0.4733 | mar=0.9268\n",
            "[2020-01-29 00:24:06,699] \n",
            "24/30 * Epoch 24 (train): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=3689.6529 | _timers/batch_time=0.1012 | _timers/data_time=0.0890 | _timers/model_time=0.0122 | loss=0.0881 | mar=0.9802\n",
            "24/30 * Epoch 24 (valid): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=5077.9572 | _timers/batch_time=0.1381 | _timers/data_time=0.1315 | _timers/model_time=0.0065 | loss=0.4682 | mar=0.9306\n",
            "[2020-01-29 00:28:51,867] \n",
            "25/30 * Epoch 25 (train): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=3834.3253 | _timers/batch_time=0.1014 | _timers/data_time=0.0894 | _timers/model_time=0.0119 | loss=0.0620 | mar=0.9859\n",
            "25/30 * Epoch 25 (valid): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=7132.7042 | _timers/batch_time=0.1394 | _timers/data_time=0.1327 | _timers/model_time=0.0067 | loss=0.4687 | mar=0.9310\n",
            "[2020-01-29 00:33:35,884] \n",
            "26/30 * Epoch 26 (train): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=3949.7832 | _timers/batch_time=0.1009 | _timers/data_time=0.0888 | _timers/model_time=0.0121 | loss=0.0412 | mar=0.9911\n",
            "26/30 * Epoch 26 (valid): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=6448.0071 | _timers/batch_time=0.1383 | _timers/data_time=0.1315 | _timers/model_time=0.0068 | loss=0.4484 | mar=0.9383\n",
            "[2020-01-29 00:38:19,401] \n",
            "27/30 * Epoch 27 (train): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=3915.8224 | _timers/batch_time=0.1004 | _timers/data_time=0.0884 | _timers/model_time=0.0119 | loss=0.0265 | mar=0.9945\n",
            "27/30 * Epoch 27 (valid): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=5887.8865 | _timers/batch_time=0.1370 | _timers/data_time=0.1304 | _timers/model_time=0.0066 | loss=0.4623 | mar=0.9409\n",
            "[2020-01-29 00:43:02,912] \n",
            "28/30 * Epoch 28 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4057.6486 | _timers/batch_time=0.1000 | _timers/data_time=0.0881 | _timers/model_time=0.0118 | loss=0.0167 | mar=0.9966\n",
            "28/30 * Epoch 28 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=6125.5206 | _timers/batch_time=0.1403 | _timers/data_time=0.1331 | _timers/model_time=0.0071 | loss=0.4369 | mar=0.9442\n",
            "[2020-01-29 00:47:47,457] \n",
            "29/30 * Epoch 29 (train): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=3937.4534 | _timers/batch_time=0.1011 | _timers/data_time=0.0891 | _timers/model_time=0.0120 | loss=0.0107 | mar=0.9980\n",
            "29/30 * Epoch 29 (valid): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=4563.8622 | _timers/batch_time=0.1389 | _timers/data_time=0.1322 | _timers/model_time=0.0067 | loss=0.4254 | mar=0.9471\n",
            "[2020-01-29 00:52:33,528] \n",
            "30/30 * Epoch 30 (train): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=3853.6011 | _timers/batch_time=0.1012 | _timers/data_time=0.0892 | _timers/model_time=0.0120 | loss=0.0079 | mar=0.9985\n",
            "30/30 * Epoch 30 (valid): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=4752.5427 | _timers/batch_time=0.1397 | _timers/data_time=0.1329 | _timers/model_time=0.0068 | loss=0.4237 | mar=0.9490\n",
            "Top best models:\n",
            "output/fold0/checkpoints/train.30.pth\t0.9490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF64LRYqK1l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}