{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/koukyo1994/kaggle-bengali-ai/blob/master/notebook/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-LYW6ekKQ-x"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyICnC_QKQ-0"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n",
    "pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n",
    "pip install pretrainedmodels==0.7.4 >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2m_PlwpKQ-5"
   },
   "source": [
    "## Integration with Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jsPLSeVuKQ-6",
    "outputId": "dfa51f64-d321-4603-b8f3-8457fd6c3dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3FN8jiWKQ--"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir input\n",
    "cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n",
    "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n",
    "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24Iv5BnEKQ_B"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qYrCK0t6KQ_C",
    "outputId": "d5117fc3-a959-4aa4-d81d-7d057b1d91a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import catalyst as ct\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "import torchvision.models as models\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Union, Optional, List\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
    "from catalyst.dl.callbacks import MixupCallback\n",
    "from catalyst.utils import get_device\n",
    "from easydict import EasyDict as edict\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from fastprogress import progress_bar\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n",
    "                                      CosineAnnealingLR,\n",
    "                                      CosineAnnealingWarmRestarts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tszhN7oGKQ_H"
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqfUxJd6KQ_I"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "trial = \"resnet34_fourth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXUZcRAGKQ_L"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S16TliO4KQ_M"
   },
   "outputs": [],
   "source": [
    "conf_string = '''\n",
    "dataset:\n",
    "  train:\n",
    "    affine: True\n",
    "    morphology: False\n",
    "  val:\n",
    "    affine: False\n",
    "    morphology: False\n",
    "  test:\n",
    "    affine: False\n",
    "    morphology: False\n",
    "\n",
    "data:\n",
    "  train_df_path: input/bengaliai-cv19/train.csv\n",
    "  train_images_path: input/bengaliai-cv19/train_images\n",
    "  test_images_path: input/bengaliai-cv19/test_images\n",
    "  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n",
    "\n",
    "model:\n",
    "  model_name: resnet34\n",
    "  pretrained: True\n",
    "  num_classes: 186\n",
    "  head: custom\n",
    "  in_channels: 3\n",
    "\n",
    "train:\n",
    "  batch_size: 128\n",
    "  num_epochs: 10\n",
    "\n",
    "test:\n",
    "  batch_size: 128\n",
    "\n",
    "loss:\n",
    "  name: cross_entropy\n",
    "  params:\n",
    "    n_grapheme: 168\n",
    "    n_vowel: 11\n",
    "    n_consonant: 7\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.0001\n",
    "\n",
    "scheduler:\n",
    "  name: cosine\n",
    "  params:\n",
    "    T_max: 10\n",
    "\n",
    "transforms:\n",
    "  train:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: True\n",
    "    RandomScale: True\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "  val:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: False\n",
    "    RandomScale: False\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "  test:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: False\n",
    "    RandomScale: False\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "\n",
    "val:\n",
    "  name: kfold\n",
    "  params:\n",
    "    random_state: 42\n",
    "    n_splits: 5\n",
    "\n",
    "callbacks:\n",
    "  - AverageRecall:\n",
    "      index: 0\n",
    "      offset: 0\n",
    "      n_classes: 168\n",
    "      prefix: grapheme_recall\n",
    "      loss_type: cross_entroy\n",
    "  - AverageRecall:\n",
    "      index: 1\n",
    "      offset: 168\n",
    "      n_classes: 11\n",
    "      prefix: vowel_recall\n",
    "      loss_type: cross_entropy\n",
    "  - AverageRecall:\n",
    "      index: 2\n",
    "      offset: 179\n",
    "      n_classes: 7\n",
    "      prefix: consonant_recall\n",
    "      loss_type: cross_entropy\n",
    "  - TotalAverageRecall:\n",
    "      loss_type: cross_entropy\n",
    "  - SaveWeightsCallback:\n",
    "      to: /content/gdrive/My Drive/kaggle-bengali/checkpoints\n",
    "\n",
    "log_dir: log/\n",
    "num_workers: 2\n",
    "seed: 1213\n",
    "img_size: 224\n",
    "mixup: False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piePmxjjKQ_P"
   },
   "outputs": [],
   "source": [
    "def _get_default():\n",
    "    cfg = edict()\n",
    "\n",
    "    # dataset\n",
    "    cfg.dataset = edict()\n",
    "    cfg.dataset.train = edict()\n",
    "    cfg.dataset.val = edict()\n",
    "    cfg.dataset.test = edict()\n",
    "    cfg.dataset.train.affine = False\n",
    "    cfg.dataset.train.morphology = False\n",
    "    cfg.dataset.val.affine = False\n",
    "    cfg.dataset.val.morphology = False\n",
    "    cfg.dataset.test.affine = False\n",
    "    cfg.dataset.test.morphology = False\n",
    "\n",
    "    # dataset\n",
    "    cfg.data = edict()\n",
    "\n",
    "    # model\n",
    "    cfg.model = edict()\n",
    "    cfg.model.model_name = \"resnet18\"\n",
    "    cfg.model.num_classes = 186\n",
    "    cfg.model.pretrained = True\n",
    "    cfg.model.head = \"linear\"\n",
    "    cfg.model.in_channels = 3\n",
    "\n",
    "    # train\n",
    "    cfg.train = edict()\n",
    "\n",
    "    # test\n",
    "    cfg.test = edict()\n",
    "\n",
    "    # loss\n",
    "    cfg.loss = edict()\n",
    "    cfg.loss.params = edict()\n",
    "\n",
    "    # optimizer\n",
    "    cfg.optimizer = edict()\n",
    "    cfg.optimizer.params = edict()\n",
    "\n",
    "    # scheduler\n",
    "    cfg.scheduler = edict()\n",
    "    cfg.scheduler.params = edict()\n",
    "\n",
    "    # transforms:\n",
    "    cfg.transforms = edict()\n",
    "    cfg.transforms.train = edict()\n",
    "    cfg.transforms.train.HorizontalFlip = False\n",
    "    cfg.transforms.train.VerticalFlip = False\n",
    "    cfg.transforms.train.Noise = False\n",
    "    cfg.transforms.train.Contrast = False\n",
    "    cfg.transforms.train.Rotate = False\n",
    "    cfg.transforms.train.RandomScale = False\n",
    "    cfg.transforms.train.Cutout = edict()\n",
    "    cfg.transforms.train.Cutout.num_holes = 0\n",
    "    cfg.transforms.val = edict()\n",
    "    cfg.transforms.val.HorizontalFlip = False\n",
    "    cfg.transforms.val.VerticalFlip = False\n",
    "    cfg.transforms.val.Noise = False\n",
    "    cfg.transforms.val.Contrast = False\n",
    "    cfg.transforms.val.Rotate = False\n",
    "    cfg.transforms.val.RandomScale = False\n",
    "    cfg.transforms.val.Cutout = edict()\n",
    "    cfg.transforms.val.Cutout.num_holes = 0\n",
    "    cfg.transforms.test = edict()\n",
    "    cfg.transforms.test.HorizontalFlip = False\n",
    "    cfg.transforms.test.VerticalFlip = False\n",
    "    cfg.transforms.test.Noise = False\n",
    "    cfg.transforms.test.Contrast = False\n",
    "    cfg.transforms.test.Rotate = False\n",
    "    cfg.transforms.test.RandomScale = False\n",
    "    cfg.transforms.test.Cutout = edict()\n",
    "    cfg.transforms.test.Cutout.num_holes = 0\n",
    "    cfg.transforms.mean = [0.485, 0.456, 0.406]\n",
    "    cfg.transforms.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # val\n",
    "    cfg.val = edict()\n",
    "    cfg.val.params = edict()\n",
    "\n",
    "    cfg.callbacks = []\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def _merge_config(src: edict, dst: edict):\n",
    "    if not isinstance(src, edict):\n",
    "        return\n",
    "    for k, v in src.items():\n",
    "        if isinstance(v, edict):\n",
    "            _merge_config(src[k], dst[k])\n",
    "        else:\n",
    "            dst[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOq2Hol4KQ_S"
   },
   "outputs": [],
   "source": [
    "cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n",
    "config = _get_default()\n",
    "_merge_config(cfg, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iinSUuVEKQ_V"
   },
   "source": [
    "## Environmental settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Mo5V5VT5KQ_W",
    "outputId": "d8e95664-f502-45ef-ae06-d8db678f7801"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ct.utils.set_global_seed(config.seed)\n",
    "ct.utils.prepare_cudnn(deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHv73-KuKQ_Y"
   },
   "outputs": [],
   "source": [
    "output_base_dir = Path(\"output\")\n",
    "output_base_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "train_images_path = Path(config.data.train_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nowCCU9GKQ_b",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data and utilities preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAy9mKC1KQ_c"
   },
   "source": [
    "### validation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38wcJQJEKQ_c"
   },
   "outputs": [],
   "source": [
    "def no_fold(df: pd.DataFrame,\n",
    "            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    params = config.val.params\n",
    "    idx = np.arange(len(df))\n",
    "    trn_idx, val_idx = train_test_split(idx, **params)\n",
    "    return [(trn_idx, val_idx)]\n",
    "\n",
    "\n",
    "def kfold(df: pd.DataFrame,\n",
    "          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    params = config.val.params\n",
    "    kf = KFold(shuffle=True, **params)\n",
    "    splits = list(kf.split(df))\n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_validation(df: pd.DataFrame,\n",
    "                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    name: str = config.val.name\n",
    "\n",
    "    func = globals().get(name)\n",
    "    if func is None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return func(df, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE5iD2HAKQ_f"
   },
   "source": [
    "### transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvCvJ5ScKQ_f"
   },
   "outputs": [],
   "source": [
    "def get_transforms(config: edict, phase: str = \"train\"):\n",
    "    assert phase in [\"train\", \"valid\", \"test\"]\n",
    "    if phase == \"train\":\n",
    "        cfg = config.transforms.train\n",
    "    elif phase == \"valid\":\n",
    "        cfg = config.transforms.val\n",
    "    elif phase == \"test\":\n",
    "        cfg = config.transforms.test\n",
    "    list_transforms = []\n",
    "    if cfg.HorizontalFlip:\n",
    "        list_transforms.append(A.HorizontalFrip())\n",
    "    if cfg.VerticalFlip:\n",
    "        list_transforms.append(A.VerticalFlip())\n",
    "    if cfg.Rotate:\n",
    "        list_transforms.append(A.Rotate(limit=15))\n",
    "    if cfg.RandomScale:\n",
    "        list_transforms.append(A.RandomScale())\n",
    "    if cfg.Noise:\n",
    "        list_transforms.append(\n",
    "            A.OneOf(\n",
    "                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n",
    "    if cfg.Contrast:\n",
    "        list_transforms.append(\n",
    "            A.OneOf(\n",
    "                [A.RandomContrast(0.5),\n",
    "                 A.RandomGamma(),\n",
    "                 A.RandomBrightness()],\n",
    "                p=0.5))\n",
    "    if cfg.Cutout.num_holes > 0:\n",
    "        list_transforms.append(A.Cutout(**config.Cutout))\n",
    "\n",
    "    list_transforms.append(\n",
    "        A.Normalize(\n",
    "            mean=config.transforms.mean, std=config.transforms.std, p=1))\n",
    "\n",
    "    return A.Compose(list_transforms, p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mQCOAtuLtV3"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdTnGd0aLu-8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.data.train_df_path)\n",
    "splits = get_validation(df, config)\n",
    "\n",
    "transforms_dict = {\n",
    "    phase: get_transforms(config, phase)\n",
    "    for phase in [\"train\", \"valid\"]\n",
    "}\n",
    "\n",
    "cls_levels = {\n",
    "    \"grapheme\": df.grapheme_root.nunique(),\n",
    "    \"vowel\": df.vowel_diacritic.nunique(),\n",
    "    \"consonant\": df.consonant_diacritic.nunique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3X2245OKQ_j"
   },
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hj6MHrqXKQ_j"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(torchdata.Dataset):\n",
    "    def __init__(self, image_dir: Path, df: pd.DataFrame, transforms,\n",
    "                 size: Tuple[int, int]):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.df.loc[idx, \"image_id\"]\n",
    "        image_path = self.image_dir / f\"{image_id}.png\"\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "        longer_side = image.shape[1]\n",
    "        if image.ndim == 2:\n",
    "            new_image = np.ones(\n",
    "                (longer_side, longer_side), dtype=np.uint8) * 255\n",
    "        else:\n",
    "            new_image = np.ones(\n",
    "                (longer_side, longer_side, 3), dtype=np.uint8) * 255\n",
    "        offset = np.random.randint(0, longer_side - image.shape[0])\n",
    "        new_image[offset:offset + image.shape[1], :] = image\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=new_image)[\"image\"]\n",
    "        image = cv2.resize(image, self.size)\n",
    "        if image.shape[2] == 3:\n",
    "            image = np.moveaxis(image, -1, 0)\n",
    "        grapheme = self.df.loc[idx, \"grapheme_root\"]\n",
    "        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n",
    "        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n",
    "        label = np.zeros(3, dtype=int)\n",
    "        label[0] = grapheme\n",
    "        label[1] = vowel\n",
    "        label[2] = consonant\n",
    "        return {\"images\": image, \"targets\": label}\n",
    "    \n",
    "    \n",
    "def get_base_loader(df: pd.DataFrame,\n",
    "                    image_dir: Path,\n",
    "                    phase: str = \"train\",\n",
    "                    size: Tuple[int, int] = (128, 128),\n",
    "                    batch_size=256,\n",
    "                    num_workers=2,\n",
    "                    transforms=None):\n",
    "    assert phase in [\"train\", \"valid\"]\n",
    "    if phase == \"train\":\n",
    "        is_shuffle = True\n",
    "        drop_last = True\n",
    "    else:\n",
    "        is_shuffle = False\n",
    "        drop_last = False\n",
    "\n",
    "    dataset = BaseDataset(  # type: ignore\n",
    "        image_dir, df, transforms, size)\n",
    "    return torchdata.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=is_shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc6F3Pu5KQ_m",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjBhyu98KQ_n"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wABhZZ9LKQ_o"
   },
   "outputs": [],
   "source": [
    "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p),\n",
    "                        (x.size(-2), x.size(-1))).pow(1. / p)\n",
    "\n",
    "\n",
    "def mish(input):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    See additional documentation for mish class.\n",
    "    '''\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    Examples:\n",
    "        >>> m = Mish()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return mish(input)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(\n",
    "            self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model_name: str,\n",
    "                 num_classes: int,\n",
    "                 pretrained=False,\n",
    "                 head=\"linear\",\n",
    "                 in_channels=3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.base = getattr(models, model_name)(pretrained=pretrained)\n",
    "        self.head = head\n",
    "        assert in_channels in [1, 3]\n",
    "        assert head in [\"linear\", \"custom\"]\n",
    "        if in_channels == 1:\n",
    "            if pretrained:\n",
    "                weight = self.base.conv1.weight\n",
    "                self.base.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                self.base.conv1.weight = nn.Parameter(\n",
    "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
    "                    requires_grad=True)\n",
    "            else:\n",
    "                self.base.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if head == \"linear\":\n",
    "            n_in_features = self.base.fc.in_features\n",
    "            self.base.fc = nn.Linear(n_in_features, self.num_classes)\n",
    "        elif head == \"custom\":\n",
    "            n_in_features = self.base.fc.in_features\n",
    "            arch = list(self.base.children())\n",
    "            for _ in range(2):\n",
    "                arch.pop()\n",
    "            self.base = nn.Sequential(*arch)\n",
    "            self.grapheme_head = nn.Sequential(\n",
    "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 168))\n",
    "            self.vowel_head = nn.Sequential(\n",
    "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 11))\n",
    "            self.consonant_head = nn.Sequential(\n",
    "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 7))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.head == \"linear\":\n",
    "            return self.base(x)\n",
    "        elif self.head == \"custom\":\n",
    "            x = self.base(x)\n",
    "            grapheme = self.grapheme_head(x)\n",
    "            vowel = self.vowel_head(x)\n",
    "            consonant = self.consonant_head(x)\n",
    "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "def get_model(config: edict):\n",
    "    params = config.model\n",
    "    if \"resnet\" in params.model_name:\n",
    "        return Resnet(**params)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IPNqFE5KQ_q"
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXKZUtQdKQ_r"
   },
   "outputs": [],
   "source": [
    "class BengaliCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
    "        super().__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        head = 0\n",
    "        tail = self.n_grapheme\n",
    "        grapheme_pred = pred[:, head:tail]\n",
    "        grapheme_true = true[:, 0]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_vowel\n",
    "        vowel_pred = pred[:, head:tail]\n",
    "        vowel_true = true[:, 1]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_consonant\n",
    "        consonant_pred = pred[:, head:tail]\n",
    "        consonant_true = true[:, 2]\n",
    "\n",
    "        return self.cross_entropy(grapheme_pred, grapheme_true) + \\\n",
    "            self.cross_entropy(vowel_pred, vowel_true) + \\\n",
    "            self.cross_entropy(consonant_pred, consonant_true)\n",
    "\n",
    "\n",
    "class BengaliBCELoss(nn.Module):\n",
    "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
    "        super().__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        head = 0\n",
    "        tail = self.n_grapheme\n",
    "        grapheme_pred = pred[:, head:tail]\n",
    "        grapheme_true = true[:, head:tail]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_vowel\n",
    "        vowel_pred = pred[:, head:tail]\n",
    "        vowel_true = true[:, head:tail]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_consonant\n",
    "        consonant_pred = pred[:, head:tail]\n",
    "        consonant_true = true[:, head:tail]\n",
    "\n",
    "        return self.bce(grapheme_pred, grapheme_true) + \\\n",
    "            self.bce(vowel_pred, vowel_true) + \\\n",
    "            self.bce(consonant_pred, consonant_true)\n",
    "\n",
    "\n",
    "def get_loss(config: edict):\n",
    "    name = config.loss.name\n",
    "    params = config.loss.params\n",
    "    if name == \"bce\":\n",
    "        criterion = BengaliBCELoss(**params)\n",
    "    elif name == \"cross_entropy\":\n",
    "        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4aJX5V_KQ_t",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thU1KR2NKQ_u"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWo_pBvzKQ_u"
   },
   "outputs": [],
   "source": [
    "Optimizer = Union[Adam, SGD]\n",
    "\n",
    "\n",
    "def get_optimizer(model, config: edict) -> Optimizer:\n",
    "    name = config.optimizer.name\n",
    "    params = config.optimizer.params\n",
    "    if name == \"Adam\":\n",
    "        optimizer = Adam(model.parameters(), **params)\n",
    "    elif name == \"SGD\":\n",
    "        optimizer = Adam(model.parameters(), **params)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmA47o80KQ_z"
   },
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA7gtPiyKQ_0"
   },
   "outputs": [],
   "source": [
    "Scheduler = Optional[\n",
    "    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, config: edict) -> Scheduler:\n",
    "    params = config.scheduler.params\n",
    "    name = config.scheduler.name\n",
    "    scheduler: Scheduler = None\n",
    "    if name == \"plateau\":\n",
    "        scheduler = ReduceLROnPlateau(optimizer, **params)\n",
    "    elif name == \"cosine\":\n",
    "        scheduler = CosineAnnealingLR(optimizer, **params)\n",
    "    elif name == \"cosine_warmup\":\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YB5qDnQIKQ_2"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IwyscXBKQ_3"
   },
   "outputs": [],
   "source": [
    "class AverageRecall(Callback):\n",
    "    def __init__(self,\n",
    "                 index: int,\n",
    "                 offset: int,\n",
    "                 n_classes: int,\n",
    "                 prefix: str,\n",
    "                 loss_type: str = \"bce\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 target_key: str = \"targets\"):\n",
    "        self.index = index\n",
    "        self.offset = offset\n",
    "        self.n_classes = n_classes\n",
    "        self.prefix = prefix\n",
    "        self.loss_type = loss_type\n",
    "        self.output_key = output_key\n",
    "        self.target_key = target_key\n",
    "        self.recall = 0.0\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "\n",
    "    def on_loader_start(self, state: RunnerState):\n",
    "        self.prediction: List[int] = []\n",
    "        self.target: List[int] = []\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        self.batch_count += 1\n",
    "\n",
    "        targ = state.input[self.target_key].detach()\n",
    "        out = state.output[self.output_key].detach()\n",
    "        head = self.offset\n",
    "        tail = self.offset + self.n_classes\n",
    "        if self.loss_type == \"bce\":\n",
    "            pred_np = torch.argmax(\n",
    "                torch.sigmoid(out[:, head:tail]), dim=1).cpu().numpy()\n",
    "            target_np = torch.argmax(targ[:, head:tail], dim=1).cpu().numpy()\n",
    "        else:\n",
    "            pred_np = torch.argmax(out[:, head:tail], dim=1).cpu().numpy()\n",
    "            target_np = targ[:, self.index].cpu().numpy()\n",
    "        self.prediction.extend(pred_np)\n",
    "        self.target.extend(target_np)\n",
    "        score = recall_score(\n",
    "            target_np, pred_np, average=\"macro\", zero_division=0)\n",
    "        state.metrics.add_batch_value(name=\"batch_\" + self.prefix, value=score)\n",
    "        if self.batch_count == state.loader_len:\n",
    "            recall = self._recall()\n",
    "            state.metrics.add_batch_value(name=self.prefix, value=recall)\n",
    "            self.recall = recall\n",
    "\n",
    "    def _recall(self):\n",
    "        rec = recall_score(\n",
    "            y_true=self.target,\n",
    "            y_pred=self.prediction,\n",
    "            average=\"macro\",\n",
    "            zero_division=0)\n",
    "        return rec\n",
    "\n",
    "\n",
    "class TotalAverageRecall(Callback):\n",
    "    def __init__(self,\n",
    "                 n_grapheme=168,\n",
    "                 n_vowel=11,\n",
    "                 n_consonant=7,\n",
    "                 loss_type: str = \"bce\",\n",
    "                 prefix: str = \"tar\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 target_key: str = \"targets\"):\n",
    "        self.prefix = prefix\n",
    "        self.grapheme_callback = AverageRecall(\n",
    "            index=0,\n",
    "            offset=0,\n",
    "            n_classes=n_grapheme,\n",
    "            prefix=\"grapheme_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        self.vowel_callback = AverageRecall(\n",
    "            index=1,\n",
    "            offset=n_grapheme,\n",
    "            n_classes=n_vowel,\n",
    "            prefix=\"vowel_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        self.consonant_callback = AverageRecall(\n",
    "            index=2,\n",
    "            offset=n_grapheme + n_vowel,\n",
    "            n_classes=n_consonant,\n",
    "            prefix=\"consonant_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "\n",
    "    def on_loader_start(self, state):\n",
    "        self.grapheme_callback.on_loader_start(state)\n",
    "        self.vowel_callback.on_loader_start(state)\n",
    "        self.consonant_callback.on_loader_start(state)\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        self.batch_count += 1\n",
    "        self.grapheme_callback.on_batch_end(state)\n",
    "        self.vowel_callback.on_batch_end(state)\n",
    "        self.consonant_callback.on_batch_end(state)\n",
    "        if self.batch_count == state.loader_len:\n",
    "            grapheme_recall = self.grapheme_callback.recall\n",
    "            vowel_recall = self.vowel_callback.recall\n",
    "            consonant_recall = self.consonant_callback.recall\n",
    "            final_score = np.average(\n",
    "                [grapheme_recall, vowel_recall, consonant_recall],\n",
    "                weights=[2, 1, 1])\n",
    "            state.metrics.add_batch_value(name=self.prefix, value=final_score)\n",
    "\n",
    "\n",
    "\n",
    "class SaveWeightsCallback(Callback):\n",
    "    def __init__(self, to: Optional[Union[Path, str]] = None, name: str=\"\"):\n",
    "        if isinstance(to, str):\n",
    "            self.to = Path(to)\n",
    "        else:\n",
    "            self.to = to\n",
    "        self.name = name\n",
    "        super().__init__(CallbackOrder.External)\n",
    "\n",
    "    def on_epoch_end(self, state: RunnerState):\n",
    "        weights = state.model.state_dict()\n",
    "        logdir = state.logdir / \"checkpoints\"\n",
    "        logdir.mkdir(exist_ok=True, parents=True)\n",
    "        if self.name == \"\":\n",
    "            torch.save(weights, logdir / \"temp.pth\")\n",
    "        else:\n",
    "            torch.save(weights, logdir / f\"{self.name}.pth\")\n",
    "\n",
    "        if self.to is not None:\n",
    "            if self.name == \"\":\n",
    "                torch.save(weights, self.to / \"temp.pth\")\n",
    "            else:\n",
    "                torch.save(weights, self.to / f\"{self.name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHvFfq-C3NGk"
   },
   "outputs": [],
   "source": [
    "def get_callbacks(config: edict):\n",
    "    callbacks = []\n",
    "    for callback in config.callbacks:\n",
    "        name = list(callback.keys())[0]\n",
    "        params = callback[name]\n",
    "        if globals().get(name) is not None:\n",
    "            if params is not None:\n",
    "                callbacks.append(globals().get(name)(**params))  # type: ignore\n",
    "            else:\n",
    "                callbacks.append(globals().get(name)())  # type: ignore\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChYS5rgoKQ_5"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "M-QhaJoMKQ_6",
    "outputId": "664db7f0-fb92-470b-cb15-f505a17c82d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "[2020-01-30 22:13:08,174] \n",
      "1/30 * Epoch 1 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=4257.7112 | _timers/batch_time=0.0376 | _timers/data_time=0.0100 | _timers/model_time=0.0252 | batch_consonant_recall=0.4058 | batch_grapheme_recall=0.1212 | batch_vowel_recall=0.4119 | consonant_recall=0.3401 | grapheme_recall=0.0845 | loss=6.2271 | tar=0.2289 | vowel_recall=0.4064\n",
      "1/30 * Epoch 1 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2565.3749 | _timers/batch_time=0.1135 | _timers/data_time=0.0980 | _timers/model_time=0.0154 | batch_consonant_recall=0.5202 | batch_grapheme_recall=0.4960 | batch_vowel_recall=0.7486 | consonant_recall=0.4627 | grapheme_recall=0.3973 | loss=3.2068 | tar=0.5009 | vowel_recall=0.7462\n",
      "[2020-01-30 22:19:40,390] \n",
      "2/30 * Epoch 2 (train): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=4219.3685 | _timers/batch_time=0.0379 | _timers/data_time=0.0102 | _timers/model_time=0.0254 | batch_consonant_recall=0.4861 | batch_grapheme_recall=0.2380 | batch_vowel_recall=0.4837 | consonant_recall=0.4197 | grapheme_recall=0.2082 | loss=5.2285 | tar=0.3287 | vowel_recall=0.4786\n",
      "2/30 * Epoch 2 (valid): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=3261.1573 | _timers/batch_time=0.1140 | _timers/data_time=0.0986 | _timers/model_time=0.0154 | batch_consonant_recall=0.8351 | batch_grapheme_recall=0.7237 | batch_vowel_recall=0.9071 | consonant_recall=0.7792 | grapheme_recall=0.7035 | loss=1.8921 | tar=0.7740 | vowel_recall=0.9096\n",
      "[2020-01-30 22:26:08,522] \n",
      "3/30 * Epoch 3 (train): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=3799.6227 | _timers/batch_time=0.0437 | _timers/data_time=0.0149 | _timers/model_time=0.0263 | batch_consonant_recall=0.4931 | batch_grapheme_recall=0.2616 | batch_vowel_recall=0.4890 | consonant_recall=0.4288 | grapheme_recall=0.2537 | loss=4.9629 | tar=0.3552 | vowel_recall=0.4845\n",
      "3/30 * Epoch 3 (valid): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=2631.2633 | _timers/batch_time=0.1140 | _timers/data_time=0.0986 | _timers/model_time=0.0154 | batch_consonant_recall=0.7480 | batch_grapheme_recall=0.7322 | batch_vowel_recall=0.8139 | consonant_recall=0.6936 | grapheme_recall=0.7276 | loss=1.9879 | tar=0.7407 | vowel_recall=0.8140\n",
      "[2020-01-30 22:32:37,124] \n",
      "4/30 * Epoch 4 (train): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=4163.2948 | _timers/batch_time=0.0391 | _timers/data_time=0.0115 | _timers/model_time=0.0252 | batch_consonant_recall=0.5091 | batch_grapheme_recall=0.2741 | batch_vowel_recall=0.4970 | consonant_recall=0.4468 | grapheme_recall=0.2725 | loss=4.7826 | tar=0.3707 | vowel_recall=0.4910\n",
      "4/30 * Epoch 4 (valid): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=3020.6923 | _timers/batch_time=0.1137 | _timers/data_time=0.0977 | _timers/model_time=0.0159 | batch_consonant_recall=0.8056 | batch_grapheme_recall=0.7894 | batch_vowel_recall=0.8815 | consonant_recall=0.7709 | grapheme_recall=0.8011 | loss=1.8405 | tar=0.8140 | vowel_recall=0.8828\n",
      "[2020-01-30 22:39:11,967] \n",
      "5/30 * Epoch 5 (train): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=3996.5498 | _timers/batch_time=0.0416 | _timers/data_time=0.0131 | _timers/model_time=0.0261 | batch_consonant_recall=0.5148 | batch_grapheme_recall=0.2961 | batch_vowel_recall=0.5056 | consonant_recall=0.4547 | grapheme_recall=0.3013 | loss=4.5338 | tar=0.3890 | vowel_recall=0.4986\n",
      "5/30 * Epoch 5 (valid): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=2667.8266 | _timers/batch_time=0.1171 | _timers/data_time=0.1010 | _timers/model_time=0.0160 | batch_consonant_recall=0.8752 | batch_grapheme_recall=0.8221 | batch_vowel_recall=0.9385 | consonant_recall=0.8317 | grapheme_recall=0.8480 | loss=1.4108 | tar=0.8671 | vowel_recall=0.9408\n",
      "[2020-01-30 22:45:36,799] \n",
      "6/30 * Epoch 6 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=3919.1842 | _timers/batch_time=0.0407 | _timers/data_time=0.0114 | _timers/model_time=0.0268 | batch_consonant_recall=0.5221 | batch_grapheme_recall=0.3081 | batch_vowel_recall=0.5088 | consonant_recall=0.4622 | grapheme_recall=0.3218 | loss=4.3867 | tar=0.4025 | vowel_recall=0.5041\n",
      "6/30 * Epoch 6 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=2649.9209 | _timers/batch_time=0.1157 | _timers/data_time=0.0991 | _timers/model_time=0.0166 | batch_consonant_recall=0.7810 | batch_grapheme_recall=0.8114 | batch_vowel_recall=0.9023 | consonant_recall=0.7295 | grapheme_recall=0.8233 | loss=1.7710 | tar=0.8198 | vowel_recall=0.9031\n",
      "[2020-01-30 22:52:01,037] \n",
      "7/30 * Epoch 7 (train): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=3968.8172 | _timers/batch_time=0.0412 | _timers/data_time=0.0124 | _timers/model_time=0.0264 | batch_consonant_recall=0.5395 | batch_grapheme_recall=0.3313 | batch_vowel_recall=0.5223 | consonant_recall=0.4824 | grapheme_recall=0.3429 | loss=4.1819 | tar=0.4216 | vowel_recall=0.5181\n",
      "7/30 * Epoch 7 (valid): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=2703.6178 | _timers/batch_time=0.1161 | _timers/data_time=0.1001 | _timers/model_time=0.0159 | batch_consonant_recall=0.8522 | batch_grapheme_recall=0.8358 | batch_vowel_recall=0.9283 | consonant_recall=0.8049 | grapheme_recall=0.8594 | loss=1.6086 | tar=0.8632 | vowel_recall=0.9290\n",
      "[2020-01-30 22:58:29,054] \n",
      "8/30 * Epoch 8 (train): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=4084.9592 | _timers/batch_time=0.0389 | _timers/data_time=0.0102 | _timers/model_time=0.0262 | batch_consonant_recall=0.5501 | batch_grapheme_recall=0.3514 | batch_vowel_recall=0.5329 | consonant_recall=0.5027 | grapheme_recall=0.3638 | loss=4.0188 | tar=0.4397 | vowel_recall=0.5287\n",
      "8/30 * Epoch 8 (valid): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=2844.0047 | _timers/batch_time=0.1143 | _timers/data_time=0.0983 | _timers/model_time=0.0159 | batch_consonant_recall=0.9038 | batch_grapheme_recall=0.8506 | batch_vowel_recall=0.9467 | consonant_recall=0.8774 | grapheme_recall=0.8723 | loss=1.4025 | tar=0.8929 | vowel_recall=0.9496\n",
      "[2020-01-30 23:04:57,407] \n",
      "9/30 * Epoch 9 (train): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=4077.8417 | _timers/batch_time=0.0411 | _timers/data_time=0.0133 | _timers/model_time=0.0255 | batch_consonant_recall=0.5498 | batch_grapheme_recall=0.3545 | batch_vowel_recall=0.5255 | consonant_recall=0.5030 | grapheme_recall=0.3697 | loss=3.9988 | tar=0.4407 | vowel_recall=0.5203\n",
      "9/30 * Epoch 9 (valid): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=2969.0675 | _timers/batch_time=0.1148 | _timers/data_time=0.0992 | _timers/model_time=0.0155 | batch_consonant_recall=0.8918 | batch_grapheme_recall=0.8555 | batch_vowel_recall=0.9325 | consonant_recall=0.8669 | grapheme_recall=0.8755 | loss=1.4247 | tar=0.8881 | vowel_recall=0.9345\n",
      "[2020-01-30 23:11:19,593] \n",
      "10/30 * Epoch 10 (train): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=4046.7056 | _timers/batch_time=0.0397 | _timers/data_time=0.0109 | _timers/model_time=0.0264 | batch_consonant_recall=0.5507 | batch_grapheme_recall=0.3573 | batch_vowel_recall=0.5273 | consonant_recall=0.4985 | grapheme_recall=0.3734 | loss=3.9713 | tar=0.4419 | vowel_recall=0.5225\n",
      "10/30 * Epoch 10 (valid): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=2464.0477 | _timers/batch_time=0.1144 | _timers/data_time=0.0986 | _timers/model_time=0.0157 | batch_consonant_recall=0.8912 | batch_grapheme_recall=0.8554 | batch_vowel_recall=0.9380 | consonant_recall=0.8613 | grapheme_recall=0.8758 | loss=1.4341 | tar=0.8882 | vowel_recall=0.9398\n",
      "[2020-01-30 23:17:38,896] \n",
      "11/30 * Epoch 11 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=4071.1171 | _timers/batch_time=0.0383 | _timers/data_time=0.0094 | _timers/model_time=0.0264 | batch_consonant_recall=0.5487 | batch_grapheme_recall=0.3555 | batch_vowel_recall=0.5273 | consonant_recall=0.5010 | grapheme_recall=0.3700 | loss=3.9700 | tar=0.4414 | vowel_recall=0.5245\n",
      "11/30 * Epoch 11 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2592.0912 | _timers/batch_time=0.1109 | _timers/data_time=0.0957 | _timers/model_time=0.0152 | batch_consonant_recall=0.8804 | batch_grapheme_recall=0.8578 | batch_vowel_recall=0.9413 | consonant_recall=0.8451 | grapheme_recall=0.8776 | loss=1.4227 | tar=0.8859 | vowel_recall=0.9432\n",
      "[2020-01-30 23:24:01,247] \n",
      "12/30 * Epoch 12 (train): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=3969.3603 | _timers/batch_time=0.0403 | _timers/data_time=0.0113 | _timers/model_time=0.0265 | batch_consonant_recall=0.5380 | batch_grapheme_recall=0.3463 | batch_vowel_recall=0.5234 | consonant_recall=0.4899 | grapheme_recall=0.3603 | loss=4.0174 | tar=0.4323 | vowel_recall=0.5188\n",
      "12/30 * Epoch 12 (valid): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=3162.8726 | _timers/batch_time=0.1127 | _timers/data_time=0.0975 | _timers/model_time=0.0151 | batch_consonant_recall=0.8942 | batch_grapheme_recall=0.8570 | batch_vowel_recall=0.9361 | consonant_recall=0.8698 | grapheme_recall=0.8771 | loss=1.4699 | tar=0.8904 | vowel_recall=0.9378\n",
      "[2020-01-30 23:30:20,565] \n",
      "13/30 * Epoch 13 (train): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=4157.1968 | _timers/batch_time=0.0376 | _timers/data_time=0.0092 | _timers/model_time=0.0261 | batch_consonant_recall=0.5431 | batch_grapheme_recall=0.3470 | batch_vowel_recall=0.5239 | consonant_recall=0.4958 | grapheme_recall=0.3620 | loss=3.9991 | tar=0.4349 | vowel_recall=0.5199\n",
      "13/30 * Epoch 13 (valid): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=2864.2116 | _timers/batch_time=0.1132 | _timers/data_time=0.0976 | _timers/model_time=0.0156 | batch_consonant_recall=0.8880 | batch_grapheme_recall=0.8528 | batch_vowel_recall=0.9374 | consonant_recall=0.8580 | grapheme_recall=0.8752 | loss=1.3607 | tar=0.8868 | vowel_recall=0.9389\n",
      "[2020-01-30 23:36:44,906] \n",
      "14/30 * Epoch 14 (train): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=4083.9413 | _timers/batch_time=0.0391 | _timers/data_time=0.0103 | _timers/model_time=0.0263 | batch_consonant_recall=0.5405 | batch_grapheme_recall=0.3350 | batch_vowel_recall=0.5163 | consonant_recall=0.4896 | grapheme_recall=0.3497 | loss=4.0299 | tar=0.4251 | vowel_recall=0.5113\n",
      "14/30 * Epoch 14 (valid): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=3078.2849 | _timers/batch_time=0.1112 | _timers/data_time=0.0954 | _timers/model_time=0.0157 | batch_consonant_recall=0.9037 | batch_grapheme_recall=0.8534 | batch_vowel_recall=0.9391 | consonant_recall=0.8860 | grapheme_recall=0.8768 | loss=1.3368 | tar=0.8956 | vowel_recall=0.9427\n",
      "[2020-01-30 23:43:10,799] \n",
      "15/30 * Epoch 15 (train): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=4258.4469 | _timers/batch_time=0.0377 | _timers/data_time=0.0096 | _timers/model_time=0.0257 | batch_consonant_recall=0.5394 | batch_grapheme_recall=0.3296 | batch_vowel_recall=0.5168 | consonant_recall=0.4890 | grapheme_recall=0.3428 | loss=4.0679 | tar=0.4218 | vowel_recall=0.5124\n",
      "15/30 * Epoch 15 (valid): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=3523.2386 | _timers/batch_time=0.0996 | _timers/data_time=0.0858 | _timers/model_time=0.0137 | batch_consonant_recall=0.9193 | batch_grapheme_recall=0.8558 | batch_vowel_recall=0.9391 | consonant_recall=0.9059 | grapheme_recall=0.8813 | loss=1.3100 | tar=0.9022 | vowel_recall=0.9405\n",
      "[2020-01-30 23:49:19,934] \n",
      "16/30 * Epoch 16 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=5335.1977 | _timers/batch_time=0.0279 | _timers/data_time=0.0039 | _timers/model_time=0.0218 | batch_consonant_recall=0.5356 | batch_grapheme_recall=0.3460 | batch_vowel_recall=0.5199 | consonant_recall=0.4929 | grapheme_recall=0.3611 | loss=4.0013 | tar=0.4330 | vowel_recall=0.5170\n",
      "16/30 * Epoch 16 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=3779.5885 | _timers/batch_time=0.0972 | _timers/data_time=0.0831 | _timers/model_time=0.0140 | batch_consonant_recall=0.9254 | batch_grapheme_recall=0.8648 | batch_vowel_recall=0.9529 | consonant_recall=0.9118 | grapheme_recall=0.8908 | loss=1.0802 | tar=0.9122 | vowel_recall=0.9555\n",
      "[2020-01-30 23:55:27,469] \n",
      "17/30 * Epoch 17 (train): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=5269.6400 | _timers/batch_time=0.0284 | _timers/data_time=0.0041 | _timers/model_time=0.0219 | batch_consonant_recall=0.5286 | batch_grapheme_recall=0.3422 | batch_vowel_recall=0.5191 | consonant_recall=0.4796 | grapheme_recall=0.3579 | loss=4.0670 | tar=0.4278 | vowel_recall=0.5157\n",
      "17/30 * Epoch 17 (valid): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=3068.9756 | _timers/batch_time=0.1137 | _timers/data_time=0.0981 | _timers/model_time=0.0155 | batch_consonant_recall=0.9090 | batch_grapheme_recall=0.8524 | batch_vowel_recall=0.9494 | consonant_recall=0.8954 | grapheme_recall=0.8672 | loss=1.6582 | tar=0.8957 | vowel_recall=0.9530\n",
      "[2020-01-31 00:01:50,956] \n",
      "18/30 * Epoch 18 (train): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=3945.3670 | _timers/batch_time=0.0407 | _timers/data_time=0.0123 | _timers/model_time=0.0261 | batch_consonant_recall=0.5317 | batch_grapheme_recall=0.3345 | batch_vowel_recall=0.5132 | consonant_recall=0.4849 | grapheme_recall=0.3508 | loss=4.0358 | tar=0.4238 | vowel_recall=0.5089\n",
      "18/30 * Epoch 18 (valid): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=2881.7620 | _timers/batch_time=0.1136 | _timers/data_time=0.0973 | _timers/model_time=0.0162 | batch_consonant_recall=0.8819 | batch_grapheme_recall=0.8436 | batch_vowel_recall=0.9400 | consonant_recall=0.8401 | grapheme_recall=0.8786 | loss=1.2182 | tar=0.8845 | vowel_recall=0.9405\n",
      "[2020-01-31 00:08:12,270] \n",
      "19/30 * Epoch 19 (train): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=4196.8214 | _timers/batch_time=0.0380 | _timers/data_time=0.0098 | _timers/model_time=0.0258 | batch_consonant_recall=0.5418 | batch_grapheme_recall=0.3602 | batch_vowel_recall=0.5219 | consonant_recall=0.5019 | grapheme_recall=0.3776 | loss=3.9164 | tar=0.4443 | vowel_recall=0.5202\n",
      "19/30 * Epoch 19 (valid): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=3062.1031 | _timers/batch_time=0.1167 | _timers/data_time=0.1003 | _timers/model_time=0.0163 | batch_consonant_recall=0.9325 | batch_grapheme_recall=0.8614 | batch_vowel_recall=0.9382 | consonant_recall=0.9301 | grapheme_recall=0.8847 | loss=1.1981 | tar=0.9092 | vowel_recall=0.9374\n",
      "[2020-01-31 00:14:33,531] \n",
      "20/30 * Epoch 20 (train): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=3933.2511 | _timers/batch_time=0.0407 | _timers/data_time=0.0111 | _timers/model_time=0.0274 | batch_consonant_recall=0.5348 | batch_grapheme_recall=0.3559 | batch_vowel_recall=0.5169 | consonant_recall=0.4903 | grapheme_recall=0.3724 | loss=3.9390 | tar=0.4374 | vowel_recall=0.5143\n",
      "20/30 * Epoch 20 (valid): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=3262.5462 | _timers/batch_time=0.1124 | _timers/data_time=0.0967 | _timers/model_time=0.0157 | batch_consonant_recall=0.8246 | batch_grapheme_recall=0.8458 | batch_vowel_recall=0.9225 | consonant_recall=0.7475 | grapheme_recall=0.8639 | loss=1.3879 | tar=0.8495 | vowel_recall=0.9226\n",
      "[2020-01-31 00:20:53,046] \n",
      "21/30 * Epoch 21 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=4246.8047 | _timers/batch_time=0.0373 | _timers/data_time=0.0097 | _timers/model_time=0.0253 | batch_consonant_recall=0.5351 | batch_grapheme_recall=0.3480 | batch_vowel_recall=0.5189 | consonant_recall=0.4882 | grapheme_recall=0.3651 | loss=3.8705 | tar=0.4336 | vowel_recall=0.5160\n",
      "21/30 * Epoch 21 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3508.7635 | _timers/batch_time=0.1110 | _timers/data_time=0.0957 | _timers/model_time=0.0152 | batch_consonant_recall=0.9113 | batch_grapheme_recall=0.8592 | batch_vowel_recall=0.9545 | consonant_recall=0.8712 | grapheme_recall=0.8787 | loss=0.8157 | tar=0.8967 | vowel_recall=0.9581\n",
      "[2020-01-31 00:27:25,699] \n",
      "22/30 * Epoch 22 (train): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=4016.7565 | _timers/batch_time=0.0424 | _timers/data_time=0.0144 | _timers/model_time=0.0256 | batch_consonant_recall=0.5384 | batch_grapheme_recall=0.3665 | batch_vowel_recall=0.5201 | consonant_recall=0.4947 | grapheme_recall=0.3841 | loss=3.7936 | tar=0.4448 | vowel_recall=0.5162\n",
      "22/30 * Epoch 22 (valid): _base/lr=9.755e-05 | _base/momentum=0.9000 | _timers/_fps=3213.4184 | _timers/batch_time=0.1109 | _timers/data_time=0.0958 | _timers/model_time=0.0151 | batch_consonant_recall=0.9358 | batch_grapheme_recall=0.8657 | batch_vowel_recall=0.9586 | consonant_recall=0.9073 | grapheme_recall=0.8968 | loss=0.7677 | tar=0.9157 | vowel_recall=0.9619\n",
      "[2020-01-31 00:33:56,749] \n",
      "23/30 * Epoch 23 (train): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=3859.2641 | _timers/batch_time=0.0417 | _timers/data_time=0.0123 | _timers/model_time=0.0269 | batch_consonant_recall=0.5480 | batch_grapheme_recall=0.3740 | batch_vowel_recall=0.5260 | consonant_recall=0.5066 | grapheme_recall=0.3912 | loss=3.6604 | tar=0.4532 | vowel_recall=0.5236\n",
      "23/30 * Epoch 23 (valid): _base/lr=9.045e-05 | _base/momentum=0.9000 | _timers/_fps=3077.6490 | _timers/batch_time=0.1131 | _timers/data_time=0.0973 | _timers/model_time=0.0158 | batch_consonant_recall=0.9539 | batch_grapheme_recall=0.8763 | batch_vowel_recall=0.9686 | consonant_recall=0.9403 | grapheme_recall=0.8978 | loss=0.5506 | tar=0.9267 | vowel_recall=0.9710\n",
      "[2020-01-31 00:40:21,038] \n",
      "24/30 * Epoch 24 (train): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=3960.9993 | _timers/batch_time=0.0405 | _timers/data_time=0.0113 | _timers/model_time=0.0268 | batch_consonant_recall=0.5379 | batch_grapheme_recall=0.3770 | batch_vowel_recall=0.5193 | consonant_recall=0.4996 | grapheme_recall=0.3948 | loss=3.6394 | tar=0.4517 | vowel_recall=0.5176\n",
      "24/30 * Epoch 24 (valid): _base/lr=7.939e-05 | _base/momentum=0.9000 | _timers/_fps=3340.1749 | _timers/batch_time=0.1134 | _timers/data_time=0.0971 | _timers/model_time=0.0162 | batch_consonant_recall=0.9012 | batch_grapheme_recall=0.8672 | batch_vowel_recall=0.9580 | consonant_recall=0.8508 | grapheme_recall=0.8861 | loss=0.7829 | tar=0.8960 | vowel_recall=0.9608\n",
      "[2020-01-31 00:46:45,372] \n",
      "25/30 * Epoch 25 (train): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=3898.1389 | _timers/batch_time=0.0416 | _timers/data_time=0.0124 | _timers/model_time=0.0268 | batch_consonant_recall=0.5502 | batch_grapheme_recall=0.3845 | batch_vowel_recall=0.5306 | consonant_recall=0.5143 | grapheme_recall=0.4018 | loss=3.4723 | tar=0.4615 | vowel_recall=0.5280\n",
      "25/30 * Epoch 25 (valid): _base/lr=6.545e-05 | _base/momentum=0.9000 | _timers/_fps=3135.8627 | _timers/batch_time=0.1145 | _timers/data_time=0.0983 | _timers/model_time=0.0161 | batch_consonant_recall=0.9169 | batch_grapheme_recall=0.8795 | batch_vowel_recall=0.9681 | consonant_recall=0.8525 | grapheme_recall=0.8965 | loss=0.5545 | tar=0.9046 | vowel_recall=0.9728\n",
      "[2020-01-31 00:53:18,881] \n",
      "26/30 * Epoch 26 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=3893.0497 | _timers/batch_time=0.0426 | _timers/data_time=0.0139 | _timers/model_time=0.0264 | batch_consonant_recall=0.5478 | batch_grapheme_recall=0.3892 | batch_vowel_recall=0.5265 | consonant_recall=0.5172 | grapheme_recall=0.4094 | loss=3.4392 | tar=0.4649 | vowel_recall=0.5237\n",
      "26/30 * Epoch 26 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=3146.8045 | _timers/batch_time=0.1151 | _timers/data_time=0.0993 | _timers/model_time=0.0157 | batch_consonant_recall=0.9519 | batch_grapheme_recall=0.8936 | batch_vowel_recall=0.9675 | consonant_recall=0.9340 | grapheme_recall=0.9142 | loss=0.6042 | tar=0.9332 | vowel_recall=0.9704\n",
      "[2020-01-31 00:59:52,246] \n",
      "27/30 * Epoch 27 (train): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=3963.0969 | _timers/batch_time=0.0417 | _timers/data_time=0.0128 | _timers/model_time=0.0265 | batch_consonant_recall=0.5446 | batch_grapheme_recall=0.3951 | batch_vowel_recall=0.5254 | consonant_recall=0.5098 | grapheme_recall=0.4135 | loss=3.3696 | tar=0.4651 | vowel_recall=0.5234\n",
      "27/30 * Epoch 27 (valid): _base/lr=3.455e-05 | _base/momentum=0.9000 | _timers/_fps=2718.8881 | _timers/batch_time=0.1157 | _timers/data_time=0.0995 | _timers/model_time=0.0161 | batch_consonant_recall=0.9500 | batch_grapheme_recall=0.8945 | batch_vowel_recall=0.9703 | consonant_recall=0.9325 | grapheme_recall=0.9169 | loss=0.5462 | tar=0.9346 | vowel_recall=0.9722\n",
      "[2020-01-31 01:06:23,462] \n",
      "28/30 * Epoch 28 (train): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=4033.3183 | _timers/batch_time=0.0399 | _timers/data_time=0.0113 | _timers/model_time=0.0261 | batch_consonant_recall=0.5497 | batch_grapheme_recall=0.4008 | batch_vowel_recall=0.5281 | consonant_recall=0.5125 | grapheme_recall=0.4194 | loss=3.2635 | tar=0.4696 | vowel_recall=0.5273\n",
      "28/30 * Epoch 28 (valid): _base/lr=2.061e-05 | _base/momentum=0.9000 | _timers/_fps=2726.1200 | _timers/batch_time=0.1176 | _timers/data_time=0.1015 | _timers/model_time=0.0161 | batch_consonant_recall=0.9568 | batch_grapheme_recall=0.9001 | batch_vowel_recall=0.9743 | consonant_recall=0.9426 | grapheme_recall=0.9246 | loss=0.4438 | tar=0.9421 | vowel_recall=0.9766\n",
      "[2020-01-31 01:12:52,150] \n",
      "29/30 * Epoch 29 (train): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=4167.7294 | _timers/batch_time=0.0384 | _timers/data_time=0.0103 | _timers/model_time=0.0256 | batch_consonant_recall=0.5547 | batch_grapheme_recall=0.4089 | batch_vowel_recall=0.5303 | consonant_recall=0.5222 | grapheme_recall=0.4254 | loss=3.2409 | tar=0.4754 | vowel_recall=0.5285\n",
      "29/30 * Epoch 29 (valid): _base/lr=9.549e-06 | _base/momentum=0.9000 | _timers/_fps=2623.2628 | _timers/batch_time=0.1146 | _timers/data_time=0.0991 | _timers/model_time=0.0154 | batch_consonant_recall=0.9607 | batch_grapheme_recall=0.9053 | batch_vowel_recall=0.9712 | consonant_recall=0.9533 | grapheme_recall=0.9269 | loss=0.5322 | tar=0.9452 | vowel_recall=0.9735\n",
      "[2020-01-31 01:19:09,088] \n",
      "30/30 * Epoch 30 (train): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=4542.5075 | _timers/batch_time=0.0345 | _timers/data_time=0.0074 | _timers/model_time=0.0247 | batch_consonant_recall=0.5551 | batch_grapheme_recall=0.4081 | batch_vowel_recall=0.5269 | consonant_recall=0.5276 | grapheme_recall=0.4262 | loss=3.2131 | tar=0.4765 | vowel_recall=0.5262\n",
      "30/30 * Epoch 30 (valid): _base/lr=2.447e-06 | _base/momentum=0.9000 | _timers/_fps=2947.3074 | _timers/batch_time=0.1053 | _timers/data_time=0.0908 | _timers/model_time=0.0144 | batch_consonant_recall=0.9630 | batch_grapheme_recall=0.9042 | batch_vowel_recall=0.9752 | consonant_recall=0.9532 | grapheme_recall=0.9275 | loss=0.4061 | tar=0.9466 | vowel_recall=0.9783\n",
      "Top best models:\n",
      "output/fold0/checkpoints/train.30.pth\t0.9466\n"
     ]
    }
   ],
   "source": [
    "trn_idx, val_idx = splits[i]\n",
    "\n",
    "print(f\"Fold: {i}\")\n",
    "\n",
    "output_dir = output_base_dir / f\"fold{i}\"\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n",
    "val_df = df.loc[val_idx, :].reset_index(drop=True)\n",
    "data_loaders = {\n",
    "    phase: get_base_loader(\n",
    "        df,\n",
    "        train_images_path,\n",
    "        phase=phase,\n",
    "        size=(config.img_size, config.img_size),\n",
    "        batch_size=config.train.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        transforms=transforms_dict[phase])\n",
    "    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
    "}\n",
    "model = get_model(config)\n",
    "criterion = get_loss(config)\n",
    "optimizer = get_optimizer(model, config)\n",
    "scheduler = get_scheduler(optimizer, config)\n",
    "callbacks = get_callbacks(config)\n",
    "\n",
    "if config.mixup:\n",
    "    callbacks.append(MixupCallback(fields=[\n",
    "        \"images\",\n",
    "    ]))\n",
    "\n",
    "runner = SupervisedRunner(\n",
    "    device=ct.utils.get_device(),\n",
    "    input_key=\"images\",\n",
    "    input_target_key=\"targets\",\n",
    "    output_key=\"logits\")\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=data_loaders,\n",
    "    logdir=output_dir,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=config.train.num_epochs,\n",
    "    callbacks=callbacks,\n",
    "    main_metric=\"tar\",\n",
    "    state_kwargs={\n",
    "        \"batch_consistant_metrics\": False\n",
    "    },\n",
    "    minimize_metric=False,\n",
    "    monitoring_params=None,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhArTZXhDEdO"
   },
   "source": [
    "## Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32PY32ziDEdP"
   },
   "outputs": [],
   "source": [
    "def load_model(config: edict, bin_path: Union[str, Path]):\n",
    "    # config.model.pretrained = None\n",
    "    model = get_model(config)\n",
    "    state_dict = torch.load(bin_path, map_location=get_device())\n",
    "    if \"model_state_dict\" in state_dict.keys():\n",
    "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_F9IDJdDEdS"
   },
   "outputs": [],
   "source": [
    "def macro_average_recall(prediction: np.ndarray, df: pd.DataFrame):\n",
    "    grapheme = recall_score(\n",
    "        prediction[:, 0], df[\"grapheme_root\"].values, average=\"macro\")\n",
    "    vowel = recall_score(\n",
    "        prediction[:, 1], df[\"vowel_diacritic\"].values, average=\"macro\")\n",
    "    consonant = recall_score(\n",
    "        prediction[:, 2], df[\"consonant_diacritic\"].values, average=\"macro\")\n",
    "    return np.average([grapheme, vowel, consonant], weights=[2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPVll_NsDEdV"
   },
   "outputs": [],
   "source": [
    "def inference_loop(model: nn.Module,\n",
    "                   loader: torchdata.DataLoader,\n",
    "                   cls_levels: dict,\n",
    "                   loss_fn: Optional[nn.Module] = None,\n",
    "                   requires_soft=False):\n",
    "    n_grapheme = cls_levels[\"grapheme\"]\n",
    "    n_vowel = cls_levels[\"vowel\"]\n",
    "    n_consonant = cls_levels[\"consonant\"]\n",
    "\n",
    "    dataset_length = len(loader.dataset)\n",
    "    prediction = np.zeros((dataset_length, 3), dtype=np.uint8)\n",
    "    if requires_soft:\n",
    "        soft_prediction = np.zeros(\n",
    "            (dataset_length, n_grapheme + n_vowel + n_consonant),\n",
    "            dtype=np.float32)\n",
    "\n",
    "    batch_size = loader.batch_size\n",
    "    device = get_device()\n",
    "\n",
    "    avg_loss = 0.\n",
    "    model.eval()\n",
    "\n",
    "    targets: Optional[torch.Tensor] = None\n",
    "\n",
    "    for i, batch in enumerate(progress_bar(loader, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            if isinstance(batch, dict):\n",
    "                images = batch[\"images\"].to(device)\n",
    "                targets = batch[\"targets\"].to(device)\n",
    "            else:\n",
    "                images = batch.to(device)\n",
    "                targets = None\n",
    "            pred = model(images).detach()\n",
    "            if loss_fn is not None and targets is not None:\n",
    "                avg_loss += loss_fn(\n",
    "                    pred, batch[\"targets\"].to(device)).item() / len(loader)\n",
    "            head = 0\n",
    "            tail = n_grapheme\n",
    "            pred_grapheme = torch.argmax(\n",
    "                pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "            head = tail\n",
    "            tail = head + n_vowel\n",
    "            pred_vowel = torch.argmax(pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "            head = tail\n",
    "            tail = head + n_consonant\n",
    "            pred_consonant = torch.argmax(\n",
    "                pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "            prediction[i * batch_size:(i + 1) * batch_size, 0] = pred_grapheme\n",
    "            prediction[i * batch_size:(i + 1) * batch_size, 1] = pred_vowel\n",
    "            prediction[i * batch_size:(i + 1) * batch_size, 2] = pred_consonant\n",
    "\n",
    "            if requires_soft:\n",
    "                head = 0\n",
    "                tail = n_grapheme\n",
    "                soft_prediction[i * batch_size:(i + 1) *\n",
    "                                batch_size, head:tail] = F.softmax(\n",
    "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "                head = tail\n",
    "                tail = head + n_vowel\n",
    "                soft_prediction[i * batch_size:(i + 1) *\n",
    "                                batch_size, head:tail] = F.softmax(\n",
    "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "                head = tail\n",
    "                tail = head + n_consonant\n",
    "                soft_prediction[i * batch_size:(i + 1) *\n",
    "                                batch_size, head:tail] = F.softmax(\n",
    "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
    "\n",
    "    return_dict = {\"prediction\": prediction, \"loss\": avg_loss}\n",
    "    if requires_soft:\n",
    "        return_dict[\"soft_prediction\"] = soft_prediction\n",
    "\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hPKIgJnMDEdY",
    "outputId": "0781f57f-5507-4d99-fcc1-9386a9da2f54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.95841\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"output/fold0/checkpoints/best.pth\"\n",
    "model = load_model(config, checkpoint_path)\n",
    "model.to(get_device())\n",
    "loader = data_loaders[\"valid\"]\n",
    "\n",
    "prediction = inference_loop(\n",
    "    model,\n",
    "    loader,\n",
    "    cls_levels,\n",
    "    criterion,\n",
    "    requires_soft=False)\n",
    "score = macro_average_recall(prediction[\"prediction\"], val_df)\n",
    "print(f\"Score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF64LRYqK1l6"
   },
   "outputs": [],
   "source": [
    "!cp output/fold0/checkpoints/best.pth /content/gdrive/My\\ Drive/kaggle-bengali/checkpoints/fold0/resnet34_30epoch_mixup.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf7pT23OU1X1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Resnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
