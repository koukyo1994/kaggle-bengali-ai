{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/koukyo1994/kaggle-bengali-ai/blob/master/Colab_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"33NabMBXKwoL"},"source":["## Dependencies"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"LmEhILX5KwoO"},"outputs":[],"source":["%%sh\n","pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n","pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n","pip install pretrainedmodels==0.7.4 >> /dev/null"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-V8VzSgVKwoT"},"source":["## Integration with Google Drive"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"colab_type":"code","id":"h-lXTjFHKwoU","outputId":"b9e968ab-3e41-435b-bf70-dc4c560fd350"},"outputs":[{"name":"stdout","output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"zfI_vnU9KwoX"},"outputs":[],"source":["%%sh\n","mkdir input\n","cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n","unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n","unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oHYxI6rdKwoa"},"source":["## Libraries"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"1JJVr1fZKwob","outputId":"fe9a1ffc-5169-48f7-ff00-38a019839863"},"outputs":[{"name":"stderr","output_type":"stream","text":["alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"]}],"source":["import albumentations as A\n","import catalyst as ct\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import pretrainedmodels\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as torchdata\n","import yaml\n","\n","from pathlib import Path\n","from typing import Tuple, Dict, Union, Optional, List\n","\n","from catalyst.dl import SupervisedRunner\n","from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n","from easydict import EasyDict as edict\n","from efficientnet_pytorch import EfficientNet\n","from skimage.transform import AffineTransform, warp\n","from sklearn.metrics import recall_score\n","from sklearn.model_selection import KFold, train_test_split\n","from torch.optim import Adam, SGD\n","from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n","                                      CosineAnnealingLR,\n","                                      CosineAnnealingWarmRestarts)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oB0aMP-X4qGe"},"source":["## Settings"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"6HNqP0T_4pyV"},"outputs":[],"source":["i = 0\n","trial = \"cross_entropy_cosine\""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"USmf2YqUKwoe"},"source":["## Config"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"mzqNckioKwof"},"outputs":[],"source":["conf_string = '''\n","dataset:\n","  train:\n","    affine: True\n","    morphology: False\n","  val:\n","    affine: False\n","    morphology: False\n","  test:\n","    affine: False\n","    morphology: False\n","\n","data:\n","  train_df_path: input/bengaliai-cv19/train.csv\n","  train_images_path: input/bengaliai-cv19/train_images\n","  test_images_path: input/bengaliai-cv19/test_images\n","  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n","\n","model:\n","  model_name: se_resnext50_32x4d\n","  pretrained: imagenet\n","  num_classes: 186\n","\n","train:\n","  batch_size: 32\n","  num_epochs: 10\n","\n","test:\n","  batch_size: 32\n","\n","loss:\n","  name: cross_entropy\n","  params:\n","    n_grapheme: 168\n","    n_vowel: 11\n","    n_consonant: 7\n","\n","optimizer:\n","  name: Adam\n","  params:\n","    lr: 0.001\n","\n","scheduler:\n","  name: cosine\n","  params:\n","    T_max: 10\n","\n","transforms:\n","  Noise: True\n","  Contrast: True\n","  Cutout:\n","    num_holes: 0\n","\n","val:\n","  name: kfold\n","  params:\n","    random_state: 42\n","    n_splits: 5\n","\n","log_dir: log/\n","num_workers: 2\n","seed: 1213\n","img_size: 64\n","checkpoints: /content/gdrive/My Drive/kaggle-bengali/checkpoints/\n","'''"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"PB2wzOKGKwoj"},"outputs":[],"source":["def _get_default():\n","    cfg = edict()\n","\n","    # dataset\n","    cfg.dataset = edict()\n","    cfg.dataset.train = edict()\n","    cfg.dataset.val = edict()\n","    cfg.dataset.test = edict()\n","    cfg.dataset.train.affine = False\n","    cfg.dataset.train.morphology = False\n","    cfg.dataset.val.affine = False\n","    cfg.dataset.val.morphology = False\n","    cfg.dataset.test.affine = False\n","    cfg.dataset.test.morphology = False\n","\n","    # dataset\n","    cfg.data = edict()\n","\n","    # model\n","    cfg.model = edict()\n","\n","    # train\n","    cfg.train = edict()\n","\n","    # test\n","    cfg.test = edict()\n","\n","    # loss\n","    cfg.loss = edict()\n","    cfg.loss.params = edict()\n","\n","    # optimizer\n","    cfg.optimizer = edict()\n","    cfg.optimizer.params = edict()\n","\n","    # scheduler\n","    cfg.scheduler = edict()\n","    cfg.scheduler.params = edict()\n","\n","    # transforms:\n","    cfg.transforms = edict()\n","    cfg.transforms.HorizontalFlip = False\n","    cfg.transforms.VerticalFlip = False\n","    cfg.transforms.Noise = False\n","    cfg.transforms.Contrast = False\n","    cfg.transforms.Cutout = edict()\n","    cfg.transforms.Cutout.num_holes = 0\n","    cfg.transforms.mean = [0.485, 0.456, 0.406]\n","    cfg.transforms.std = [0.229, 0.224, 0.225]\n","\n","    # val\n","    cfg.val = edict()\n","    cfg.val.params = edict()\n","\n","    return cfg\n","\n","\n","def _merge_config(src: edict, dst: edict):\n","    if not isinstance(src, edict):\n","        return\n","    for k, v in src.items():\n","        if isinstance(v, edict):\n","            _merge_config(src[k], dst[k])\n","        else:\n","            dst[k] = v"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"-eXzDYNKKwol"},"outputs":[],"source":["cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n","config = _get_default()\n","_merge_config(cfg, config)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BDwtD7_qKwoo"},"source":["## Environmental settings"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":63},"colab_type":"code","id":"MvltP9XNKwor","outputId":"8e33ce0a-0ce9-4a6e-b839-79cdedc7b81e"},"outputs":[{"data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["ct.utils.set_global_seed(config.seed)\n","ct.utils.prepare_cudnn(deterministic=True)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"NE-bSL4wKwou"},"outputs":[],"source":["output_base_dir = Path(\"output\")\n","output_base_dir.mkdir(exist_ok=True, parents=True)\n","\n","train_images_path = Path(config.data.train_images_path)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Izzn1pfQKwox"},"source":["## Data and utilities preparation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s2g3_Wh2Kwoy"},"source":["### validation utils"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"4p56BR9OKwoz"},"outputs":[],"source":["def no_fold(df: pd.DataFrame,\n","            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n","    params = config.val.params\n","    idx = np.arange(len(df))\n","    trn_idx, val_idx = train_test_split(idx, **params)\n","    return [(trn_idx, val_idx)]\n","\n","\n","def kfold(df: pd.DataFrame,\n","          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n","    params = config.val.params\n","    kf = KFold(shuffle=True, **params)\n","    splits = list(kf.split(df))\n","    return splits\n","\n","\n","def get_validation(df: pd.DataFrame,\n","                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n","    name: str = config.val.name\n","\n","    func = globals().get(name)\n","    if func is None:\n","        raise NotImplementedError\n","\n","    return func(df, config)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Df7OiqfkKwo1"},"source":["### transforms"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"qer87L9pKwo2"},"outputs":[],"source":["def get_transforms(config: edict):\n","    list_transforms = []\n","    if config.transforms.HorizontalFlip:\n","        list_transforms.append(A.HorizontalFrip())\n","    if config.transforms.VerticalFlip:\n","        list_transforms.append(A.VerticalFlip())\n","    if config.transforms.Noise:\n","        list_transforms.append(\n","            A.OneOf(\n","                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n","    if config.transforms.Contrast:\n","        list_transforms.append(\n","            A.OneOf(\n","                [A.RandomContrast(0.5),\n","                 A.RandomGamma(),\n","                 A.RandomBrightness()],\n","                p=0.5))\n","    if config.transforms.Cutout.num_holes > 0:\n","        list_transforms.append(A.Cutout(**config.Cutout))\n","\n","    list_transforms.append(\n","        A.Normalize(\n","            mean=config.transforms.mean, std=config.transforms.std, p=1))\n","\n","    return A.Compose(list_transforms, p=1.0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"muCpRi55Kwo4"},"source":["### Data Loading"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"zEdk1aCZKwo5"},"outputs":[],"source":"df = pd.read_csv(config.data.train_df_path)\nsplits = get_validation(df, config)\ntransforms = get_transforms(config)\n\ncls_levels = {\n    \"grapheme\": df.grapheme_root.nunique(),\n    \"vowel\": df.vowel_diacritic.nunique(),\n    \"consonant\": df.consonant_diacritic.nunique()\n}"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z7tkhAAjKwo8"},"source":["## Dataset and DataLoader"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"IR70FZllKwo9"},"outputs":[],"source":["def crop_image(image: np.ndarray, threshold=5. / 255.) -> np.ndarray:\n","    assert image.ndim == 2\n","    is_black = image > threshold\n","    is_black_vertical = np.sum(is_black, axis=0) > 0\n","    is_black_horizontal = np.sum(is_black, axis=1) > 0\n","\n","    left = np.argmax(is_black_horizontal)\n","    right = np.argmax(is_black_horizontal[::-1])\n","    top = np.argmax(is_black_vertical)\n","    bottom = np.argmax(is_black_vertical[::-1])\n","    height, width = image.shape\n","    cropped_image = image[left:height - right, top:width - bottom]\n","    return cropped_image\n","\n","\n","def resize(image, size=(128, 128)) -> np.ndarray:\n","    return cv2.resize(image, size)\n","\n","\n","def crop_and_embed(image: np.ndarray, size=(128, 128), threshold=20. / 255.):\n","    cropped = crop_image(image, threshold)\n","    height, width = cropped.shape\n","    aspect_ratio = height / width\n","    embedded = np.zeros(size)\n","    if aspect_ratio > 1.0:\n","        if height > size[0]:\n","            new_height = size[0]\n","            new_width = int(size[0] * 1 / aspect_ratio)\n","            image = resize(cropped, size=(new_width, new_height))\n","\n","            margin = size[1] - new_width\n","            head = margin // 2\n","            embedded[:, head:head + new_width] = image\n","        else:\n","            margin = size[0] - height\n","\n","            new_height = height + np.random.randint(0, margin)\n","            new_width = int(new_height * 1 / aspect_ratio)\n","            image = resize(cropped, size=(new_width, new_height))\n","\n","            margin_height = size[0] - new_height\n","            margin_width = size[1] - new_width\n","\n","            head_height = margin_height // 2\n","            head_width = margin_width // 2\n","            embedded[head_height:head_height +\n","                     new_height, head_width:head_width + new_width] = image\n","    else:\n","        if width > size[1]:\n","            new_width = size[1]\n","            new_height = int(size[1] * aspect_ratio)\n","            image = resize(cropped, size=(new_width, new_height))\n","\n","            margin = size[0] - new_height\n","            head = margin // 2\n","            embedded[head:head + new_height, :] = image\n","        else:\n","            margin = size[1] - width\n","\n","            new_width = width + np.random.randint(0, margin)\n","            new_height = int(new_width * aspect_ratio)\n","            image = resize(cropped, size=(new_width, new_height))\n","\n","            margin_height = size[0] - new_height\n","            margin_width = size[1] - new_width\n","\n","            head_height = margin_height // 2\n","            head_width = margin_width // 2\n","            embedded[head_height:head_height +\n","                     new_height, head_width:head_width + new_width] = image\n","\n","    return embedded\n","\n","\n","def normalize(image: np.ndarray):\n","    if image.ndim == 3:\n","        image = image[:, :, 0]\n","    image = (255 - image).astype(np.float32) / 255.0\n","    return image\n","\n","\n","def to_image(image: np.ndarray):\n","    if image.ndim == 2:\n","        image = np.stack([image, image, image])\n","        image = np.moveaxis(image, 0, -1)\n","    image = (255 - image * 255).astype(np.uint8)\n","    return image\n","\n","\n","def affine_image(image: np.ndarray):\n","    assert image.ndim == 2\n","    min_scale = 0.8\n","    max_scale = 1.2\n","    sx = np.random.uniform(min_scale, max_scale)\n","    sy = np.random.uniform(min_scale, max_scale)\n","\n","    max_rot_angle = 10\n","    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n","\n","    max_shear_angle = 10\n","    shear_angle = np.random.uniform(-max_shear_angle,\n","                                    max_shear_angle) * np.pi / 180.\n","\n","    max_translation = 4\n","    tx = np.random.randint(-max_translation, max_translation)\n","    ty = np.random.randint(-max_translation, max_translation)\n","\n","    tform = AffineTransform(\n","        scale=(sx, sy),\n","        rotation=rot_angle,\n","        shear=shear_angle,\n","        translation=(tx, ty))\n","    transformed_image = warp(image, tform)\n","    return transformed_image\n","\n","\n","def random_erosion_or_dilation(image: np.ndarray):\n","    dice = np.random.randint(0, 3)\n","    if dice == 0:\n","        return image\n","    elif dice == 1:\n","        kernel = np.ones((3, 3), dtype=np.uint8)\n","        return cv2.erode(image, kernel, iterations=1)\n","    else:\n","        kernel = np.ones((3, 3), dtype=np.uint8)\n","        return cv2.dilate(image, kernel, iterations=1)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"0xvp6ssDKwpA"},"outputs":[],"source":["class TrainDataset(torchdata.Dataset):\n","    def __init__(self,\n","                 image_dir: Path,\n","                 df: pd.DataFrame,\n","                 transforms,\n","                 size: Tuple[int, int],\n","                 cls_levels: Dict[str, int] = None,\n","                 affine=True,\n","                 morphology=True,\n","                 onehot=True):\n","        self.df = df\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","        self.size = size\n","        self.onehot = onehot\n","        self.cls_levels = cls_levels\n","        self.affine = affine\n","        self.morphology = morphology\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.df.loc[idx, \"image_id\"]\n","        image_path = self.image_dir / f\"{image_id}.png\"\n","\n","        image = cv2.imread(str(image_path))\n","        image = normalize(image)\n","        image = crop_and_embed(image, size=self.size, threshold=5. / 255.)\n","        if self.affine:\n","            image = affine_image(image)\n","        if self.morphology:\n","            image = random_erosion_or_dilation(image)\n","        image = to_image(image)\n","        if self.transforms is not None:\n","            image = self.transforms(image=image)[\"image\"]\n","        if image.shape[2] == 3:\n","            image = np.moveaxis(image, -1, 0)\n","        grapheme = self.df.loc[idx, \"grapheme_root\"]\n","        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n","        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n","\n","        if self.onehot:\n","            grapheme_levels = self.cls_levels[\"grapheme\"]\n","            vowel_levels = self.cls_levels[\"vowel\"]\n","            consonant_levels = self.cls_levels[\"consonant\"]\n","            total_n_levels = grapheme_levels + vowel_levels + consonant_levels\n","            label = np.zeros(total_n_levels, dtype=np.float32)\n","            label[grapheme] = 1.0\n","            label[grapheme_levels + vowel] = 1.0\n","            label[grapheme_levels + vowel_levels + consonant] = 1.0\n","\n","        else:\n","            label = np.zeros(3, dtype=int)\n","            label[0] = grapheme\n","            label[1] = vowel\n","            label[2] = consonant\n","        return {\"images\": image, \"targets\": label}\n","\n","\n","class TestDataset(torchdata.Dataset):\n","    def __init__(self,\n","                 image_dir: Path,\n","                 df: pd.DataFrame,\n","                 transforms,\n","                 size: Tuple[int, int],\n","                 affine=True,\n","                 morphology=True):\n","        self.image_dir = image_dir\n","        self.df = df\n","        self.transforms = transforms\n","        self.size = size\n","        self.affine = affine\n","        self.morphology = morphology\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.df.loc[idx, \"image_id\"]\n","        image_path = self.image_dir / f\"{image_id}.png\"\n","\n","        image = cv2.imread(image_path)\n","        image = normalize(image)\n","        image = crop_and_embed(image, size=self.size, threshold=5. / 255.)\n","        if self.affine:\n","            image = affine_image(image)\n","        if self.morphology:\n","            image = random_erosion_or_dilation(image)\n","        image = to_image(image)\n","        if self.transforms is not None:\n","            image = self.transforms(image=image)[\"image\"]\n","        if image.shape[2] == 3:\n","            image = np.moveaxis(image, -1, 0)\n","        return image\n","\n","\n","def get_loader(df: pd.DataFrame,\n","               image_dir: Path,\n","               phase: str = \"train\",\n","               size: Tuple[int, int] = (128, 128),\n","               batch_size=256,\n","               num_workers=2,\n","               transforms=None,\n","               cls_levels=None,\n","               affine=True,\n","               morphology=True,\n","               onehot=None):\n","    assert phase in [\"train\", \"valid\", \"test\"]\n","    if phase == \"test\":\n","        dataset = TestDataset(image_dir, df, transforms, size, affine,\n","                              morphology)\n","        is_shuffle = False\n","        drop_last = False\n","    else:\n","        if phase == \"train\":\n","            is_shuffle = True\n","            drop_last = True\n","        else:\n","            is_shuffle = False\n","            drop_last = False\n","        if onehot is not None:\n","            if cls_levels is None:\n","                raise ValueError(\n","                    \"if 'onehot' is set to None, cls_levels must be set\")\n","            else:\n","                dataset = TrainDataset(  # type: ignore\n","                    image_dir,\n","                    df,\n","                    transforms,\n","                    size,\n","                    cls_levels,\n","                    affine=affine,\n","                    morphology=morphology,\n","                    onehot=onehot)\n","        else:\n","            dataset = TrainDataset(  # type: ignore\n","                image_dir,\n","                df,\n","                transforms,\n","                size,\n","                affine=affine,\n","                morphology=morphology)\n","    return torchdata.DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=is_shuffle,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=drop_last)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CRSPrkp_KwpD"},"source":["## Model and Loss"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qt8H0kDqKwpD"},"source":["### Model"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"Ey32J5_BKwpE"},"outputs":[],"source":["class BengaliClassifier(nn.Module):\n","    def __init__(self, model_name: str, num_classes: int, pretrained=True):\n","        super().__init__()\n","        self.model_name = model_name\n","        self.num_classes = num_classes\n","        self.pretrained = pretrained\n","\n","        if \"se_resnext\" in self.model_name:\n","            self.base = getattr(pretrainedmodels,\n","                                self.model_name)(pretrained=pretrained)\n","            self.base.avg_pool = nn.AdaptiveAvgPool2d(1)\n","            self.base.last_linear = nn.Linear(\n","                self.base.last_linear.in_features, self.num_classes)\n","        elif \"resnet\" in self.model_name:\n","            self.base = getattr(pretrainedmodels,\n","                                self.model_name)(pretrained=pretrained)\n","            self.base.avg_pool = nn.AdaptiveAvgPool2d(1)\n","            self.base.fc = nn.Linear(self.base.fc.in_features,\n","                                     self.num_classes)\n","        elif \"efficientnet\" in self.model_name:\n","            if pretrained:\n","                self.base = EfficientNet.from_pretrained(self.model_name)\n","            else:\n","                self.base = EfficientNet.from_name(self.model_name)\n","            self.base._fc = nn.Linear(self.base._fc.in_features,\n","                                      self.num_classes)\n","        else:\n","            raise NotImplementedError\n","\n","    def fresh_params(self):\n","        if \"se_resnext\" in self.model_name:\n","            return self.base.last_linear.parameters()\n","        elif \"resnet\" in self.model_name:\n","            return self.base.fc.parameters()\n","        elif \"efficientnet\" in self.model_name:\n","            return self.base._fc.parameters()\n","        else:\n","            raise NotImplementedError\n","\n","    def base_params(self):\n","        params = []\n","        if \"se_resnext\" in self.model_name:\n","            fc_name = \"last_linear\"\n","        elif \"resnet\" in self.model_name:\n","            fc_name = \"fc\"\n","        elif \"efficientnet\" in self.model_name:\n","            fc_name = \"_fc\"\n","        else:\n","            raise NotImplementedError\n","        for name, param in self.net.named_parameters():\n","            if fc_name not in name:\n","                params.append(param)\n","        return params\n","\n","    def forward(self, x):\n","        return self.base(x)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7yGn8bXpKwpG"},"source":["### Loss"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"fG4H1Z04KwpH"},"outputs":[],"source":["class BengaliCrossEntropyLoss(nn.Module):\n","    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n","        super().__init__()\n","        self.n_grapheme = n_grapheme\n","        self.n_vowel = n_vowel\n","        self.n_consonant = n_consonant\n","        self.cross_entropy = nn.CrossEntropyLoss()\n","\n","    def forward(self, pred, true):\n","        head = 0\n","        tail = self.n_grapheme\n","        grapheme_pred = pred[:, head:tail]\n","        grapheme_true = true[:, 0]\n","\n","        head = tail\n","        tail = head + self.n_vowel\n","        vowel_pred = pred[:, head:tail]\n","        vowel_true = true[:, 1]\n","\n","        head = tail\n","        tail = head + self.n_consonant\n","        consonant_pred = pred[:, head:tail]\n","        consonant_true = true[:, 2]\n","\n","        return self.cross_entropy(grapheme_pred, grapheme_true) + \\\n","            self.cross_entropy(vowel_pred, vowel_true) + \\\n","            self.cross_entropy(consonant_pred, consonant_true)\n","\n","\n","class BengaliBCELoss(nn.Module):\n","    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n","        super().__init__()\n","        self.n_grapheme = n_grapheme\n","        self.n_vowel = n_vowel\n","        self.n_consonant = n_consonant\n","        self.bce = nn.BCEWithLogitsLoss()\n","\n","    def forward(self, pred, true):\n","        head = 0\n","        tail = self.n_grapheme\n","        grapheme_pred = pred[:, head:tail]\n","        grapheme_true = true[:, head:tail]\n","\n","        head = tail\n","        tail = head + self.n_vowel\n","        vowel_pred = pred[:, head:tail]\n","        vowel_true = true[:, head:tail]\n","\n","        head = tail\n","        tail = head + self.n_consonant\n","        consonant_pred = pred[:, head:tail]\n","        consonant_true = true[:, head:tail]\n","\n","        return self.bce(grapheme_pred, grapheme_true) + \\\n","            self.bce(vowel_pred, vowel_true) + \\\n","            self.bce(consonant_pred, consonant_true)\n","\n","\n","def get_loss(config: edict):\n","    name = config.loss.name\n","    params = config.loss.params\n","    if name == \"bce\":\n","        criterion = BengaliBCELoss(**params)\n","    elif name == \"cross_entropy\":\n","        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n","    else:\n","        raise NotImplementedError\n","    return criterion"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6VRL8e21KwpK"},"source":["## Optimizer and Scheduler"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cJiWlNg5KwpK"},"source":["### Optimizer"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"BmBA7SsEKwpL"},"outputs":[],"source":["Optimizer = Union[Adam, SGD]\n","\n","\n","def get_optimizer(model, config: edict) -> Optimizer:\n","    name = config.optimizer.name\n","    params = config.optimizer.params\n","    if name == \"Adam\":\n","        optimizer = Adam(model.parameters(), **params)\n","    elif name == \"SGD\":\n","        optimizer = Adam(model.parameters(), **params)\n","    else:\n","        raise NotImplementedError\n","    return optimizer"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F6UsyO8GKwpO"},"source":["### Scheduler"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"qjotHZyDKwpP"},"outputs":[],"source":["Scheduler = Optional[\n","    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n","\n","\n","def get_scheduler(optimizer, config: edict) -> Scheduler:\n","    params = config.scheduler.params\n","    name = config.scheduler.name\n","    scheduler: Scheduler = None\n","    if name == \"plateau\":\n","        scheduler = ReduceLROnPlateau(optimizer, **params)\n","    elif name == \"cosine\":\n","        scheduler = CosineAnnealingLR(optimizer, **params)\n","    elif name == \"cosine_warmup\":\n","        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n","\n","    return scheduler"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZN_KIlxPKwpR"},"source":["## Callbacks"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"NW3x-uJ6KwpS"},"outputs":[],"source":["class MacroAverageRecall(Callback):\n","    def __init__(self,\n","                 n_grapheme=168,\n","                 n_vowel=11,\n","                 n_consonant=7,\n","                 loss_type: str = \"bce\",\n","                 prefix: str = \"mar\",\n","                 output_key: str = \"logits\",\n","                 target_key: str = \"targets\"):\n","        self.prefix = prefix\n","        self.output_key = output_key\n","        self.target_key = target_key\n","        self.n_grapheme = n_grapheme\n","        self.n_vowel = n_vowel\n","        self.n_consonant = n_consonant\n","        self.loss_type = loss_type\n","        super().__init__(CallbackOrder.Metric)\n","\n","    def on_batch_end(self, state: RunnerState):\n","        targ = state.input[self.target_key].detach()\n","        out = state.output[self.output_key]\n","        head = 0\n","        tail = self.n_grapheme\n","        grapheme = torch.sigmoid(out[:, head:tail])\n","        grapheme_np = torch.argmax(grapheme, dim=1).detach().cpu().numpy()\n","        if self.loss_type == \"bce\":\n","            grapheme_target = torch.argmax(\n","                targ[:, head:tail], dim=1).cpu().numpy()\n","        else:\n","            grapheme_target = targ[:, 0].cpu().numpy()\n","\n","        head = tail\n","        tail = head + self.n_vowel\n","        vowel = torch.sigmoid(out[:, head:tail])\n","        vowel_np = torch.argmax(vowel, dim=1).detach().cpu().numpy()\n","        if self.loss_type == \"bce\":\n","            vowel_target = torch.argmax(\n","                targ[:, head:tail], dim=1).cpu().numpy()\n","        else:\n","            vowel_target = targ[:, 1].cpu().numpy()\n","\n","        head = tail\n","        tail = head + self.n_consonant\n","        consonant = torch.sigmoid(out[:, head:tail])\n","        consonant_np = torch.argmax(consonant, dim=1).detach().cpu().numpy()\n","        if self.loss_type == \"bce\":\n","            consonant_target = torch.argmax(\n","                targ[:, head:tail], dim=1).cpu().numpy()\n","        else:\n","            consonant_target = targ[:, 2].cpu().numpy()\n","\n","        scores = []\n","        scores.append(\n","            recall_score(\n","                grapheme_target, grapheme_np, average=\"macro\",\n","                zero_division=0))\n","        scores.append(\n","            recall_score(\n","                vowel_target, vowel_np, average=\"macro\", zero_division=0))\n","        scores.append(\n","            recall_score(\n","                consonant_target,\n","                consonant_np,\n","                average=\"macro\",\n","                zero_division=0))\n","        final_score = np.average(scores, weights=[2, 1, 1])\n","        state.metrics.add_batch_value(name=self.prefix, value=final_score)\n","\n","\n","class SaveWeightsCallback(Callback):\n","    def __init__(self, to: Optional[Path] = None, name: str=\"\"):\n","        self.to = to\n","        self.name = name\n","        super().__init__(CallbackOrder.External)\n","\n","    def on_epoch_end(self, state: RunnerState):\n","        weights = state.model.state_dict()\n","        logdir = state.logdir / \"checkpoints\"\n","        logdir.mkdir(exist_ok=True, parents=True)\n","        if self.name == \"\":\n","            torch.save(weights, logdir / \"temp.pth\")\n","        else:\n","            torch.save(weights, logdir / f\"{self.name}.pth\")\n","\n","        if self.to is not None:\n","            if self.name == \"\":\n","                torch.save(weights, self.to / \"temp.pth\")\n","            else:\n","                torch.save(weights, self.to / f\"{self.name}.pth\")"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-HN1iGwXKwpU"},"source":["## KFold Training"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"colab_type":"code","id":"osNWYzH_KwpV","outputId":"cc87388d-a066-4924-ce9f-ef81e65f1269"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold: 0\n","[2020-01-28 11:10:06,804] \n","1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1015.2071 | _timers/batch_time=0.0317 | _timers/data_time=0.0009 | _timers/model_time=0.0308 | loss=2.6039 | mar=0.5959\n","1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=671.0545 | _timers/batch_time=0.0533 | _timers/data_time=0.0102 | _timers/model_time=0.0430 | loss=1.2327 | mar=0.7596\n","[2020-01-28 11:21:45,072] \n","2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1049.8069 | _timers/batch_time=0.0307 | _timers/data_time=0.0009 | _timers/model_time=0.0298 | loss=1.3010 | mar=0.7560\n","2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=675.5815 | _timers/batch_time=0.0526 | _timers/data_time=0.0101 | _timers/model_time=0.0424 | loss=0.9173 | mar=0.8202\n","[2020-01-28 11:33:21,138] \n","3/10 * Epoch 3 (train): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=1059.2512 | _timers/batch_time=0.0306 | _timers/data_time=0.0010 | _timers/model_time=0.0296 | loss=1.0352 | mar=0.7991\n","3/10 * Epoch 3 (valid): _base/lr=0.0009 | _base/momentum=0.9000 | _timers/_fps=690.3608 | _timers/batch_time=0.0531 | _timers/data_time=0.0125 | _timers/model_time=0.0405 | loss=0.7737 | mar=0.8558\n","[2020-01-28 11:44:59,626] \n","4/10 * Epoch 4 (train): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=1052.1415 | _timers/batch_time=0.0307 | _timers/data_time=0.0008 | _timers/model_time=0.0298 | loss=0.8673 | mar=0.8273\n","4/10 * Epoch 4 (valid): _base/lr=0.0008 | _base/momentum=0.9000 | _timers/_fps=686.7187 | _timers/batch_time=0.0532 | _timers/data_time=0.0126 | _timers/model_time=0.0406 | loss=0.6803 | mar=0.8671\n","[2020-01-28 11:56:34,547] \n","5/10 * Epoch 5 (train): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=1057.3400 | _timers/batch_time=0.0305 | _timers/data_time=0.0008 | _timers/model_time=0.0297 | loss=0.7364 | mar=0.8511\n","5/10 * Epoch 5 (valid): _base/lr=0.0007 | _base/momentum=0.9000 | _timers/_fps=702.7512 | _timers/batch_time=0.0527 | _timers/data_time=0.0128 | _timers/model_time=0.0398 | loss=0.5528 | mar=0.8899\n","[2020-01-28 12:08:11,676] \n","6/10 * Epoch 6 (train): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=1063.7071 | _timers/batch_time=0.0303 | _timers/data_time=0.0008 | _timers/model_time=0.0295 | loss=0.6294 | mar=0.8708\n","6/10 * Epoch 6 (valid): _base/lr=0.0005 | _base/momentum=0.9000 | _timers/_fps=698.9324 | _timers/batch_time=0.0529 | _timers/data_time=0.0130 | _timers/model_time=0.0398 | loss=0.5085 | mar=0.8971\n","[2020-01-28 12:19:44,527] \n","7/10 * Epoch 7 (train): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=1062.4910 | _timers/batch_time=0.0304 | _timers/data_time=0.0008 | _timers/model_time=0.0295 | loss=0.5408 | mar=0.8865\n","7/10 * Epoch 7 (valid): _base/lr=0.0003 | _base/momentum=0.9000 | _timers/_fps=695.3971 | _timers/batch_time=0.0523 | _timers/data_time=0.0118 | _timers/model_time=0.0404 | loss=0.4579 | mar=0.9069\n","[2020-01-28 12:31:14,417] \n","8/10 * Epoch 8 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=1072.4821 | _timers/batch_time=0.0301 | _timers/data_time=0.0008 | _timers/model_time=0.0293 | loss=0.4626 | mar=0.9009\n","8/10 * Epoch 8 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=702.7249 | _timers/batch_time=0.0530 | _timers/data_time=0.0132 | _timers/model_time=0.0397 | loss=0.4303 | mar=0.9127\n","[2020-01-28 12:42:45,392] \n","9/10 * Epoch 9 (train): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=1066.4800 | _timers/batch_time=0.0303 | _timers/data_time=0.0008 | _timers/model_time=0.0294 | loss=0.4107 | mar=0.9112\n","9/10 * Epoch 9 (valid): _base/lr=9.549e-05 | _base/momentum=0.9000 | _timers/_fps=688.4300 | _timers/batch_time=0.0528 | _timers/data_time=0.0112 | _timers/model_time=0.0415 | loss=0.3953 | mar=0.9210\n","[2020-01-28 12:54:15,767] \n","10/10 * Epoch 10 (train): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=1067.9404 | _timers/batch_time=0.0302 | _timers/data_time=0.0008 | _timers/model_time=0.0294 | loss=0.3770 | mar=0.9175\n","10/10 * Epoch 10 (valid): _base/lr=2.447e-05 | _base/momentum=0.9000 | _timers/_fps=684.8119 | _timers/batch_time=0.0525 | _timers/data_time=0.0104 | _timers/model_time=0.0420 | loss=0.3866 | mar=0.9223\n","Top best models:\n","output/fold0/checkpoints/train.10.pth\t0.9223\n"]}],"source":["trn_idx, val_idx = splits[i]\n","\n","print(f\"Fold: {i}\")\n","\n","output_dir = output_base_dir / f\"fold{i}\"\n","output_dir.mkdir(exist_ok=True, parents=True)\n","\n","trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n","val_df = df.loc[val_idx, :].reset_index(drop=True)\n","data_loaders = {\n","    phase: get_loader(\n","        df,\n","        train_images_path,\n","        phase=phase,\n","        size=(config.img_size, config.img_size),\n","        batch_size=config.train.batch_size,\n","        num_workers=config.num_workers,\n","        transforms=transforms,\n","        cls_levels=cls_levels,\n","        affine=config.dataset.train.affine\n","        if phase == \"train\" else config.dataset.val.affine,\n","        morphology=config.dataset.train.morphology\n","        if phase == \"train\" else config.dataset.val.morphology,\n","        onehot=config.loss.name == \"bce\")\n","    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n","}\n","model = BengaliClassifier(**config.model)\n","criterion = get_loss(config)\n","optimizer = get_optimizer(model, config)\n","scheduler = get_scheduler(optimizer, config)\n","callbacks = [\n","    MacroAverageRecall(\n","        n_grapheme=cls_levels[\"grapheme\"],\n","        n_vowel=cls_levels[\"vowel\"],\n","        n_consonant=cls_levels[\"consonant\"],\n","        loss_type=config.loss.name),\n","    SaveWeightsCallback(\n","        to=Path(config.checkpoints\n","                ) if config.checkpoints is not None else None,\n","        name=trial)\n","]\n","\n","runner = SupervisedRunner(\n","    device=ct.utils.get_device(),\n","    input_key=\"images\",\n","    input_target_key=\"targets\",\n","    output_key=\"logits\")\n","runner.train(\n","    model=model,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    loaders=data_loaders,\n","    logdir=output_dir,\n","    scheduler=scheduler,\n","    num_epochs=config.train.num_epochs,\n","    callbacks=callbacks,\n","    main_metric=\"mar\",\n","    minimize_metric=False,\n","    monitoring_params=None,\n","    verbose=False)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"tTukaQrzNW8T"},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}