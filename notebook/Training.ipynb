{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "facf27d6089b42a99b56b67fa4b806f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acda58fbfd0a42bdac475382915e17fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b94a6ad15aa41199d5c70fd13580f05",
              "IPY_MODEL_19e4131392d2460eaa95685fae05635e"
            ]
          }
        },
        "acda58fbfd0a42bdac475382915e17fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b94a6ad15aa41199d5c70fd13580f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd01af70424f46b28a3915ce99e41f7c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b48a359b8e549349925f03d41397538"
          }
        },
        "19e4131392d2460eaa95685fae05635e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9909548a71fe4e109a0df41b6c50a084",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [08:37&lt;00:00, 169kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6d83802234e431aaa43717748ad2b4a"
          }
        },
        "fd01af70424f46b28a3915ce99e41f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b48a359b8e549349925f03d41397538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9909548a71fe4e109a0df41b6c50a084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6d83802234e431aaa43717748ad2b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koukyo1994/kaggle-bengali-ai/blob/master/notebook/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H-LYW6ekKQ-x"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QyICnC_QKQ-0",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n",
        "pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n",
        "pip install pretrainedmodels==0.7.4 >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2m_PlwpKQ-5"
      },
      "source": [
        "## Integration with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jsPLSeVuKQ-6",
        "outputId": "34469882-1b2d-4a72-dfea-aad20c9da51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a3FN8jiWKQ--",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "mkdir input\n",
        "cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24Iv5BnEKQ_B"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrCK0t6KQ_C",
        "outputId": "e3c88d17-deb0-4635-ac67-1b055de32dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import albumentations as A\n",
        "import catalyst as ct\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pretrainedmodels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as torchdata\n",
        "import torchvision.models as models\n",
        "import yaml\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Union, Optional, List\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
        "from catalyst.dl.callbacks import CriterionCallback\n",
        "from catalyst.utils import get_device\n",
        "from easydict import EasyDict as edict\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from fastprogress import progress_bar\n",
        "from skimage.transform import AffineTransform, warp\n",
        "from sklearn.metrics import recall_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n",
        "                                      CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tszhN7oGKQ_H"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dqfUxJd6KQ_I",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "trial = \"resnet34_size128_　70epoch_weighted_loss_mixup\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dXUZcRAGKQ_L"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S16TliO4KQ_M",
        "colab": {}
      },
      "source": [
        "conf_string = '''\n",
        "dataset:\n",
        "  train:\n",
        "    affine: True\n",
        "    morphology: False\n",
        "  val:\n",
        "    affine: False\n",
        "    morphology: False\n",
        "  test:\n",
        "    affine: False\n",
        "    morphology: False\n",
        "\n",
        "data:\n",
        "  train_df_path: input/bengaliai-cv19/train.csv\n",
        "  train_images_path: input/bengaliai-cv19/train_images\n",
        "  test_images_path: input/bengaliai-cv19/test_images\n",
        "  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n",
        "\n",
        "model:\n",
        "  model_name: resnet34\n",
        "  pretrained: imagenet\n",
        "  num_classes: 186\n",
        "  head: custom\n",
        "  in_channels: 3\n",
        "\n",
        "train:\n",
        "  batch_size: 128\n",
        "  num_epochs: 70\n",
        "\n",
        "test:\n",
        "  batch_size: 128\n",
        "\n",
        "loss:\n",
        "  name: cross_entropy\n",
        "  params:\n",
        "    n_grapheme: 168\n",
        "    n_vowel: 11\n",
        "    n_consonant: 7\n",
        "    weights:\n",
        "      - 2.0\n",
        "      - 1.0\n",
        "      - 1.0\n",
        "\n",
        "optimizer:\n",
        "  name: Adam\n",
        "  params:\n",
        "    lr: 0.0001\n",
        "\n",
        "scheduler:\n",
        "  name: cosine\n",
        "  params:\n",
        "    T_max: 10\n",
        "\n",
        "transforms:\n",
        "  train:\n",
        "    Noise: False\n",
        "    Contrast: False\n",
        "    Rotate: True\n",
        "    RandomScale: True\n",
        "    Cutout:\n",
        "      num_holes: 0\n",
        "  val:\n",
        "    Noise: False\n",
        "    Contrast: False\n",
        "    Rotate: False\n",
        "    RandomScale: False\n",
        "    Cutout:\n",
        "      num_holes: 0\n",
        "  test:\n",
        "    Noise: False\n",
        "    Contrast: False\n",
        "    Rotate: False\n",
        "    RandomScale: False\n",
        "    Cutout:\n",
        "      num_holes: 0\n",
        "\n",
        "val:\n",
        "  name: kfold\n",
        "  params:\n",
        "    random_state: 42\n",
        "    n_splits: 5\n",
        "\n",
        "callbacks:\n",
        "  - AverageRecall:\n",
        "      index: 0\n",
        "      offset: 0\n",
        "      n_classes: 168\n",
        "      prefix: grapheme_recall\n",
        "      loss_type: cross_entroy\n",
        "  - AverageRecall:\n",
        "      index: 1\n",
        "      offset: 168\n",
        "      n_classes: 11\n",
        "      prefix: vowel_recall\n",
        "      loss_type: cross_entropy\n",
        "  - AverageRecall:\n",
        "      index: 2\n",
        "      offset: 179\n",
        "      n_classes: 7\n",
        "      prefix: consonant_recall\n",
        "      loss_type: cross_entropy\n",
        "  - TotalAverageRecall:\n",
        "      loss_type: cross_entropy\n",
        "  - SaveWeightsCallback:\n",
        "      to: /content/gdrive/My Drive/kaggle-bengali/checkpoints/fold{}/\n",
        "      name: {}\n",
        "      is_larger_better: True\n",
        "      main_metric: tar\n",
        "  - MixupOrCutmixCallback:\n",
        "      mixup_prob: 0.5\n",
        "      cutmix_prob: 0.0\n",
        "\n",
        "log_dir: log/\n",
        "num_workers: 2\n",
        "seed: 1213\n",
        "img_size: 128\n",
        "weights: /content/gdrive/My Drive/kaggle-bengali/checkpoints/fold0/resnet34_size128_　70epoch_weighted_loss_mixup.pth\n",
        "'''.format(i, trial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "piePmxjjKQ_P",
        "colab": {}
      },
      "source": [
        "def _get_default():\n",
        "    cfg = edict()\n",
        "\n",
        "    # dataset\n",
        "    cfg.dataset = edict()\n",
        "    cfg.dataset.train = edict()\n",
        "    cfg.dataset.val = edict()\n",
        "    cfg.dataset.test = edict()\n",
        "    cfg.dataset.train.affine = False\n",
        "    cfg.dataset.train.morphology = False\n",
        "    cfg.dataset.val.affine = False\n",
        "    cfg.dataset.val.morphology = False\n",
        "    cfg.dataset.test.affine = False\n",
        "    cfg.dataset.test.morphology = False\n",
        "\n",
        "    # dataset\n",
        "    cfg.data = edict()\n",
        "\n",
        "    # model\n",
        "    cfg.model = edict()\n",
        "    cfg.model.model_name = \"resnet18\"\n",
        "    cfg.model.num_classes = 186\n",
        "    cfg.model.pretrained = True\n",
        "    cfg.model.head = \"linear\"\n",
        "    cfg.model.in_channels = 3\n",
        "\n",
        "    # train\n",
        "    cfg.train = edict()\n",
        "\n",
        "    # test\n",
        "    cfg.test = edict()\n",
        "\n",
        "    # loss\n",
        "    cfg.loss = edict()\n",
        "    cfg.loss.params = edict()\n",
        "\n",
        "    # optimizer\n",
        "    cfg.optimizer = edict()\n",
        "    cfg.optimizer.params = edict()\n",
        "\n",
        "    # scheduler\n",
        "    cfg.scheduler = edict()\n",
        "    cfg.scheduler.params = edict()\n",
        "\n",
        "    # transforms:\n",
        "    cfg.transforms = edict()\n",
        "    cfg.transforms.train = edict()\n",
        "    cfg.transforms.train.HorizontalFlip = False\n",
        "    cfg.transforms.train.VerticalFlip = False\n",
        "    cfg.transforms.train.Noise = False\n",
        "    cfg.transforms.train.Contrast = False\n",
        "    cfg.transforms.train.Rotate = False\n",
        "    cfg.transforms.train.RandomScale = False\n",
        "    cfg.transforms.train.Cutout = edict()\n",
        "    cfg.transforms.train.Cutout.num_holes = 0\n",
        "    cfg.transforms.val = edict()\n",
        "    cfg.transforms.val.HorizontalFlip = False\n",
        "    cfg.transforms.val.VerticalFlip = False\n",
        "    cfg.transforms.val.Noise = False\n",
        "    cfg.transforms.val.Contrast = False\n",
        "    cfg.transforms.val.Rotate = False\n",
        "    cfg.transforms.val.RandomScale = False\n",
        "    cfg.transforms.val.Cutout = edict()\n",
        "    cfg.transforms.val.Cutout.num_holes = 0\n",
        "    cfg.transforms.test = edict()\n",
        "    cfg.transforms.test.HorizontalFlip = False\n",
        "    cfg.transforms.test.VerticalFlip = False\n",
        "    cfg.transforms.test.Noise = False\n",
        "    cfg.transforms.test.Contrast = False\n",
        "    cfg.transforms.test.Rotate = False\n",
        "    cfg.transforms.test.RandomScale = False\n",
        "    cfg.transforms.test.Cutout = edict()\n",
        "    cfg.transforms.test.Cutout.num_holes = 0\n",
        "    cfg.transforms.mean = [0.485, 0.456, 0.406]\n",
        "    cfg.transforms.std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # val\n",
        "    cfg.val = edict()\n",
        "    cfg.val.params = edict()\n",
        "\n",
        "    cfg.callbacks = []\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def _merge_config(src: edict, dst: edict):\n",
        "    if not isinstance(src, edict):\n",
        "        return\n",
        "    for k, v in src.items():\n",
        "        if isinstance(v, edict):\n",
        "            _merge_config(src[k], dst[k])\n",
        "        else:\n",
        "            dst[k] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DOq2Hol4KQ_S",
        "colab": {}
      },
      "source": [
        "cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n",
        "config = _get_default()\n",
        "_merge_config(cfg, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iinSUuVEKQ_V"
      },
      "source": [
        "## Environmental settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mo5V5VT5KQ_W",
        "outputId": "4ad7cc22-c2a3-48ff-f450-98a69a2fc25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "ct.utils.set_global_seed(config.seed)\n",
        "ct.utils.prepare_cudnn(deterministic=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EHv73-KuKQ_Y",
        "colab": {}
      },
      "source": [
        "output_base_dir = Path(\"output\")\n",
        "output_base_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_images_path = Path(config.data.train_images_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nowCCU9GKQ_b",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Data and utilities preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hAy9mKC1KQ_c"
      },
      "source": [
        "### validation utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38wcJQJEKQ_c",
        "colab": {}
      },
      "source": [
        "def no_fold(df: pd.DataFrame,\n",
        "            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    idx = np.arange(len(df))\n",
        "    trn_idx, val_idx = train_test_split(idx, **params)\n",
        "    return [(trn_idx, val_idx)]\n",
        "\n",
        "\n",
        "def kfold(df: pd.DataFrame,\n",
        "          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    kf = KFold(shuffle=True, **params)\n",
        "    splits = list(kf.split(df))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def get_validation(df: pd.DataFrame,\n",
        "                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    name: str = config.val.name\n",
        "\n",
        "    func = globals().get(name)\n",
        "    if func is None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return func(df, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xE5iD2HAKQ_f"
      },
      "source": [
        "### transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvCvJ5ScKQ_f",
        "colab": {}
      },
      "source": [
        "def get_transforms(config: edict, phase: str = \"train\"):\n",
        "    assert phase in [\"train\", \"valid\", \"test\"]\n",
        "    if phase == \"train\":\n",
        "        cfg = config.transforms.train\n",
        "    elif phase == \"valid\":\n",
        "        cfg = config.transforms.val\n",
        "    elif phase == \"test\":\n",
        "        cfg = config.transforms.test\n",
        "    list_transforms = []\n",
        "    if cfg.HorizontalFlip:\n",
        "        list_transforms.append(A.HorizontalFrip())\n",
        "    if cfg.VerticalFlip:\n",
        "        list_transforms.append(A.VerticalFlip())\n",
        "    if cfg.Rotate:\n",
        "        list_transforms.append(A.Rotate(limit=15))\n",
        "    if cfg.RandomScale:\n",
        "        list_transforms.append(A.RandomScale())\n",
        "    if cfg.Noise:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n",
        "    if cfg.Contrast:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.RandomContrast(0.5),\n",
        "                 A.RandomGamma(),\n",
        "                 A.RandomBrightness()],\n",
        "                p=0.5))\n",
        "    if cfg.Cutout.num_holes > 0:\n",
        "        list_transforms.append(A.Cutout(**cfg.Cutout))\n",
        "\n",
        "    list_transforms.append(\n",
        "        A.Normalize(\n",
        "            mean=config.transforms.mean,\n",
        "            std=config.transforms.std,\n",
        "            p=1,\n",
        "            always_apply=True))\n",
        "\n",
        "    return A.Compose(list_transforms, p=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5mQCOAtuLtV3"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GdTnGd0aLu-8",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(config.data.train_df_path)\n",
        "splits = get_validation(df, config)\n",
        "\n",
        "transforms_dict = {\n",
        "    phase: get_transforms(config, phase)\n",
        "    for phase in [\"train\", \"valid\"]\n",
        "}\n",
        "\n",
        "cls_levels = {\n",
        "    \"grapheme\": df.grapheme_root.nunique(),\n",
        "    \"vowel\": df.vowel_diacritic.nunique(),\n",
        "    \"consonant\": df.consonant_diacritic.nunique()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k3X2245OKQ_j"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hj6MHrqXKQ_j",
        "colab": {}
      },
      "source": [
        "class BaseDataset(torchdata.Dataset):\n",
        "    def __init__(self, image_dir: Path, df: pd.DataFrame, transforms,\n",
        "                 size: Tuple[int, int]):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.size = size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df.loc[idx, \"image_id\"]\n",
        "        image_path = self.image_dir / f\"{image_id}.png\"\n",
        "\n",
        "        image = cv2.imread(str(image_path))\n",
        "        longer_side = image.shape[1]\n",
        "        if image.ndim == 2:\n",
        "            new_image = np.ones(\n",
        "                (longer_side, longer_side), dtype=np.uint8) * 255\n",
        "        else:\n",
        "            new_image = np.ones(\n",
        "                (longer_side, longer_side, 3), dtype=np.uint8) * 255\n",
        "        offset = np.random.randint(0, longer_side - image.shape[0])\n",
        "        new_image[offset:offset + image.shape[0], :] = image\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=new_image)[\"image\"]\n",
        "        image = cv2.resize(image, self.size)\n",
        "        if image.shape[2] == 3:\n",
        "            image = np.moveaxis(image, -1, 0)\n",
        "        grapheme = self.df.loc[idx, \"grapheme_root\"]\n",
        "        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n",
        "        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n",
        "        label = np.zeros(3, dtype=int)\n",
        "        label[0] = grapheme\n",
        "        label[1] = vowel\n",
        "        label[2] = consonant\n",
        "        return {\"images\": image, \"targets\": label}\n",
        "    \n",
        "    \n",
        "def get_base_loader(df: pd.DataFrame,\n",
        "                    image_dir: Path,\n",
        "                    phase: str = \"train\",\n",
        "                    size: Tuple[int, int] = (128, 128),\n",
        "                    batch_size=256,\n",
        "                    num_workers=2,\n",
        "                    transforms=None):\n",
        "    assert phase in [\"train\", \"valid\"]\n",
        "    if phase == \"train\":\n",
        "        is_shuffle = True\n",
        "        drop_last = True\n",
        "    else:\n",
        "        is_shuffle = False\n",
        "        drop_last = False\n",
        "\n",
        "    dataset = BaseDataset(  # type: ignore\n",
        "        image_dir, df, transforms, size)\n",
        "    return torchdata.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=drop_last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yc6F3Pu5KQ_m",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Model and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PjBhyu98KQ_n"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wABhZZ9LKQ_o",
        "colab": {}
      },
      "source": [
        "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
        "    return F.avg_pool2d(x.clamp(min=eps).pow(p),\n",
        "                        (x.size(-2), x.size(-1))).pow(1. / p)\n",
        "\n",
        "\n",
        "def mish(input):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    See additional documentation for mish class.\n",
        "    '''\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "    Examples:\n",
        "        >>> m = Mish()\n",
        "        >>> input = torch.randn(2)\n",
        "        >>> output = m(input)\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Init method.\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Forward pass of the function.\n",
        "        '''\n",
        "        return mish(input)\n",
        "\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return gem(x, p=self.p, eps=self.eps).squeeze(-1).squeeze(-1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(\n",
        "            self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
        "\n",
        "\n",
        "class SpatialAttention2d(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(SpatialAttention2d, self).__init__()\n",
        "        self.squeeze = nn.Conv2d(channel, 1, kernel_size=1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.squeeze(x)\n",
        "        z = self.sigmoid(z)\n",
        "        return x * z\n",
        "\n",
        "\n",
        "class GAB(nn.Module):\n",
        "    def __init__(self, input_dim, reduction=4):\n",
        "        super(GAB, self).__init__()\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            input_dim, input_dim // reduction, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            input_dim // reduction, input_dim, kernel_size=1, stride=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.global_avgpool(x)\n",
        "        z = self.relu(self.conv1(z))\n",
        "        z = self.sigmoid(self.conv2(z))\n",
        "        return x * z\n",
        "\n",
        "\n",
        "class SCse(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(SCse, self).__init__()\n",
        "        self.satt = SpatialAttention2d(dim)\n",
        "        self.catt = GAB(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.satt(x) + self.catt(x)\n",
        "    \n",
        "    \n",
        "class SEResNext(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_name: str,\n",
        "                 num_classes: int,\n",
        "                 pretrained=None,\n",
        "                 head=\"linear\",\n",
        "                 in_channels=3):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.base = getattr(pretrainedmodels.models,\n",
        "                            model_name)(pretrained=pretrained)\n",
        "        self.head = head\n",
        "        assert in_channels in [1, 3]\n",
        "        assert head in [\"linear\", \"custom\", \"scse\"]\n",
        "        if in_channels == 1:\n",
        "            if pretrained == \"imagenet\":\n",
        "                weight = self.base.layer0.conv1.weight\n",
        "                self.base.layer0.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "                self.base.layer0.conv1.weight = nn.Parameter(\n",
        "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
        "                    requires_grad=True)\n",
        "            else:\n",
        "                self.base.layer0.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        if head == \"linear\":\n",
        "            n_in_features = self.base.last_linear.in_features\n",
        "            self.base.last_linear = nn.Linear(n_in_features, self.num_classes)\n",
        "        elif head == \"custom\":\n",
        "            n_in_features = self.base.last_linear.in_features\n",
        "            arch = list(self.base.children())\n",
        "            for _ in range(2):\n",
        "                arch.pop()\n",
        "            self.base = nn.Sequential(*arch)\n",
        "            self.grapheme_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Dropout(0.3), nn.Linear(\n",
        "                    512, 168))\n",
        "            self.vowel_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Dropout(0.3), nn.Linear(\n",
        "                    512, 11))\n",
        "            self.consonant_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Dropout(0.3), nn.Linear(512, 7))\n",
        "        elif head == \"scse\":\n",
        "            n_in_features = self.base.last_linear.in_features\n",
        "            arch = list(self.base.children())\n",
        "            for _ in range(2):\n",
        "                arch.pop()\n",
        "            self.base = nn.Sequential(*arch)\n",
        "            self.grapheme_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 168))\n",
        "            self.vowel_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 11))\n",
        "            self.consonant_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 7))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.head == \"linear\":\n",
        "            return self.base(x)\n",
        "        elif self.head == \"custom\":\n",
        "            x = self.base(x)\n",
        "            grapheme = self.grapheme_head(x)\n",
        "            vowel = self.vowel_head(x)\n",
        "            consonant = self.consonant_head(x)\n",
        "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
        "        elif self.head == \"scse\":\n",
        "            x = self.base(x)\n",
        "            grapheme = self.grapheme_head(x)\n",
        "            vowel = self.vowel_head(x)\n",
        "            consonant = self.consonant_head(x)\n",
        "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_name: str,\n",
        "                 num_classes: int,\n",
        "                 pretrained=False,\n",
        "                 head=\"linear\",\n",
        "                 in_channels=3):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.base = getattr(models, model_name)(pretrained=pretrained)\n",
        "        self.head = head\n",
        "        assert in_channels in [1, 3]\n",
        "        assert head in [\"linear\", \"custom\", \"scse\"]\n",
        "        if in_channels == 1:\n",
        "            if pretrained:\n",
        "                weight = self.base.conv1.weight\n",
        "                self.base.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "                self.base.conv1.weight = nn.Parameter(\n",
        "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
        "                    requires_grad=True)\n",
        "            else:\n",
        "                self.base.conv1 = nn.Conv2d(\n",
        "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        if head == \"linear\":\n",
        "            n_in_features = self.base.fc.in_features\n",
        "            self.base.fc = nn.Linear(n_in_features, self.num_classes)\n",
        "        elif head == \"custom\":\n",
        "            n_in_features = self.base.fc.in_features\n",
        "            arch = list(self.base.children())\n",
        "            for _ in range(2):\n",
        "                arch.pop()\n",
        "            self.base = nn.Sequential(*arch)\n",
        "            self.grapheme_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 168))\n",
        "            self.vowel_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 11))\n",
        "            self.consonant_head = nn.Sequential(\n",
        "                Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
        "                nn.BatchNorm2d(512), GeM(), nn.Linear(512, 7))\n",
        "        elif head == \"scse\":\n",
        "            n_in_features = self.base.fc.in_features\n",
        "            arch = list(self.base.children())\n",
        "            for _ in range(2):\n",
        "                arch.pop()\n",
        "            self.base = nn.Sequential(*arch)\n",
        "            self.grapheme_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 168))\n",
        "            self.vowel_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 11))\n",
        "            self.consonant_head = nn.Sequential(\n",
        "                SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
        "                nn.Dropout(0.3), nn.Linear(512, 7))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.head == \"linear\":\n",
        "            return self.base(x)\n",
        "        elif self.head == \"custom\":\n",
        "            x = self.base(x)\n",
        "            grapheme = self.grapheme_head(x)\n",
        "            vowel = self.vowel_head(x)\n",
        "            consonant = self.consonant_head(x)\n",
        "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
        "        elif self.head == \"scse\":\n",
        "            x = self.base(x)\n",
        "            grapheme = self.grapheme_head(x)\n",
        "            vowel = self.vowel_head(x)\n",
        "            consonant = self.consonant_head(x)\n",
        "            return torch.cat([grapheme, vowel, consonant], dim=1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "def get_model(config: edict):\n",
        "    params = config.model\n",
        "    if \"resnet\" in params.model_name:\n",
        "        return Resnet(**params)\n",
        "    elif \"se_resnext\" in params.model_name:\n",
        "        return SEResNext(**params)\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-IPNqFE5KQ_q"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lXKZUtQdKQ_r",
        "colab": {}
      },
      "source": [
        "class BengaliCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int, weights=[1.0, 1.0, 1.0]):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, 0]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, 1]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, 2]\n",
        "\n",
        "        return self.weights[0] * self.cross_entropy(grapheme_pred, grapheme_true) + \\\n",
        "            self.weights[1] * self.cross_entropy(vowel_pred, vowel_true) + \\\n",
        "            self.weights[2] * self.cross_entropy(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "class BengaliBCELoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, head:tail]\n",
        "\n",
        "        return self.bce(grapheme_pred, grapheme_true) + \\\n",
        "            self.bce(vowel_pred, vowel_true) + \\\n",
        "            self.bce(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "def get_loss(config: edict):\n",
        "    name = config.loss.name\n",
        "    params = config.loss.params\n",
        "    if name == \"bce\":\n",
        "        criterion = BengaliBCELoss(**params)\n",
        "    elif name == \"cross_entropy\":\n",
        "        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4aJX5V_KQ_t",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "thU1KR2NKQ_u"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fWo_pBvzKQ_u",
        "colab": {}
      },
      "source": [
        "Optimizer = Union[Adam, SGD]\n",
        "\n",
        "\n",
        "def get_optimizer(model, config: edict) -> Optimizer:\n",
        "    name = config.optimizer.name\n",
        "    params = config.optimizer.params\n",
        "    if name == \"Adam\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    elif name == \"SGD\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FmA47o80KQ_z"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DA7gtPiyKQ_0",
        "colab": {}
      },
      "source": [
        "Scheduler = Optional[\n",
        "    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, config: edict) -> Scheduler:\n",
        "    params = config.scheduler.params\n",
        "    name = config.scheduler.name\n",
        "    scheduler: Scheduler = None\n",
        "    if name == \"plateau\":\n",
        "        scheduler = ReduceLROnPlateau(optimizer, **params)\n",
        "    elif name == \"cosine\":\n",
        "        scheduler = CosineAnnealingLR(optimizer, **params)\n",
        "    elif name == \"cosine_warmup\":\n",
        "        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n",
        "\n",
        "    return scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YB5qDnQIKQ_2"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IwyscXBKQ_3",
        "colab": {}
      },
      "source": [
        "class AverageRecall(Callback):\n",
        "    def __init__(self,\n",
        "                 index: int,\n",
        "                 offset: int,\n",
        "                 n_classes: int,\n",
        "                 prefix: str,\n",
        "                 loss_type: str = \"bce\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 target_key: str = \"targets\"):\n",
        "        self.index = index\n",
        "        self.offset = offset\n",
        "        self.n_classes = n_classes\n",
        "        self.prefix = prefix\n",
        "        self.loss_type = loss_type\n",
        "        self.output_key = output_key\n",
        "        self.target_key = target_key\n",
        "        self.recall = 0.0\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "    def on_loader_start(self, state: RunnerState):\n",
        "        self.prediction: List[int] = []\n",
        "        self.target: List[int] = []\n",
        "\n",
        "    def on_batch_end(self, state: RunnerState):\n",
        "        targ = state.input[self.target_key].detach()\n",
        "        out = state.output[self.output_key].detach()\n",
        "        head = self.offset\n",
        "        tail = self.offset + self.n_classes\n",
        "        if self.loss_type == \"bce\":\n",
        "            pred_np = torch.argmax(\n",
        "                torch.sigmoid(out[:, head:tail]), dim=1).cpu().numpy()\n",
        "            target_np = torch.argmax(targ[:, head:tail], dim=1).cpu().numpy()\n",
        "        else:\n",
        "            pred_np = torch.argmax(out[:, head:tail], dim=1).cpu().numpy()\n",
        "            target_np = targ[:, self.index].cpu().numpy()\n",
        "        self.prediction.extend(pred_np)\n",
        "        self.target.extend(target_np)\n",
        "        score = recall_score(\n",
        "            target_np, pred_np, average=\"macro\", zero_division=0)\n",
        "        state.metrics.add_batch_value(name=\"batch_\" + self.prefix, value=score)\n",
        "\n",
        "    def on_loader_end(self, state: RunnerState):\n",
        "        metric_name = self.prefix\n",
        "        y_true = np.asarray(self.target)\n",
        "        y_pred = np.asarray(self.prediction)\n",
        "\n",
        "        metric = recall_score(y_true, y_pred, average=\"macro\")\n",
        "        state.metrics.epoch_values[state.loader_name][metric_name] = float(\n",
        "            metric)\n",
        "        self.recall = metric\n",
        "\n",
        "\n",
        "class TotalAverageRecall(Callback):\n",
        "    def __init__(self,\n",
        "                 n_grapheme=168,\n",
        "                 n_vowel=11,\n",
        "                 n_consonant=7,\n",
        "                 loss_type: str = \"bce\",\n",
        "                 prefix: str = \"tar\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 target_key: str = \"targets\"):\n",
        "        self.prefix = prefix\n",
        "        self.grapheme_callback = AverageRecall(\n",
        "            index=0,\n",
        "            offset=0,\n",
        "            n_classes=n_grapheme,\n",
        "            prefix=\"grapheme_recall\",\n",
        "            loss_type=loss_type,\n",
        "            output_key=output_key,\n",
        "            target_key=target_key)\n",
        "        self.vowel_callback = AverageRecall(\n",
        "            index=1,\n",
        "            offset=n_grapheme,\n",
        "            n_classes=n_vowel,\n",
        "            prefix=\"vowel_recall\",\n",
        "            loss_type=loss_type,\n",
        "            output_key=output_key,\n",
        "            target_key=target_key)\n",
        "        self.consonant_callback = AverageRecall(\n",
        "            index=2,\n",
        "            offset=n_grapheme + n_vowel,\n",
        "            n_classes=n_consonant,\n",
        "            prefix=\"consonant_recall\",\n",
        "            loss_type=loss_type,\n",
        "            output_key=output_key,\n",
        "            target_key=target_key)\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "    def on_loader_start(self, state):\n",
        "        self.grapheme_callback.on_loader_start(state)\n",
        "        self.vowel_callback.on_loader_start(state)\n",
        "        self.consonant_callback.on_loader_start(state)\n",
        "\n",
        "    def on_batch_end(self, state: RunnerState):\n",
        "        self.grapheme_callback.on_batch_end(state)\n",
        "        self.vowel_callback.on_batch_end(state)\n",
        "        self.consonant_callback.on_batch_end(state)\n",
        "\n",
        "    def on_loader_end(self, state: RunnerState):\n",
        "        self.grapheme_callback.on_loader_end(state)\n",
        "        self.vowel_callback.on_loader_end(state)\n",
        "        self.consonant_callback.on_loader_end(state)\n",
        "\n",
        "        grapheme_recall = self.grapheme_callback.recall\n",
        "        vowel_recall = self.vowel_callback.recall\n",
        "        consonant_recall = self.consonant_callback.recall\n",
        "        final_score = np.average(\n",
        "            [grapheme_recall, vowel_recall, consonant_recall],\n",
        "            weights=[2, 1, 1])\n",
        "        state.metrics.epoch_values[state.loader_name][self.\n",
        "                                                      prefix] = final_score\n",
        "\n",
        "\n",
        "\n",
        "class SaveWeightsCallback(Callback):\n",
        "    def __init__(self,\n",
        "                 to: Optional[Path] = None,\n",
        "                 name: str = \"\",\n",
        "                 is_larger_better=True,\n",
        "                 main_metric=\"tar\"):\n",
        "        self.to = to\n",
        "        if isinstance(self.to, str):\n",
        "            self.to = Path(to)\n",
        "        self.name = name\n",
        "        self.best = -np.inf if is_larger_better else np.inf\n",
        "        self.is_larger_better = is_larger_better\n",
        "        self.main_metric = main_metric\n",
        "        super().__init__(CallbackOrder.External)\n",
        "\n",
        "    def on_epoch_end(self, state: RunnerState):\n",
        "        val_metric = state.metrics.epoch_values[\"valid\"][self.main_metric]\n",
        "        to_save = False\n",
        "        if self.is_larger_better and self.best < val_metric:\n",
        "            to_save = True\n",
        "            self.best = val_metric\n",
        "        elif not self.is_larger_better and self.best > val_metric:\n",
        "            to_save = True\n",
        "            self.best = val_metric\n",
        "        if to_save:\n",
        "            weights = state.model.state_dict()\n",
        "            epoch = state.epoch\n",
        "            optimizer_state = state.optimizer.state_dict()\n",
        "            scheduler_state = state.scheduler.state_dict()\n",
        "            state_dict = {\n",
        "                \"model_state_dict\": weights,\n",
        "                \"epoch\": epoch,\n",
        "                \"optimizer_state_dict\": optimizer_state,\n",
        "                \"scheduler_state_dict\": scheduler_state\n",
        "            }\n",
        "\n",
        "            logdir = state.logdir / \"checkpoints\"\n",
        "            logdir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "            if self.name == \"\":\n",
        "                torch.save(state_dict, logdir / \"temp.pth\")\n",
        "            else:\n",
        "                torch.save(state_dict, logdir / f\"{self.name}.pth\")\n",
        "\n",
        "            if self.to is not None:\n",
        "                if self.name == \"\":\n",
        "                    torch.save(state_dict, self.to / \"temp.pth\")\n",
        "                else:\n",
        "                    torch.save(state_dict, self.to / f\"{self.name}.pth\")\n",
        "                    \n",
        "                    \n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "\n",
        "class MixupOrCutmixCallback(CriterionCallback):\n",
        "    def __init__(self,\n",
        "                 fields: List[str] = [\n",
        "                     \"images\",\n",
        "                 ],\n",
        "                 alpha=1.0,\n",
        "                 on_train_only=True,\n",
        "                 mixup_prob=0.5,\n",
        "                 cutmix_prob=0.5,\n",
        "                 **kwargs):\n",
        "        assert len(fields) > 0, \\\n",
        "            \"At least one field is required\"\n",
        "        assert alpha >= 0, \"alpha must be>=0\"\n",
        "        assert 1 >= mixup_prob >= 0, \"mixup_prob must be within 1 and 0\"\n",
        "        assert 1 >= cutmix_prob >= 0, \"cutmix_prob must be within 1 and 0\"\n",
        "        assert 1 >= mixup_prob + cutmix_prob, \\\n",
        "            \"sum of mixup_prob and cutmix_prob must be lower than 1\"\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.on_train_only = on_train_only\n",
        "        self.fields = fields\n",
        "        self.alpha = alpha\n",
        "        self.lam = 1\n",
        "        self.index = None\n",
        "        self.is_needed = True\n",
        "        self.mixup_prob = mixup_prob\n",
        "        self.cutmix_prob = cutmix_prob\n",
        "        self.no_action_prob = 1 - (mixup_prob + cutmix_prob)\n",
        "\n",
        "    def on_loader_start(self, state: RunnerState):\n",
        "        self.is_needed = not self.on_train_only or \\\n",
        "            state.loader_name.startswith(\"train\")\n",
        "\n",
        "    def on_batch_start(self, state: RunnerState):\n",
        "        if not self.is_needed:\n",
        "            return\n",
        "\n",
        "        dice = np.random.choice(\n",
        "            [0, 1, 2],\n",
        "            p=[self.mixup_prob, self.cutmix_prob, self.no_action_prob])\n",
        "        self.dice = dice\n",
        "        if dice == 0:\n",
        "            if self.alpha > 0:\n",
        "                self.lam = np.random.beta(self.alpha, self.alpha)\n",
        "            else:\n",
        "                self.lam = 1\n",
        "            self.index = torch.randperm(state.input[self.fields[0]].shape[0])\n",
        "            self.index.to(state.device)\n",
        "\n",
        "            for f in self.fields:\n",
        "                state.input[f] = self.lam * state.input[f] + \\\n",
        "                    (1 - self.lam) * state.input[f][self.index]\n",
        "        elif dice == 1:\n",
        "            self.index = torch.randperm(state.input[self.fields[0]].shape[0])\n",
        "            self.index.to(state.device)\n",
        "\n",
        "            if self.alpha > 0:\n",
        "                lam = np.random.beta(self.alpha, self.alpha)\n",
        "            else:\n",
        "                lam = 1\n",
        "                bbx1, bby1, bbx2, bby2 = rand_bbox(\n",
        "                    state.input[self.fields[0]].size(), lam)\n",
        "                for f in self.fields:\n",
        "                    state.input[f][:, :, bbx1:bbx2, bby1:bby2] = \\\n",
        "                        state.input[f][self.index, :, bbx1:bbx2, bby1:bby2]\n",
        "                self.lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) /\n",
        "                                (state.input[self.fields[0]].size()[-1] *\n",
        "                                 state.input[self.fields[0]].size()[-2]))\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def _compute_loss(self, state: RunnerState, criterion):\n",
        "        if not self.is_needed:\n",
        "            return super()._compute_loss(state, criterion)\n",
        "\n",
        "        if self.dice == 0 or self.dice == 1:\n",
        "            pred = state.output[self.output_key]\n",
        "            y_a = state.input[self.input_key]\n",
        "            y_b = state.input[self.input_key][self.index]\n",
        "            loss = self.lam * criterion(pred, y_a) + \\\n",
        "                (1 - self.lam) * criterion(pred, y_b)\n",
        "            return loss\n",
        "        else:\n",
        "            return super()._compute_loss(state, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kHvFfq-C3NGk",
        "colab": {}
      },
      "source": [
        "def get_callbacks(config: edict):\n",
        "    callbacks = []\n",
        "    for callback in config.callbacks:\n",
        "        name = list(callback.keys())[0]\n",
        "        params = callback[name]\n",
        "        if globals().get(name) is not None:\n",
        "            if params is not None:\n",
        "                callbacks.append(globals().get(name)(**params))  # type: ignore\n",
        "            else:\n",
        "                callbacks.append(globals().get(name)())  # type: ignore\n",
        "    return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ChYS5rgoKQ_5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M-QhaJoMKQ_6",
        "outputId": "de230a73-9f6c-494a-b3b4-e8efb6bee526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "facf27d6089b42a99b56b67fa4b806f4",
            "acda58fbfd0a42bdac475382915e17fe",
            "8b94a6ad15aa41199d5c70fd13580f05",
            "19e4131392d2460eaa95685fae05635e",
            "fd01af70424f46b28a3915ce99e41f7c",
            "7b48a359b8e549349925f03d41397538",
            "9909548a71fe4e109a0df41b6c50a084",
            "e6d83802234e431aaa43717748ad2b4a"
          ]
        }
      },
      "source": [
        "trn_idx, val_idx = splits[i]\n",
        "\n",
        "print(f\"Fold: {i}\")\n",
        "\n",
        "output_dir = output_base_dir / f\"fold{i}\"\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n",
        "val_df = df.loc[val_idx, :].reset_index(drop=True)\n",
        "data_loaders = {\n",
        "    phase: get_base_loader(\n",
        "        df,\n",
        "        train_images_path,\n",
        "        phase=phase,\n",
        "        size=(config.img_size, config.img_size),\n",
        "        batch_size=config.train.batch_size,\n",
        "        num_workers=config.num_workers,\n",
        "        transforms=transforms_dict[phase])\n",
        "    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
        "}\n",
        "\n",
        "load_weights = False\n",
        "\n",
        "if config.weights is not None:\n",
        "    state_dict = torch.load(config.weights)\n",
        "    load_weights = True\n",
        "\n",
        "model = get_model(config)\n",
        "\n",
        "if load_weights:\n",
        "    if \"model_state_dict\" in state_dict.keys():\n",
        "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
        "        model.to(get_device())\n",
        "    else:\n",
        "        model.load_state_dict(state_dict)\n",
        "        model.to(get_device())\n",
        "\n",
        "criterion = get_loss(config).to(get_device())\n",
        "optimizer = get_optimizer(model, config)\n",
        "scheduler = get_scheduler(optimizer, config)\n",
        "callbacks = get_callbacks(config)\n",
        "\n",
        "if load_weights:\n",
        "    if \"optimizer_state_dict\" in state_dict.keys():\n",
        "        optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
        "    if \"scheduler_state_dict\" in state_dict.keys():\n",
        "        scheduler.load_state_dict(state_dict[\"scheduler_state_dict\"])\n",
        "\n",
        "runner = SupervisedRunner(\n",
        "    device=ct.utils.get_device(),\n",
        "    input_key=\"images\",\n",
        "    input_target_key=\"targets\",\n",
        "    output_key=\"logits\")\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    loaders=data_loaders,\n",
        "    logdir=output_dir,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=config.train.num_epochs,\n",
        "    callbacks=callbacks,\n",
        "    main_metric=\"tar\",\n",
        "    minimize_metric=False,\n",
        "    monitoring_params=None,\n",
        "    verbose=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "facf27d6089b42a99b56b67fa4b806f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[2020-02-08 01:05:59,569] \n",
            "1/70 * Epoch 1 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2712.2347 | _timers/batch_time=0.1348 | _timers/data_time=0.1090 | _timers/model_time=0.0243 | batch_consonant_recall=0.7796 | batch_grapheme_recall=0.7174 | batch_vowel_recall=0.7615 | consonant_recall=0.7661 | grapheme_recall=0.7254 | loss=2.2318 | tar=0.7440 | vowel_recall=0.7593\n",
            "1/70 * Epoch 1 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=4320.3923 | _timers/batch_time=0.1878 | _timers/data_time=0.1721 | _timers/model_time=0.0157 | batch_consonant_recall=0.9745 | batch_grapheme_recall=0.9334 | batch_vowel_recall=0.9776 | consonant_recall=0.9724 | grapheme_recall=0.9521 | loss=0.8626 | tar=0.9641 | vowel_recall=0.9798\n",
            "[2020-02-08 01:15:20,586] \n",
            "2/70 * Epoch 2 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2921.6782 | _timers/batch_time=0.1485 | _timers/data_time=0.1279 | _timers/model_time=0.0192 | batch_consonant_recall=0.7809 | batch_grapheme_recall=0.7215 | batch_vowel_recall=0.7656 | consonant_recall=0.7706 | grapheme_recall=0.7291 | loss=2.1408 | tar=0.7476 | vowel_recall=0.7617\n",
            "2/70 * Epoch 2 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=3869.0265 | _timers/batch_time=0.1827 | _timers/data_time=0.1703 | _timers/model_time=0.0123 | batch_consonant_recall=0.9743 | batch_grapheme_recall=0.9366 | batch_vowel_recall=0.9784 | consonant_recall=0.9723 | grapheme_recall=0.9554 | loss=0.7802 | tar=0.9659 | vowel_recall=0.9806\n",
            "[2020-02-08 01:24:19,975] \n",
            "3/70 * Epoch 3 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=3078.2096 | _timers/batch_time=0.1399 | _timers/data_time=0.1175 | _timers/model_time=0.0210 | batch_consonant_recall=0.7814 | batch_grapheme_recall=0.7254 | batch_vowel_recall=0.7667 | consonant_recall=0.7648 | grapheme_recall=0.7333 | loss=2.1339 | tar=0.7491 | vowel_recall=0.7649\n",
            "3/70 * Epoch 3 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2777.6446 | _timers/batch_time=0.1602 | _timers/data_time=0.1446 | _timers/model_time=0.0155 | batch_consonant_recall=0.9780 | batch_grapheme_recall=0.9373 | batch_vowel_recall=0.9804 | consonant_recall=0.9788 | grapheme_recall=0.9568 | loss=0.5627 | tar=0.9685 | vowel_recall=0.9818\n",
            "[2020-02-08 01:33:05,624] \n",
            "4/70 * Epoch 4 (train): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2754.2047 | _timers/batch_time=0.1415 | _timers/data_time=0.1187 | _timers/model_time=0.0213 | batch_consonant_recall=0.7816 | batch_grapheme_recall=0.7228 | batch_vowel_recall=0.7656 | consonant_recall=0.7628 | grapheme_recall=0.7305 | loss=2.1795 | tar=0.7469 | vowel_recall=0.7637\n",
            "4/70 * Epoch 4 (valid): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2571.5381 | _timers/batch_time=0.1647 | _timers/data_time=0.1489 | _timers/model_time=0.0157 | batch_consonant_recall=0.9759 | batch_grapheme_recall=0.9362 | batch_vowel_recall=0.9801 | consonant_recall=0.9753 | grapheme_recall=0.9568 | loss=0.6329 | tar=0.9677 | vowel_recall=0.9820\n",
            "[2020-02-08 01:41:13,227] \n",
            "5/70 * Epoch 5 (train): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2475.5090 | _timers/batch_time=0.1133 | _timers/data_time=0.0850 | _timers/model_time=0.0269 | batch_consonant_recall=0.7943 | batch_grapheme_recall=0.7354 | batch_vowel_recall=0.7733 | consonant_recall=0.7797 | grapheme_recall=0.7439 | loss=2.0515 | tar=0.7596 | vowel_recall=0.7707\n",
            "5/70 * Epoch 5 (valid): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2522.1233 | _timers/batch_time=0.1613 | _timers/data_time=0.1457 | _timers/model_time=0.0156 | batch_consonant_recall=0.9776 | batch_grapheme_recall=0.9344 | batch_vowel_recall=0.9783 | consonant_recall=0.9772 | grapheme_recall=0.9541 | loss=0.7649 | tar=0.9665 | vowel_recall=0.9807\n",
            "[2020-02-08 01:49:21,887] \n",
            "6/70 * Epoch 6 (train): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2384.6102 | _timers/batch_time=0.1124 | _timers/data_time=0.0841 | _timers/model_time=0.0269 | batch_consonant_recall=0.7813 | batch_grapheme_recall=0.7215 | batch_vowel_recall=0.7648 | consonant_recall=0.7662 | grapheme_recall=0.7320 | loss=2.1679 | tar=0.7481 | vowel_recall=0.7622\n",
            "6/70 * Epoch 6 (valid): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2755.4675 | _timers/batch_time=0.1662 | _timers/data_time=0.1504 | _timers/model_time=0.0158 | batch_consonant_recall=0.9731 | batch_grapheme_recall=0.9345 | batch_vowel_recall=0.9802 | consonant_recall=0.9719 | grapheme_recall=0.9543 | loss=0.7790 | tar=0.9655 | vowel_recall=0.9813\n",
            "[2020-02-08 01:57:32,945] \n",
            "7/70 * Epoch 7 (train): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2478.1325 | _timers/batch_time=0.1137 | _timers/data_time=0.0858 | _timers/model_time=0.0266 | batch_consonant_recall=0.7797 | batch_grapheme_recall=0.7223 | batch_vowel_recall=0.7633 | consonant_recall=0.7628 | grapheme_recall=0.7312 | loss=2.1750 | tar=0.7464 | vowel_recall=0.7605\n",
            "7/70 * Epoch 7 (valid): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=3076.0139 | _timers/batch_time=0.1690 | _timers/data_time=0.1531 | _timers/model_time=0.0159 | batch_consonant_recall=0.9772 | batch_grapheme_recall=0.9357 | batch_vowel_recall=0.9803 | consonant_recall=0.9773 | grapheme_recall=0.9548 | loss=0.6006 | tar=0.9673 | vowel_recall=0.9821\n",
            "[2020-02-08 02:05:43,640] \n",
            "8/70 * Epoch 8 (train): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2433.0581 | _timers/batch_time=0.1161 | _timers/data_time=0.0865 | _timers/model_time=0.0283 | batch_consonant_recall=0.7788 | batch_grapheme_recall=0.7189 | batch_vowel_recall=0.7671 | consonant_recall=0.7630 | grapheme_recall=0.7275 | loss=2.1890 | tar=0.7459 | vowel_recall=0.7658\n",
            "8/70 * Epoch 8 (valid): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2698.0287 | _timers/batch_time=0.1646 | _timers/data_time=0.1486 | _timers/model_time=0.0160 | batch_consonant_recall=0.9735 | batch_grapheme_recall=0.9299 | batch_vowel_recall=0.9792 | consonant_recall=0.9751 | grapheme_recall=0.9515 | loss=0.7027 | tar=0.9649 | vowel_recall=0.9817\n",
            "[2020-02-08 02:13:51,499] \n",
            "9/70 * Epoch 9 (train): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2358.2305 | _timers/batch_time=0.1124 | _timers/data_time=0.0832 | _timers/model_time=0.0277 | batch_consonant_recall=0.7645 | batch_grapheme_recall=0.7035 | batch_vowel_recall=0.7518 | consonant_recall=0.7490 | grapheme_recall=0.7143 | loss=2.3667 | tar=0.7319 | vowel_recall=0.7500\n",
            "9/70 * Epoch 9 (valid): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=3036.1990 | _timers/batch_time=0.1667 | _timers/data_time=0.1504 | _timers/model_time=0.0163 | batch_consonant_recall=0.9680 | batch_grapheme_recall=0.9279 | batch_vowel_recall=0.9784 | consonant_recall=0.9669 | grapheme_recall=0.9478 | loss=1.1851 | tar=0.9606 | vowel_recall=0.9798\n",
            "[2020-02-08 02:21:57,583] \n",
            "10/70 * Epoch 10 (train): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2443.2434 | _timers/batch_time=0.1113 | _timers/data_time=0.0829 | _timers/model_time=0.0271 | batch_consonant_recall=0.7791 | batch_grapheme_recall=0.7254 | batch_vowel_recall=0.7732 | consonant_recall=0.7653 | grapheme_recall=0.7364 | loss=2.2014 | tar=0.7515 | vowel_recall=0.7677\n",
            "10/70 * Epoch 10 (valid): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2176.1159 | _timers/batch_time=0.1629 | _timers/data_time=0.1468 | _timers/model_time=0.0161 | batch_consonant_recall=0.9730 | batch_grapheme_recall=0.9311 | batch_vowel_recall=0.9809 | consonant_recall=0.9719 | grapheme_recall=0.9524 | loss=0.8025 | tar=0.9646 | vowel_recall=0.9818\n",
            "[2020-02-08 02:30:04,235] \n",
            "11/70 * Epoch 11 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2238.0378 | _timers/batch_time=0.1105 | _timers/data_time=0.0821 | _timers/model_time=0.0271 | batch_consonant_recall=0.7818 | batch_grapheme_recall=0.7199 | batch_vowel_recall=0.7695 | consonant_recall=0.7710 | grapheme_recall=0.7290 | loss=2.2801 | tar=0.7490 | vowel_recall=0.7670\n",
            "11/70 * Epoch 11 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2196.3683 | _timers/batch_time=0.1672 | _timers/data_time=0.1509 | _timers/model_time=0.0163 | batch_consonant_recall=0.9761 | batch_grapheme_recall=0.9263 | batch_vowel_recall=0.9795 | consonant_recall=0.9802 | grapheme_recall=0.9486 | loss=0.6207 | tar=0.9648 | vowel_recall=0.9818\n",
            "[2020-02-08 02:38:07,955] \n",
            "12/70 * Epoch 12 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2306.4217 | _timers/batch_time=0.1098 | _timers/data_time=0.0811 | _timers/model_time=0.0273 | batch_consonant_recall=0.7744 | batch_grapheme_recall=0.7136 | batch_vowel_recall=0.7628 | consonant_recall=0.7601 | grapheme_recall=0.7223 | loss=2.2984 | tar=0.7413 | vowel_recall=0.7605\n",
            "12/70 * Epoch 12 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2295.9062 | _timers/batch_time=0.1602 | _timers/data_time=0.1450 | _timers/model_time=0.0151 | batch_consonant_recall=0.9760 | batch_grapheme_recall=0.9294 | batch_vowel_recall=0.9772 | consonant_recall=0.9752 | grapheme_recall=0.9501 | loss=0.6239 | tar=0.9637 | vowel_recall=0.9794\n",
            "[2020-02-08 02:46:12,934] \n",
            "13/70 * Epoch 13 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2375.8300 | _timers/batch_time=0.1105 | _timers/data_time=0.0817 | _timers/model_time=0.0274 | batch_consonant_recall=0.7835 | batch_grapheme_recall=0.7230 | batch_vowel_recall=0.7712 | consonant_recall=0.7739 | grapheme_recall=0.7339 | loss=2.2641 | tar=0.7525 | vowel_recall=0.7684\n",
            "13/70 * Epoch 13 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2707.4212 | _timers/batch_time=0.1618 | _timers/data_time=0.1461 | _timers/model_time=0.0156 | batch_consonant_recall=0.9703 | batch_grapheme_recall=0.9208 | batch_vowel_recall=0.9775 | consonant_recall=0.9704 | grapheme_recall=0.9446 | loss=0.7011 | tar=0.9597 | vowel_recall=0.9793\n",
            "[2020-02-08 02:54:16,132] \n",
            "14/70 * Epoch 14 (train): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2387.7041 | _timers/batch_time=0.1102 | _timers/data_time=0.0816 | _timers/model_time=0.0272 | batch_consonant_recall=0.7797 | batch_grapheme_recall=0.7180 | batch_vowel_recall=0.7638 | consonant_recall=0.7655 | grapheme_recall=0.7285 | loss=2.2563 | tar=0.7460 | vowel_recall=0.7614\n",
            "14/70 * Epoch 14 (valid): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2703.3384 | _timers/batch_time=0.1565 | _timers/data_time=0.1412 | _timers/model_time=0.0152 | batch_consonant_recall=0.9718 | batch_grapheme_recall=0.9219 | batch_vowel_recall=0.9772 | consonant_recall=0.9725 | grapheme_recall=0.9442 | loss=0.7341 | tar=0.9603 | vowel_recall=0.9800\n",
            "[2020-02-08 03:02:13,149] \n",
            "15/70 * Epoch 15 (train): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2549.1349 | _timers/batch_time=0.1051 | _timers/data_time=0.0768 | _timers/model_time=0.0270 | batch_consonant_recall=0.7789 | batch_grapheme_recall=0.7158 | batch_vowel_recall=0.7652 | consonant_recall=0.7672 | grapheme_recall=0.7253 | loss=2.2530 | tar=0.7453 | vowel_recall=0.7632\n",
            "15/70 * Epoch 15 (valid): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2421.0322 | _timers/batch_time=0.1598 | _timers/data_time=0.1445 | _timers/model_time=0.0153 | batch_consonant_recall=0.9704 | batch_grapheme_recall=0.9217 | batch_vowel_recall=0.9751 | consonant_recall=0.9702 | grapheme_recall=0.9481 | loss=0.7006 | tar=0.9606 | vowel_recall=0.9761\n",
            "[2020-02-08 03:10:11,581] \n",
            "16/70 * Epoch 16 (train): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2527.6504 | _timers/batch_time=0.1055 | _timers/data_time=0.0777 | _timers/model_time=0.0266 | batch_consonant_recall=0.7917 | batch_grapheme_recall=0.7360 | batch_vowel_recall=0.7779 | consonant_recall=0.7761 | grapheme_recall=0.7462 | loss=2.0919 | tar=0.7611 | vowel_recall=0.7758\n",
            "16/70 * Epoch 16 (valid): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2534.2849 | _timers/batch_time=0.1642 | _timers/data_time=0.1480 | _timers/model_time=0.0161 | batch_consonant_recall=0.9723 | batch_grapheme_recall=0.9286 | batch_vowel_recall=0.9766 | consonant_recall=0.9728 | grapheme_recall=0.9498 | loss=0.6655 | tar=0.9629 | vowel_recall=0.9791\n",
            "[2020-02-08 03:18:07,047] \n",
            "17/70 * Epoch 17 (train): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2523.3514 | _timers/batch_time=0.1036 | _timers/data_time=0.0759 | _timers/model_time=0.0264 | batch_consonant_recall=0.7859 | batch_grapheme_recall=0.7331 | batch_vowel_recall=0.7750 | consonant_recall=0.7760 | grapheme_recall=0.7437 | loss=2.1152 | tar=0.7588 | vowel_recall=0.7717\n",
            "17/70 * Epoch 17 (valid): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=3397.7743 | _timers/batch_time=0.1628 | _timers/data_time=0.1466 | _timers/model_time=0.0162 | batch_consonant_recall=0.9725 | batch_grapheme_recall=0.9264 | batch_vowel_recall=0.9774 | consonant_recall=0.9730 | grapheme_recall=0.9494 | loss=0.7990 | tar=0.9627 | vowel_recall=0.9790\n",
            "[2020-02-08 03:26:04,579] \n",
            "18/70 * Epoch 18 (train): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=2521.2692 | _timers/batch_time=0.1049 | _timers/data_time=0.0767 | _timers/model_time=0.0269 | batch_consonant_recall=0.7782 | batch_grapheme_recall=0.7284 | batch_vowel_recall=0.7629 | consonant_recall=0.7656 | grapheme_recall=0.7398 | loss=2.1268 | tar=0.7513 | vowel_recall=0.7599\n",
            "18/70 * Epoch 18 (valid): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3028.1888 | _timers/batch_time=0.1652 | _timers/data_time=0.1490 | _timers/model_time=0.0162 | batch_consonant_recall=0.9787 | batch_grapheme_recall=0.9335 | batch_vowel_recall=0.9777 | consonant_recall=0.9779 | grapheme_recall=0.9544 | loss=0.5612 | tar=0.9668 | vowel_recall=0.9806\n",
            "[2020-02-08 03:34:01,624] \n",
            "19/70 * Epoch 19 (train): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=2399.7217 | _timers/batch_time=0.1053 | _timers/data_time=0.0772 | _timers/model_time=0.0266 | batch_consonant_recall=0.7858 | batch_grapheme_recall=0.7344 | batch_vowel_recall=0.7660 | consonant_recall=0.7752 | grapheme_recall=0.7450 | loss=2.0943 | tar=0.7578 | vowel_recall=0.7660\n",
            "19/70 * Epoch 19 (valid): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=3255.7008 | _timers/batch_time=0.1612 | _timers/data_time=0.1453 | _timers/model_time=0.0159 | batch_consonant_recall=0.9770 | batch_grapheme_recall=0.9345 | batch_vowel_recall=0.9818 | consonant_recall=0.9754 | grapheme_recall=0.9545 | loss=0.5787 | tar=0.9669 | vowel_recall=0.9831\n",
            "[2020-02-08 03:41:57,425] \n",
            "20/70 * Epoch 20 (train): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=2568.6541 | _timers/batch_time=0.1050 | _timers/data_time=0.0768 | _timers/model_time=0.0268 | batch_consonant_recall=0.8003 | batch_grapheme_recall=0.7568 | batch_vowel_recall=0.7813 | consonant_recall=0.7863 | grapheme_recall=0.7645 | loss=1.9778 | tar=0.7731 | vowel_recall=0.7770\n",
            "20/70 * Epoch 20 (valid): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=3153.5412 | _timers/batch_time=0.1599 | _timers/data_time=0.1439 | _timers/model_time=0.0159 | batch_consonant_recall=0.9778 | batch_grapheme_recall=0.9359 | batch_vowel_recall=0.9826 | consonant_recall=0.9777 | grapheme_recall=0.9559 | loss=0.5432 | tar=0.9682 | vowel_recall=0.9834\n",
            "[2020-02-08 03:49:53,360] \n",
            "21/70 * Epoch 21 (train): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2502.9058 | _timers/batch_time=0.1038 | _timers/data_time=0.0759 | _timers/model_time=0.0266 | batch_consonant_recall=0.8058 | batch_grapheme_recall=0.7619 | batch_vowel_recall=0.7857 | consonant_recall=0.7953 | grapheme_recall=0.7704 | loss=1.8698 | tar=0.7795 | vowel_recall=0.7818\n",
            "21/70 * Epoch 21 (valid): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2766.6869 | _timers/batch_time=0.1630 | _timers/data_time=0.1471 | _timers/model_time=0.0159 | batch_consonant_recall=0.9772 | batch_grapheme_recall=0.9379 | batch_vowel_recall=0.9816 | consonant_recall=0.9754 | grapheme_recall=0.9566 | loss=0.5330 | tar=0.9678 | vowel_recall=0.9826\n",
            "[2020-02-08 03:57:51,993] \n",
            "22/70 * Epoch 22 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2524.2701 | _timers/batch_time=0.1052 | _timers/data_time=0.0773 | _timers/model_time=0.0266 | batch_consonant_recall=0.7996 | batch_grapheme_recall=0.7585 | batch_vowel_recall=0.7835 | consonant_recall=0.7910 | grapheme_recall=0.7686 | loss=1.8987 | tar=0.7770 | vowel_recall=0.7796\n",
            "22/70 * Epoch 22 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2901.3713 | _timers/batch_time=0.1667 | _timers/data_time=0.1502 | _timers/model_time=0.0165 | batch_consonant_recall=0.9775 | batch_grapheme_recall=0.9379 | batch_vowel_recall=0.9812 | consonant_recall=0.9773 | grapheme_recall=0.9569 | loss=0.5784 | tar=0.9684 | vowel_recall=0.9826\n",
            "[2020-02-08 04:06:00,007] \n",
            "23/70 * Epoch 23 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2433.2350 | _timers/batch_time=0.1111 | _timers/data_time=0.0825 | _timers/model_time=0.0271 | batch_consonant_recall=0.7894 | batch_grapheme_recall=0.7436 | batch_vowel_recall=0.7746 | consonant_recall=0.7810 | grapheme_recall=0.7528 | loss=1.9955 | tar=0.7649 | vowel_recall=0.7729\n",
            "23/70 * Epoch 23 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2529.7790 | _timers/batch_time=0.1701 | _timers/data_time=0.1539 | _timers/model_time=0.0162 | batch_consonant_recall=0.9753 | batch_grapheme_recall=0.9345 | batch_vowel_recall=0.9811 | consonant_recall=0.9750 | grapheme_recall=0.9554 | loss=0.6951 | tar=0.9671 | vowel_recall=0.9824\n",
            "[2020-02-08 04:14:02,384] \n",
            "24/70 * Epoch 24 (train): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2396.5178 | _timers/batch_time=0.1075 | _timers/data_time=0.0789 | _timers/model_time=0.0271 | batch_consonant_recall=0.8060 | batch_grapheme_recall=0.7604 | batch_vowel_recall=0.7882 | consonant_recall=0.7977 | grapheme_recall=0.7672 | loss=1.8642 | tar=0.7795 | vowel_recall=0.7860\n",
            "24/70 * Epoch 24 (valid): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=3110.5026 | _timers/batch_time=0.1689 | _timers/data_time=0.1520 | _timers/model_time=0.0169 | batch_consonant_recall=0.9772 | batch_grapheme_recall=0.9375 | batch_vowel_recall=0.9803 | consonant_recall=0.9758 | grapheme_recall=0.9569 | loss=0.6849 | tar=0.9679 | vowel_recall=0.9819\n",
            "[2020-02-08 04:22:07,218] \n",
            "25/70 * Epoch 25 (train): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2425.6307 | _timers/batch_time=0.1093 | _timers/data_time=0.0808 | _timers/model_time=0.0272 | batch_consonant_recall=0.7934 | batch_grapheme_recall=0.7455 | batch_vowel_recall=0.7782 | consonant_recall=0.7807 | grapheme_recall=0.7557 | loss=1.9459 | tar=0.7666 | vowel_recall=0.7741\n",
            "25/70 * Epoch 25 (valid): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2563.9569 | _timers/batch_time=0.1666 | _timers/data_time=0.1506 | _timers/model_time=0.0159 | batch_consonant_recall=0.9759 | batch_grapheme_recall=0.9360 | batch_vowel_recall=0.9802 | consonant_recall=0.9745 | grapheme_recall=0.9553 | loss=0.6723 | tar=0.9666 | vowel_recall=0.9815\n",
            "[2020-02-08 04:30:12,860] \n",
            "26/70 * Epoch 26 (train): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2422.8056 | _timers/batch_time=0.1103 | _timers/data_time=0.0813 | _timers/model_time=0.0275 | batch_consonant_recall=0.7848 | batch_grapheme_recall=0.7374 | batch_vowel_recall=0.7662 | consonant_recall=0.7717 | grapheme_recall=0.7447 | loss=2.0479 | tar=0.7562 | vowel_recall=0.7636\n",
            "26/70 * Epoch 26 (valid): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2600.1403 | _timers/batch_time=0.1687 | _timers/data_time=0.1521 | _timers/model_time=0.0165 | batch_consonant_recall=0.9778 | batch_grapheme_recall=0.9382 | batch_vowel_recall=0.9829 | consonant_recall=0.9753 | grapheme_recall=0.9565 | loss=0.5268 | tar=0.9680 | vowel_recall=0.9839\n",
            "[2020-02-08 04:38:16,971] \n",
            "27/70 * Epoch 27 (train): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2417.7321 | _timers/batch_time=0.1096 | _timers/data_time=0.0807 | _timers/model_time=0.0276 | batch_consonant_recall=0.7872 | batch_grapheme_recall=0.7363 | batch_vowel_recall=0.7736 | consonant_recall=0.7786 | grapheme_recall=0.7438 | loss=2.0087 | tar=0.7592 | vowel_recall=0.7707\n",
            "27/70 * Epoch 27 (valid): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2870.0353 | _timers/batch_time=0.1678 | _timers/data_time=0.1513 | _timers/model_time=0.0164 | batch_consonant_recall=0.9701 | batch_grapheme_recall=0.9326 | batch_vowel_recall=0.9791 | consonant_recall=0.9665 | grapheme_recall=0.9542 | loss=0.8037 | tar=0.9639 | vowel_recall=0.9806\n",
            "[2020-02-08 04:45:56,940] \n",
            "28/70 * Epoch 28 (train): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2579.3625 | _timers/batch_time=0.0953 | _timers/data_time=0.0679 | _timers/model_time=0.0261 | batch_consonant_recall=0.7787 | batch_grapheme_recall=0.7233 | batch_vowel_recall=0.7641 | consonant_recall=0.7643 | grapheme_recall=0.7347 | loss=2.1242 | tar=0.7493 | vowel_recall=0.7633\n",
            "28/70 * Epoch 28 (valid): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=3350.2076 | _timers/batch_time=0.1463 | _timers/data_time=0.1316 | _timers/model_time=0.0147 | batch_consonant_recall=0.9684 | batch_grapheme_recall=0.9298 | batch_vowel_recall=0.9789 | consonant_recall=0.9719 | grapheme_recall=0.9535 | loss=0.9943 | tar=0.9647 | vowel_recall=0.9800\n",
            "[2020-02-08 04:53:21,365] \n",
            "29/70 * Epoch 29 (train): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2902.7065 | _timers/batch_time=0.0831 | _timers/data_time=0.0570 | _timers/model_time=0.0248 | batch_consonant_recall=0.7783 | batch_grapheme_recall=0.7190 | batch_vowel_recall=0.7618 | consonant_recall=0.7693 | grapheme_recall=0.7287 | loss=2.1807 | tar=0.7464 | vowel_recall=0.7587\n",
            "29/70 * Epoch 29 (valid): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2937.5040 | _timers/batch_time=0.1420 | _timers/data_time=0.1275 | _timers/model_time=0.0145 | batch_consonant_recall=0.9670 | batch_grapheme_recall=0.9298 | batch_vowel_recall=0.9788 | consonant_recall=0.9643 | grapheme_recall=0.9487 | loss=1.1103 | tar=0.9603 | vowel_recall=0.9797\n",
            "[2020-02-08 05:00:59,313] \n",
            "30/70 * Epoch 30 (train): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2682.4648 | _timers/batch_time=0.0932 | _timers/data_time=0.0663 | _timers/model_time=0.0256 | batch_consonant_recall=0.7857 | batch_grapheme_recall=0.7247 | batch_vowel_recall=0.7705 | consonant_recall=0.7765 | grapheme_recall=0.7347 | loss=2.0873 | tar=0.7539 | vowel_recall=0.7696\n",
            "30/70 * Epoch 30 (valid): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2731.3362 | _timers/batch_time=0.1454 | _timers/data_time=0.1310 | _timers/model_time=0.0143 | batch_consonant_recall=0.9778 | batch_grapheme_recall=0.9296 | batch_vowel_recall=0.9798 | consonant_recall=0.9767 | grapheme_recall=0.9497 | loss=0.5057 | tar=0.9646 | vowel_recall=0.9824\n",
            "[2020-02-08 05:08:25,801] \n",
            "31/70 * Epoch 31 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2886.4149 | _timers/batch_time=0.0835 | _timers/data_time=0.0578 | _timers/model_time=0.0244 | batch_consonant_recall=0.7811 | batch_grapheme_recall=0.7174 | batch_vowel_recall=0.7681 | consonant_recall=0.7625 | grapheme_recall=0.7271 | loss=2.2749 | tar=0.7457 | vowel_recall=0.7659\n",
            "31/70 * Epoch 31 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3114.5638 | _timers/batch_time=0.1460 | _timers/data_time=0.1318 | _timers/model_time=0.0142 | batch_consonant_recall=0.9788 | batch_grapheme_recall=0.9327 | batch_vowel_recall=0.9788 | consonant_recall=0.9804 | grapheme_recall=0.9521 | loss=0.5143 | tar=0.9665 | vowel_recall=0.9813\n",
            "[2020-02-08 05:15:50,838] \n",
            "32/70 * Epoch 32 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2946.2685 | _timers/batch_time=0.0827 | _timers/data_time=0.0572 | _timers/model_time=0.0242 | batch_consonant_recall=0.7701 | batch_grapheme_recall=0.7043 | batch_vowel_recall=0.7579 | consonant_recall=0.7592 | grapheme_recall=0.7157 | loss=2.3696 | tar=0.7363 | vowel_recall=0.7548\n",
            "32/70 * Epoch 32 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2854.4596 | _timers/batch_time=0.1438 | _timers/data_time=0.1300 | _timers/model_time=0.0137 | batch_consonant_recall=0.9657 | batch_grapheme_recall=0.9274 | batch_vowel_recall=0.9768 | consonant_recall=0.9628 | grapheme_recall=0.9489 | loss=1.3381 | tar=0.9596 | vowel_recall=0.9779\n",
            "[2020-02-08 05:23:12,378] \n",
            "33/70 * Epoch 33 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2990.4245 | _timers/batch_time=0.0809 | _timers/data_time=0.0555 | _timers/model_time=0.0242 | batch_consonant_recall=0.7837 | batch_grapheme_recall=0.7220 | batch_vowel_recall=0.7692 | consonant_recall=0.7754 | grapheme_recall=0.7317 | loss=2.1978 | tar=0.7516 | vowel_recall=0.7678\n",
            "33/70 * Epoch 33 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3083.9003 | _timers/batch_time=0.1417 | _timers/data_time=0.1278 | _timers/model_time=0.0139 | batch_consonant_recall=0.9465 | batch_grapheme_recall=0.9016 | batch_vowel_recall=0.9611 | consonant_recall=0.9431 | grapheme_recall=0.9284 | loss=1.3001 | tar=0.9408 | vowel_recall=0.9632\n",
            "[2020-02-08 05:30:58,671] \n",
            "34/70 * Epoch 34 (train): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2735.5405 | _timers/batch_time=0.0961 | _timers/data_time=0.0693 | _timers/model_time=0.0254 | batch_consonant_recall=0.7621 | batch_grapheme_recall=0.7017 | batch_vowel_recall=0.7528 | consonant_recall=0.7480 | grapheme_recall=0.7145 | loss=2.3380 | tar=0.7316 | vowel_recall=0.7495\n",
            "34/70 * Epoch 34 (valid): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2927.6044 | _timers/batch_time=0.1594 | _timers/data_time=0.1441 | _timers/model_time=0.0152 | batch_consonant_recall=0.9714 | batch_grapheme_recall=0.9246 | batch_vowel_recall=0.9780 | consonant_recall=0.9694 | grapheme_recall=0.9449 | loss=0.8841 | tar=0.9599 | vowel_recall=0.9805\n",
            "[2020-02-08 05:39:04,039] \n",
            "35/70 * Epoch 35 (train): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2344.2777 | _timers/batch_time=0.1103 | _timers/data_time=0.0820 | _timers/model_time=0.0269 | batch_consonant_recall=0.7785 | batch_grapheme_recall=0.7208 | batch_vowel_recall=0.7637 | consonant_recall=0.7668 | grapheme_recall=0.7321 | loss=2.2076 | tar=0.7481 | vowel_recall=0.7613\n",
            "35/70 * Epoch 35 (valid): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2598.8870 | _timers/batch_time=0.1643 | _timers/data_time=0.1479 | _timers/model_time=0.0163 | batch_consonant_recall=0.9670 | batch_grapheme_recall=0.9254 | batch_vowel_recall=0.9773 | consonant_recall=0.9652 | grapheme_recall=0.9473 | loss=1.0619 | tar=0.9597 | vowel_recall=0.9792\n",
            "[2020-02-08 05:47:02,616] \n",
            "36/70 * Epoch 36 (train): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2452.1571 | _timers/batch_time=0.1068 | _timers/data_time=0.0782 | _timers/model_time=0.0272 | batch_consonant_recall=0.7726 | batch_grapheme_recall=0.7210 | batch_vowel_recall=0.7622 | consonant_recall=0.7583 | grapheme_recall=0.7309 | loss=2.1957 | tar=0.7449 | vowel_recall=0.7594\n",
            "36/70 * Epoch 36 (valid): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2966.8361 | _timers/batch_time=0.1614 | _timers/data_time=0.1458 | _timers/model_time=0.0156 | batch_consonant_recall=0.9769 | batch_grapheme_recall=0.9283 | batch_vowel_recall=0.9767 | consonant_recall=0.9743 | grapheme_recall=0.9493 | loss=0.8402 | tar=0.9630 | vowel_recall=0.9790\n",
            "[2020-02-08 05:54:57,710] \n",
            "37/70 * Epoch 37 (train): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2465.6378 | _timers/batch_time=0.1032 | _timers/data_time=0.0756 | _timers/model_time=0.0263 | batch_consonant_recall=0.7996 | batch_grapheme_recall=0.7517 | batch_vowel_recall=0.7838 | consonant_recall=0.7892 | grapheme_recall=0.7618 | loss=1.9577 | tar=0.7734 | vowel_recall=0.7809\n",
            "37/70 * Epoch 37 (valid): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2691.4925 | _timers/batch_time=0.1607 | _timers/data_time=0.1442 | _timers/model_time=0.0164 | batch_consonant_recall=0.9731 | batch_grapheme_recall=0.9306 | batch_vowel_recall=0.9754 | consonant_recall=0.9734 | grapheme_recall=0.9518 | loss=0.9551 | tar=0.9638 | vowel_recall=0.9781\n",
            "[2020-02-08 06:03:00,649] \n",
            "38/70 * Epoch 38 (train): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=2442.5223 | _timers/batch_time=0.1091 | _timers/data_time=0.0806 | _timers/model_time=0.0272 | batch_consonant_recall=0.7892 | batch_grapheme_recall=0.7454 | batch_vowel_recall=0.7769 | consonant_recall=0.7781 | grapheme_recall=0.7557 | loss=2.0138 | tar=0.7657 | vowel_recall=0.7732\n",
            "38/70 * Epoch 38 (valid): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3327.0799 | _timers/batch_time=0.1651 | _timers/data_time=0.1492 | _timers/model_time=0.0159 | batch_consonant_recall=0.9774 | batch_grapheme_recall=0.9340 | batch_vowel_recall=0.9816 | consonant_recall=0.9765 | grapheme_recall=0.9539 | loss=0.5150 | tar=0.9667 | vowel_recall=0.9828\n",
            "[2020-02-08 06:11:06,433] \n",
            "39/70 * Epoch 39 (train): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=2422.2643 | _timers/batch_time=0.1101 | _timers/data_time=0.0820 | _timers/model_time=0.0268 | batch_consonant_recall=0.7965 | batch_grapheme_recall=0.7567 | batch_vowel_recall=0.7872 | consonant_recall=0.7848 | grapheme_recall=0.7684 | loss=1.8888 | tar=0.7761 | vowel_recall=0.7830\n",
            "39/70 * Epoch 39 (valid): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=2744.0819 | _timers/batch_time=0.1653 | _timers/data_time=0.1494 | _timers/model_time=0.0158 | batch_consonant_recall=0.9759 | batch_grapheme_recall=0.9367 | batch_vowel_recall=0.9802 | consonant_recall=0.9763 | grapheme_recall=0.9551 | loss=0.5110 | tar=0.9673 | vowel_recall=0.9827\n",
            "[2020-02-08 06:19:19,050] \n",
            "40/70 * Epoch 40 (train): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=2371.5887 | _timers/batch_time=0.1065 | _timers/data_time=0.0783 | _timers/model_time=0.0268 | batch_consonant_recall=0.7957 | batch_grapheme_recall=0.7552 | batch_vowel_recall=0.7748 | consonant_recall=0.7824 | grapheme_recall=0.7640 | loss=1.9003 | tar=0.7705 | vowel_recall=0.7716\n",
            "40/70 * Epoch 40 (valid): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=3398.3897 | _timers/batch_time=0.1543 | _timers/data_time=0.1392 | _timers/model_time=0.0150 | batch_consonant_recall=0.9799 | batch_grapheme_recall=0.9378 | batch_vowel_recall=0.9823 | consonant_recall=0.9798 | grapheme_recall=0.9576 | loss=0.4682 | tar=0.9696 | vowel_recall=0.9835\n",
            "[2020-02-08 06:27:00,671] \n",
            "41/70 * Epoch 41 (train): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2720.1792 | _timers/batch_time=0.0941 | _timers/data_time=0.0671 | _timers/model_time=0.0256 | batch_consonant_recall=0.7870 | batch_grapheme_recall=0.7434 | batch_vowel_recall=0.7726 | consonant_recall=0.7794 | grapheme_recall=0.7525 | loss=1.9794 | tar=0.7637 | vowel_recall=0.7703\n",
            "41/70 * Epoch 41 (valid): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=3340.5205 | _timers/batch_time=0.1558 | _timers/data_time=0.1398 | _timers/model_time=0.0159 | batch_consonant_recall=0.9774 | batch_grapheme_recall=0.9358 | batch_vowel_recall=0.9786 | consonant_recall=0.9752 | grapheme_recall=0.9551 | loss=0.7668 | tar=0.9665 | vowel_recall=0.9806\n",
            "[2020-02-08 06:34:39,919] \n",
            "42/70 * Epoch 42 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2683.2833 | _timers/batch_time=0.0937 | _timers/data_time=0.0665 | _timers/model_time=0.0259 | batch_consonant_recall=0.8090 | batch_grapheme_recall=0.7688 | batch_vowel_recall=0.7916 | consonant_recall=0.7996 | grapheme_recall=0.7772 | loss=1.7766 | tar=0.7857 | vowel_recall=0.7886\n",
            "42/70 * Epoch 42 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=3531.8096 | _timers/batch_time=0.1521 | _timers/data_time=0.1365 | _timers/model_time=0.0156 | batch_consonant_recall=0.9792 | batch_grapheme_recall=0.9383 | batch_vowel_recall=0.9799 | consonant_recall=0.9779 | grapheme_recall=0.9571 | loss=0.7318 | tar=0.9684 | vowel_recall=0.9817\n",
            "[2020-02-08 06:42:29,592] \n",
            "43/70 * Epoch 43 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2535.7345 | _timers/batch_time=0.0984 | _timers/data_time=0.0708 | _timers/model_time=0.0262 | batch_consonant_recall=0.7908 | batch_grapheme_recall=0.7515 | batch_vowel_recall=0.7776 | consonant_recall=0.7781 | grapheme_recall=0.7596 | loss=1.9195 | tar=0.7678 | vowel_recall=0.7740\n",
            "43/70 * Epoch 43 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2996.1768 | _timers/batch_time=0.1666 | _timers/data_time=0.1504 | _timers/model_time=0.0161 | batch_consonant_recall=0.9793 | batch_grapheme_recall=0.9394 | batch_vowel_recall=0.9817 | consonant_recall=0.9782 | grapheme_recall=0.9578 | loss=0.4933 | tar=0.9692 | vowel_recall=0.9831\n",
            "[2020-02-08 06:50:24,967] \n",
            "44/70 * Epoch 44 (train): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2464.4685 | _timers/batch_time=0.1051 | _timers/data_time=0.0772 | _timers/model_time=0.0266 | batch_consonant_recall=0.7979 | batch_grapheme_recall=0.7565 | batch_vowel_recall=0.7818 | consonant_recall=0.7867 | grapheme_recall=0.7643 | loss=1.8500 | tar=0.7737 | vowel_recall=0.7794\n",
            "44/70 * Epoch 44 (valid): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2358.3082 | _timers/batch_time=0.1556 | _timers/data_time=0.1404 | _timers/model_time=0.0151 | batch_consonant_recall=0.9749 | batch_grapheme_recall=0.9354 | batch_vowel_recall=0.9792 | consonant_recall=0.9736 | grapheme_recall=0.9550 | loss=0.7732 | tar=0.9662 | vowel_recall=0.9812\n",
            "[2020-02-08 06:58:30,485] \n",
            "45/70 * Epoch 45 (train): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2678.6435 | _timers/batch_time=0.0996 | _timers/data_time=0.0722 | _timers/model_time=0.0261 | batch_consonant_recall=0.8004 | batch_grapheme_recall=0.7586 | batch_vowel_recall=0.7852 | consonant_recall=0.7917 | grapheme_recall=0.7652 | loss=1.8149 | tar=0.7762 | vowel_recall=0.7828\n",
            "45/70 * Epoch 45 (valid): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=3296.9285 | _timers/batch_time=0.1588 | _timers/data_time=0.1426 | _timers/model_time=0.0162 | batch_consonant_recall=0.9791 | batch_grapheme_recall=0.9399 | batch_vowel_recall=0.9820 | consonant_recall=0.9779 | grapheme_recall=0.9588 | loss=0.4731 | tar=0.9699 | vowel_recall=0.9840\n",
            "[2020-02-08 07:06:26,201] \n",
            "46/70 * Epoch 46 (train): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2545.1397 | _timers/batch_time=0.1023 | _timers/data_time=0.0744 | _timers/model_time=0.0266 | batch_consonant_recall=0.7975 | batch_grapheme_recall=0.7551 | batch_vowel_recall=0.7829 | consonant_recall=0.7910 | grapheme_recall=0.7628 | loss=1.9038 | tar=0.7740 | vowel_recall=0.7792\n",
            "46/70 * Epoch 46 (valid): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=3154.3177 | _timers/batch_time=0.1597 | _timers/data_time=0.1439 | _timers/model_time=0.0158 | batch_consonant_recall=0.9776 | batch_grapheme_recall=0.9359 | batch_vowel_recall=0.9819 | consonant_recall=0.9766 | grapheme_recall=0.9557 | loss=0.6713 | tar=0.9679 | vowel_recall=0.9836\n",
            "[2020-02-08 07:14:21,603] \n",
            "47/70 * Epoch 47 (train): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2547.3092 | _timers/batch_time=0.1030 | _timers/data_time=0.0752 | _timers/model_time=0.0265 | batch_consonant_recall=0.7964 | batch_grapheme_recall=0.7479 | batch_vowel_recall=0.7783 | consonant_recall=0.7864 | grapheme_recall=0.7569 | loss=1.8930 | tar=0.7690 | vowel_recall=0.7759\n",
            "47/70 * Epoch 47 (valid): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=3316.8358 | _timers/batch_time=0.1637 | _timers/data_time=0.1481 | _timers/model_time=0.0155 | batch_consonant_recall=0.9742 | batch_grapheme_recall=0.9353 | batch_vowel_recall=0.9802 | consonant_recall=0.9748 | grapheme_recall=0.9541 | loss=0.6816 | tar=0.9662 | vowel_recall=0.9819\n",
            "[2020-02-08 07:22:12,252] \n",
            "48/70 * Epoch 48 (train): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2508.2274 | _timers/batch_time=0.1022 | _timers/data_time=0.0740 | _timers/model_time=0.0269 | batch_consonant_recall=0.7958 | batch_grapheme_recall=0.7448 | batch_vowel_recall=0.7794 | consonant_recall=0.7830 | grapheme_recall=0.7534 | loss=1.9242 | tar=0.7666 | vowel_recall=0.7767\n",
            "48/70 * Epoch 48 (valid): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2775.1052 | _timers/batch_time=0.1552 | _timers/data_time=0.1398 | _timers/model_time=0.0153 | batch_consonant_recall=0.9755 | batch_grapheme_recall=0.9344 | batch_vowel_recall=0.9812 | consonant_recall=0.9771 | grapheme_recall=0.9554 | loss=0.6312 | tar=0.9677 | vowel_recall=0.9831\n",
            "[2020-02-08 07:30:04,864] \n",
            "49/70 * Epoch 49 (train): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2472.5447 | _timers/batch_time=0.1021 | _timers/data_time=0.0742 | _timers/model_time=0.0265 | batch_consonant_recall=0.7871 | batch_grapheme_recall=0.7303 | batch_vowel_recall=0.7664 | consonant_recall=0.7754 | grapheme_recall=0.7390 | loss=2.0695 | tar=0.7545 | vowel_recall=0.7646\n",
            "49/70 * Epoch 49 (valid): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=3399.7325 | _timers/batch_time=0.1595 | _timers/data_time=0.1441 | _timers/model_time=0.0153 | batch_consonant_recall=0.9755 | batch_grapheme_recall=0.9328 | batch_vowel_recall=0.9802 | consonant_recall=0.9725 | grapheme_recall=0.9526 | loss=0.6494 | tar=0.9649 | vowel_recall=0.9821\n",
            "[2020-02-08 07:37:51,153] \n",
            "50/70 * Epoch 50 (train): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2577.4559 | _timers/batch_time=0.0977 | _timers/data_time=0.0707 | _timers/model_time=0.0257 | batch_consonant_recall=0.7741 | batch_grapheme_recall=0.7107 | batch_vowel_recall=0.7548 | consonant_recall=0.7610 | grapheme_recall=0.7192 | loss=2.2388 | tar=0.7384 | vowel_recall=0.7544\n",
            "50/70 * Epoch 50 (valid): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2647.6032 | _timers/batch_time=0.1550 | _timers/data_time=0.1400 | _timers/model_time=0.0149 | batch_consonant_recall=0.9746 | batch_grapheme_recall=0.9304 | batch_vowel_recall=0.9785 | consonant_recall=0.9739 | grapheme_recall=0.9524 | loss=0.7540 | tar=0.9648 | vowel_recall=0.9805\n",
            "[2020-02-08 07:45:33,504] \n",
            "51/70 * Epoch 51 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2578.7537 | _timers/batch_time=0.0963 | _timers/data_time=0.0691 | _timers/model_time=0.0258 | batch_consonant_recall=0.7734 | batch_grapheme_recall=0.7102 | batch_vowel_recall=0.7536 | consonant_recall=0.7597 | grapheme_recall=0.7184 | loss=2.2583 | tar=0.7372 | vowel_recall=0.7524\n",
            "51/70 * Epoch 51 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3252.4386 | _timers/batch_time=0.1490 | _timers/data_time=0.1339 | _timers/model_time=0.0150 | batch_consonant_recall=0.9705 | batch_grapheme_recall=0.9296 | batch_vowel_recall=0.9800 | consonant_recall=0.9664 | grapheme_recall=0.9517 | loss=0.6299 | tar=0.9628 | vowel_recall=0.9813\n",
            "[2020-02-08 07:52:55,839] \n",
            "52/70 * Epoch 52 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2952.7595 | _timers/batch_time=0.0819 | _timers/data_time=0.0562 | _timers/model_time=0.0245 | batch_consonant_recall=0.7856 | batch_grapheme_recall=0.7207 | batch_vowel_recall=0.7671 | consonant_recall=0.7734 | grapheme_recall=0.7333 | loss=2.1360 | tar=0.7511 | vowel_recall=0.7646\n",
            "52/70 * Epoch 52 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3621.1311 | _timers/batch_time=0.1420 | _timers/data_time=0.1272 | _timers/model_time=0.0147 | batch_consonant_recall=0.9717 | batch_grapheme_recall=0.9273 | batch_vowel_recall=0.9791 | consonant_recall=0.9744 | grapheme_recall=0.9507 | loss=0.9219 | tar=0.9643 | vowel_recall=0.9814\n",
            "[2020-02-08 08:00:15,619] \n",
            "53/70 * Epoch 53 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3024.9813 | _timers/batch_time=0.0799 | _timers/data_time=0.0545 | _timers/model_time=0.0241 | batch_consonant_recall=0.7675 | batch_grapheme_recall=0.7072 | batch_vowel_recall=0.7537 | consonant_recall=0.7546 | grapheme_recall=0.7186 | loss=2.3365 | tar=0.7361 | vowel_recall=0.7526\n",
            "53/70 * Epoch 53 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3405.2957 | _timers/batch_time=0.1408 | _timers/data_time=0.1261 | _timers/model_time=0.0146 | batch_consonant_recall=0.9554 | batch_grapheme_recall=0.8780 | batch_vowel_recall=0.9573 | consonant_recall=0.9582 | grapheme_recall=0.8983 | loss=1.2586 | tar=0.9290 | vowel_recall=0.9611\n",
            "[2020-02-08 08:07:36,072] \n",
            "54/70 * Epoch 54 (train): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2921.6104 | _timers/batch_time=0.0806 | _timers/data_time=0.0547 | _timers/model_time=0.0245 | batch_consonant_recall=0.7673 | batch_grapheme_recall=0.7013 | batch_vowel_recall=0.7453 | consonant_recall=0.7526 | grapheme_recall=0.7139 | loss=2.3150 | tar=0.7313 | vowel_recall=0.7446\n",
            "54/70 * Epoch 54 (valid): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2781.3214 | _timers/batch_time=0.1407 | _timers/data_time=0.1267 | _timers/model_time=0.0139 | batch_consonant_recall=0.9693 | batch_grapheme_recall=0.9268 | batch_vowel_recall=0.9774 | consonant_recall=0.9696 | grapheme_recall=0.9477 | loss=1.0422 | tar=0.9611 | vowel_recall=0.9792\n",
            "[2020-02-08 08:14:56,175] \n",
            "55/70 * Epoch 55 (train): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2922.1635 | _timers/batch_time=0.0802 | _timers/data_time=0.0546 | _timers/model_time=0.0244 | batch_consonant_recall=0.8030 | batch_grapheme_recall=0.7478 | batch_vowel_recall=0.7842 | consonant_recall=0.7847 | grapheme_recall=0.7570 | loss=1.9471 | tar=0.7704 | vowel_recall=0.7829\n",
            "55/70 * Epoch 55 (valid): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=3489.5256 | _timers/batch_time=0.1411 | _timers/data_time=0.1265 | _timers/model_time=0.0145 | batch_consonant_recall=0.9757 | batch_grapheme_recall=0.9326 | batch_vowel_recall=0.9791 | consonant_recall=0.9770 | grapheme_recall=0.9554 | loss=0.7167 | tar=0.9672 | vowel_recall=0.9810\n",
            "[2020-02-08 08:22:17,092] \n",
            "56/70 * Epoch 56 (train): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2985.4917 | _timers/batch_time=0.0801 | _timers/data_time=0.0545 | _timers/model_time=0.0244 | batch_consonant_recall=0.7722 | batch_grapheme_recall=0.7189 | batch_vowel_recall=0.7577 | consonant_recall=0.7572 | grapheme_recall=0.7323 | loss=2.1714 | tar=0.7441 | vowel_recall=0.7548\n",
            "56/70 * Epoch 56 (valid): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=3223.9804 | _timers/batch_time=0.1441 | _timers/data_time=0.1290 | _timers/model_time=0.0150 | batch_consonant_recall=0.9744 | batch_grapheme_recall=0.9307 | batch_vowel_recall=0.9786 | consonant_recall=0.9722 | grapheme_recall=0.9504 | loss=0.8221 | tar=0.9634 | vowel_recall=0.9806\n",
            "[2020-02-08 08:29:46,783] \n",
            "57/70 * Epoch 57 (train): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2763.1365 | _timers/batch_time=0.0874 | _timers/data_time=0.0612 | _timers/model_time=0.0249 | batch_consonant_recall=0.7931 | batch_grapheme_recall=0.7467 | batch_vowel_recall=0.7797 | consonant_recall=0.7817 | grapheme_recall=0.7570 | loss=1.9950 | tar=0.7681 | vowel_recall=0.7766\n",
            "57/70 * Epoch 57 (valid): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2798.7335 | _timers/batch_time=0.1431 | _timers/data_time=0.1282 | _timers/model_time=0.0148 | batch_consonant_recall=0.9728 | batch_grapheme_recall=0.9335 | batch_vowel_recall=0.9789 | consonant_recall=0.9724 | grapheme_recall=0.9540 | loss=0.9549 | tar=0.9652 | vowel_recall=0.9803\n",
            "[2020-02-08 08:37:12,280] \n",
            "58/70 * Epoch 58 (train): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=2898.4494 | _timers/batch_time=0.0842 | _timers/data_time=0.0587 | _timers/model_time=0.0243 | batch_consonant_recall=0.7949 | batch_grapheme_recall=0.7471 | batch_vowel_recall=0.7794 | consonant_recall=0.7803 | grapheme_recall=0.7564 | loss=1.9345 | tar=0.7675 | vowel_recall=0.7767\n",
            "58/70 * Epoch 58 (valid): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3573.7790 | _timers/batch_time=0.1411 | _timers/data_time=0.1267 | _timers/model_time=0.0143 | batch_consonant_recall=0.9744 | batch_grapheme_recall=0.9349 | batch_vowel_recall=0.9799 | consonant_recall=0.9735 | grapheme_recall=0.9539 | loss=0.6645 | tar=0.9657 | vowel_recall=0.9816\n",
            "[2020-02-08 08:44:29,074] \n",
            "59/70 * Epoch 59 (train): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=3065.6416 | _timers/batch_time=0.0771 | _timers/data_time=0.0521 | _timers/model_time=0.0238 | batch_consonant_recall=0.7893 | batch_grapheme_recall=0.7450 | batch_vowel_recall=0.7771 | consonant_recall=0.7812 | grapheme_recall=0.7550 | loss=1.9432 | tar=0.7666 | vowel_recall=0.7752\n",
            "59/70 * Epoch 59 (valid): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=3416.4439 | _timers/batch_time=0.1399 | _timers/data_time=0.1263 | _timers/model_time=0.0136 | batch_consonant_recall=0.9786 | batch_grapheme_recall=0.9356 | batch_vowel_recall=0.9823 | consonant_recall=0.9796 | grapheme_recall=0.9559 | loss=0.6392 | tar=0.9686 | vowel_recall=0.9831\n",
            "[2020-02-08 08:51:49,209] \n",
            "60/70 * Epoch 60 (train): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=3023.2601 | _timers/batch_time=0.0793 | _timers/data_time=0.0545 | _timers/model_time=0.0235 | batch_consonant_recall=0.7900 | batch_grapheme_recall=0.7545 | batch_vowel_recall=0.7744 | consonant_recall=0.7741 | grapheme_recall=0.7635 | loss=1.9023 | tar=0.7683 | vowel_recall=0.7722\n",
            "60/70 * Epoch 60 (valid): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=2714.8415 | _timers/batch_time=0.1409 | _timers/data_time=0.1268 | _timers/model_time=0.0140 | batch_consonant_recall=0.9783 | batch_grapheme_recall=0.9377 | batch_vowel_recall=0.9803 | consonant_recall=0.9774 | grapheme_recall=0.9559 | loss=0.5803 | tar=0.9681 | vowel_recall=0.9830\n",
            "[2020-02-08 08:59:10,264] \n",
            "61/70 * Epoch 61 (train): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=3051.5334 | _timers/batch_time=0.0804 | _timers/data_time=0.0552 | _timers/model_time=0.0240 | batch_consonant_recall=0.8033 | batch_grapheme_recall=0.7640 | batch_vowel_recall=0.7831 | consonant_recall=0.7917 | grapheme_recall=0.7727 | loss=1.8463 | tar=0.7795 | vowel_recall=0.7808\n",
            "61/70 * Epoch 61 (valid): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2897.8996 | _timers/batch_time=0.1412 | _timers/data_time=0.1269 | _timers/model_time=0.0142 | batch_consonant_recall=0.9760 | batch_grapheme_recall=0.9399 | batch_vowel_recall=0.9812 | consonant_recall=0.9735 | grapheme_recall=0.9584 | loss=0.5767 | tar=0.9684 | vowel_recall=0.9832\n",
            "[2020-02-08 09:06:30,506] \n",
            "62/70 * Epoch 62 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2962.2738 | _timers/batch_time=0.0806 | _timers/data_time=0.0549 | _timers/model_time=0.0244 | batch_consonant_recall=0.7994 | batch_grapheme_recall=0.7604 | batch_vowel_recall=0.7807 | consonant_recall=0.7918 | grapheme_recall=0.7697 | loss=1.8275 | tar=0.7775 | vowel_recall=0.7787\n",
            "62/70 * Epoch 62 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=3331.2029 | _timers/batch_time=0.1429 | _timers/data_time=0.1287 | _timers/model_time=0.0141 | batch_consonant_recall=0.9768 | batch_grapheme_recall=0.9375 | batch_vowel_recall=0.9805 | consonant_recall=0.9753 | grapheme_recall=0.9557 | loss=0.8391 | tar=0.9674 | vowel_recall=0.9829\n",
            "[2020-02-08 09:14:03,444] \n",
            "63/70 * Epoch 63 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2944.9130 | _timers/batch_time=0.0837 | _timers/data_time=0.0577 | _timers/model_time=0.0246 | batch_consonant_recall=0.7866 | batch_grapheme_recall=0.7469 | batch_vowel_recall=0.7661 | consonant_recall=0.7808 | grapheme_recall=0.7552 | loss=1.9428 | tar=0.7641 | vowel_recall=0.7652\n",
            "63/70 * Epoch 63 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=3281.3179 | _timers/batch_time=0.1688 | _timers/data_time=0.1521 | _timers/model_time=0.0166 | batch_consonant_recall=0.9779 | batch_grapheme_recall=0.9368 | batch_vowel_recall=0.9807 | consonant_recall=0.9788 | grapheme_recall=0.9553 | loss=0.6199 | tar=0.9679 | vowel_recall=0.9824\n",
            "[2020-02-08 09:22:09,863] \n",
            "64/70 * Epoch 64 (train): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2390.1736 | _timers/batch_time=0.1127 | _timers/data_time=0.0837 | _timers/model_time=0.0276 | batch_consonant_recall=0.8051 | batch_grapheme_recall=0.7657 | batch_vowel_recall=0.7861 | consonant_recall=0.7965 | grapheme_recall=0.7767 | loss=1.8106 | tar=0.7833 | vowel_recall=0.7835\n",
            "64/70 * Epoch 64 (valid): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2739.3122 | _timers/batch_time=0.1599 | _timers/data_time=0.1443 | _timers/model_time=0.0155 | batch_consonant_recall=0.9802 | batch_grapheme_recall=0.9376 | batch_vowel_recall=0.9817 | consonant_recall=0.9796 | grapheme_recall=0.9553 | loss=0.5836 | tar=0.9683 | vowel_recall=0.9832\n",
            "[2020-02-08 09:30:16,410] \n",
            "65/70 * Epoch 65 (train): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2383.7076 | _timers/batch_time=0.1128 | _timers/data_time=0.0831 | _timers/model_time=0.0281 | batch_consonant_recall=0.7862 | batch_grapheme_recall=0.7424 | batch_vowel_recall=0.7655 | consonant_recall=0.7797 | grapheme_recall=0.7510 | loss=1.9551 | tar=0.7608 | vowel_recall=0.7617\n",
            "65/70 * Epoch 65 (valid): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2821.2568 | _timers/batch_time=0.1632 | _timers/data_time=0.1474 | _timers/model_time=0.0157 | batch_consonant_recall=0.9750 | batch_grapheme_recall=0.9389 | batch_vowel_recall=0.9812 | consonant_recall=0.9735 | grapheme_recall=0.9567 | loss=0.7936 | tar=0.9675 | vowel_recall=0.9831\n",
            "[2020-02-08 09:38:17,884] \n",
            "66/70 * Epoch 66 (train): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2413.2976 | _timers/batch_time=0.1071 | _timers/data_time=0.0788 | _timers/model_time=0.0270 | batch_consonant_recall=0.7916 | batch_grapheme_recall=0.7479 | batch_vowel_recall=0.7739 | consonant_recall=0.7794 | grapheme_recall=0.7587 | loss=1.9052 | tar=0.7672 | vowel_recall=0.7720\n",
            "66/70 * Epoch 66 (valid): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2331.9157 | _timers/batch_time=0.1627 | _timers/data_time=0.1473 | _timers/model_time=0.0154 | batch_consonant_recall=0.9786 | batch_grapheme_recall=0.9378 | batch_vowel_recall=0.9816 | consonant_recall=0.9778 | grapheme_recall=0.9578 | loss=0.4796 | tar=0.9692 | vowel_recall=0.9833\n",
            "[2020-02-08 09:46:02,935] \n",
            "67/70 * Epoch 67 (train): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2465.6655 | _timers/batch_time=0.0973 | _timers/data_time=0.0704 | _timers/model_time=0.0257 | batch_consonant_recall=0.8002 | batch_grapheme_recall=0.7570 | batch_vowel_recall=0.7848 | consonant_recall=0.7900 | grapheme_recall=0.7669 | loss=1.8416 | tar=0.7768 | vowel_recall=0.7833\n",
            "67/70 * Epoch 67 (valid): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=3099.6745 | _timers/batch_time=0.1532 | _timers/data_time=0.1381 | _timers/model_time=0.0151 | batch_consonant_recall=0.9762 | batch_grapheme_recall=0.9380 | batch_vowel_recall=0.9813 | consonant_recall=0.9747 | grapheme_recall=0.9556 | loss=0.6099 | tar=0.9672 | vowel_recall=0.9830\n",
            "[2020-02-08 09:53:37,442] \n",
            "68/70 * Epoch 68 (train): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2723.6309 | _timers/batch_time=0.0917 | _timers/data_time=0.0648 | _timers/model_time=0.0256 | batch_consonant_recall=0.7933 | batch_grapheme_recall=0.7433 | batch_vowel_recall=0.7778 | consonant_recall=0.7806 | grapheme_recall=0.7527 | loss=1.9468 | tar=0.7651 | vowel_recall=0.7743\n",
            "68/70 * Epoch 68 (valid): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=3122.9414 | _timers/batch_time=0.1458 | _timers/data_time=0.1308 | _timers/model_time=0.0149 | batch_consonant_recall=0.9748 | batch_grapheme_recall=0.9342 | batch_vowel_recall=0.9793 | consonant_recall=0.9747 | grapheme_recall=0.9557 | loss=0.5367 | tar=0.9668 | vowel_recall=0.9812\n",
            "[2020-02-08 10:01:08,114] \n",
            "69/70 * Epoch 69 (train): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2752.9789 | _timers/batch_time=0.0880 | _timers/data_time=0.0613 | _timers/model_time=0.0254 | batch_consonant_recall=0.7744 | batch_grapheme_recall=0.7199 | batch_vowel_recall=0.7608 | consonant_recall=0.7614 | grapheme_recall=0.7290 | loss=2.1206 | tar=0.7445 | vowel_recall=0.7588\n",
            "69/70 * Epoch 69 (valid): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2926.7499 | _timers/batch_time=0.1465 | _timers/data_time=0.1318 | _timers/model_time=0.0147 | batch_consonant_recall=0.9745 | batch_grapheme_recall=0.9297 | batch_vowel_recall=0.9812 | consonant_recall=0.9734 | grapheme_recall=0.9525 | loss=0.7138 | tar=0.9653 | vowel_recall=0.9827\n",
            "[2020-02-08 10:08:30,460] \n",
            "70/70 * Epoch 70 (train): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2905.7803 | _timers/batch_time=0.0822 | _timers/data_time=0.0564 | _timers/model_time=0.0245 | batch_consonant_recall=0.7749 | batch_grapheme_recall=0.7165 | batch_vowel_recall=0.7594 | consonant_recall=0.7642 | grapheme_recall=0.7256 | loss=2.1334 | tar=0.7437 | vowel_recall=0.7594\n",
            "70/70 * Epoch 70 (valid): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=3091.9656 | _timers/batch_time=0.1422 | _timers/data_time=0.1279 | _timers/model_time=0.0143 | batch_consonant_recall=0.9719 | batch_grapheme_recall=0.9291 | batch_vowel_recall=0.9800 | consonant_recall=0.9723 | grapheme_recall=0.9505 | loss=0.7840 | tar=0.9639 | vowel_recall=0.9822\n",
            "Top best models:\n",
            "output/fold0/checkpoints/train.45.pth\t0.9699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IhArTZXhDEdO"
      },
      "source": [
        "## Check performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "32PY32ziDEdP",
        "colab": {}
      },
      "source": [
        "def load_model(config: edict, bin_path: Union[str, Path]):\n",
        "    # config.model.pretrained = None\n",
        "    model = get_model(config)\n",
        "    state_dict = torch.load(bin_path, map_location=get_device())\n",
        "    if \"model_state_dict\" in state_dict.keys():\n",
        "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
        "    else:\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9_F9IDJdDEdS",
        "colab": {}
      },
      "source": [
        "def macro_average_recall(prediction: np.ndarray, df: pd.DataFrame):\n",
        "    grapheme = recall_score(\n",
        "        df[\"grapheme_root\"].values, prediction[:, 0], average=\"macro\")\n",
        "    vowel = recall_score(\n",
        "        df[\"vowel_diacritic\"].values, prediction[:, 1], average=\"macro\")\n",
        "    consonant = recall_score(\n",
        "        df[\"consonant_diacritic\"].values, prediction[:, 2], average=\"macro\")\n",
        "    return np.average([grapheme, vowel, consonant], weights=[2, 1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XPVll_NsDEdV",
        "colab": {}
      },
      "source": [
        "def inference_loop(model: nn.Module,\n",
        "                   loader: torchdata.DataLoader,\n",
        "                   cls_levels: dict,\n",
        "                   loss_fn: Optional[nn.Module] = None,\n",
        "                   requires_soft=False):\n",
        "    n_grapheme = cls_levels[\"grapheme\"]\n",
        "    n_vowel = cls_levels[\"vowel\"]\n",
        "    n_consonant = cls_levels[\"consonant\"]\n",
        "\n",
        "    dataset_length = len(loader.dataset)\n",
        "    prediction = np.zeros((dataset_length, 3), dtype=np.uint8)\n",
        "    if requires_soft:\n",
        "        soft_prediction = np.zeros(\n",
        "            (dataset_length, n_grapheme + n_vowel + n_consonant),\n",
        "            dtype=np.float32)\n",
        "\n",
        "    batch_size = loader.batch_size\n",
        "    device = get_device()\n",
        "\n",
        "    avg_loss = 0.\n",
        "    model.eval()\n",
        "\n",
        "    targets: Optional[torch.Tensor] = None\n",
        "\n",
        "    for i, batch in enumerate(progress_bar(loader, leave=False)):\n",
        "        with torch.no_grad():\n",
        "            if isinstance(batch, dict):\n",
        "                images = batch[\"images\"].to(device)\n",
        "                targets = batch[\"targets\"].to(device)\n",
        "            else:\n",
        "                images = batch.to(device)\n",
        "                targets = None\n",
        "            pred = model(images).detach()\n",
        "            if loss_fn is not None and targets is not None:\n",
        "                avg_loss += loss_fn(\n",
        "                    pred, batch[\"targets\"].to(device)).item() / len(loader)\n",
        "            head = 0\n",
        "            tail = n_grapheme\n",
        "            pred_grapheme = torch.argmax(\n",
        "                pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "            head = tail\n",
        "            tail = head + n_vowel\n",
        "            pred_vowel = torch.argmax(pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "            head = tail\n",
        "            tail = head + n_consonant\n",
        "            pred_consonant = torch.argmax(\n",
        "                pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "            prediction[i * batch_size:(i + 1) * batch_size, 0] = pred_grapheme\n",
        "            prediction[i * batch_size:(i + 1) * batch_size, 1] = pred_vowel\n",
        "            prediction[i * batch_size:(i + 1) * batch_size, 2] = pred_consonant\n",
        "\n",
        "            if requires_soft:\n",
        "                head = 0\n",
        "                tail = n_grapheme\n",
        "                soft_prediction[i * batch_size:(i + 1) *\n",
        "                                batch_size, head:tail] = F.softmax(\n",
        "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "                head = tail\n",
        "                tail = head + n_vowel\n",
        "                soft_prediction[i * batch_size:(i + 1) *\n",
        "                                batch_size, head:tail] = F.softmax(\n",
        "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "                head = tail\n",
        "                tail = head + n_consonant\n",
        "                soft_prediction[i * batch_size:(i + 1) *\n",
        "                                batch_size, head:tail] = F.softmax(\n",
        "                                    pred[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "    return_dict = {\"prediction\": prediction, \"loss\": avg_loss}\n",
        "    if requires_soft:\n",
        "        return_dict[\"soft_prediction\"] = soft_prediction\n",
        "\n",
        "    return return_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPKIgJnMDEdY",
        "outputId": "f2479c4d-029c-48ef-c823-5e5c0b47da6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checkpoint_path = f\"output/fold{i}/checkpoints/best.pth\"\n",
        "model = load_model(config, checkpoint_path)\n",
        "model.to(get_device())\n",
        "loader = data_loaders[\"valid\"]\n",
        "\n",
        "prediction = inference_loop(\n",
        "    model,\n",
        "    loader,\n",
        "    cls_levels,\n",
        "    criterion,\n",
        "    requires_soft=False)\n",
        "score = macro_average_recall(prediction[\"prediction\"], val_df)\n",
        "print(f\"Score: {score:.5f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Score: 0.97002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BF64LRYqK1l6",
        "colab": {}
      },
      "source": [
        "!cp output/fold0/checkpoints/best.pth /content/gdrive/My\\ Drive/kaggle-bengali/checkpoints/fold0/resnet34_210epoch_size128_weighted_loss_mixup.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tf7pT23OU1X1",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}