{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Colab-Train.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33NabMBXKwoL",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEhILX5KwoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n",
        "pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n",
        "pip install pretrainedmodels==0.7.4 >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V8VzSgVKwoT",
        "colab_type": "text"
      },
      "source": [
        "## Integration with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-lXTjFHKwoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "30bf4c2c-2d84-47f2-d27a-e6b1d842731b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfI_vnU9KwoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "mkdir input\n",
        "cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n",
        "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHYxI6rdKwoa",
        "colab_type": "text"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JJVr1fZKwob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d216bc-77b8-44b6-f313-0cc5a8d128b5"
      },
      "source": [
        "import albumentations as A\n",
        "import catalyst as ct\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pretrainedmodels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as torchdata\n",
        "import yaml\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Union, Optional, List\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
        "from easydict import EasyDict as edict\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from skimage.transform import AffineTransform, warp\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n",
        "                                      CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB0aMP-X4qGe",
        "colab_type": "text"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HNqP0T_4pyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USmf2YqUKwoe",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzqNckioKwof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_string = '''\n",
        "dataset:\n",
        "  affine: True\n",
        "  morphology: True\n",
        "\n",
        "data:\n",
        "  train_df_path: input/bengaliai-cv19/train.csv\n",
        "  train_images_path: input/bengaliai-cv19/train_images\n",
        "  test_images_path: input/bengaliai-cv19/test_images\n",
        "  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n",
        "\n",
        "model:\n",
        "  model_name: se_resnext50_32x4d\n",
        "  pretrained: imagenet\n",
        "  num_classes: 186\n",
        "\n",
        "train:\n",
        "  batch_size: 32\n",
        "  num_epochs: 50\n",
        "\n",
        "test:\n",
        "  batch_size: 32\n",
        "\n",
        "loss:\n",
        "  name: bce\n",
        "  params:\n",
        "    n_grapheme: 168\n",
        "    n_vowel: 11\n",
        "    n_consonant: 7\n",
        "\n",
        "optimizer:\n",
        "  name: Adam\n",
        "  params:\n",
        "    lr: 0.001\n",
        "\n",
        "scheduler:\n",
        "  name: plateau\n",
        "\n",
        "transforms:\n",
        "  Noise: True\n",
        "  Contrast: True\n",
        "  Cutout:\n",
        "    num_holes: 0\n",
        "\n",
        "val:\n",
        "  name: kfold\n",
        "  params:\n",
        "    random_state: 42\n",
        "    n_splits: 5\n",
        "\n",
        "log_dir: log/\n",
        "num_workers: 2\n",
        "seed: 1213\n",
        "img_size: 64\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB2wzOKGKwoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_default():\n",
        "    cfg = edict()\n",
        "\n",
        "    # dataset\n",
        "    cfg.dataset = edict()\n",
        "    cfg.dataset.affine = False\n",
        "    cfg.dataset.morphology = False\n",
        "\n",
        "    # dataset\n",
        "    cfg.data = edict()\n",
        "\n",
        "    # model\n",
        "    cfg.model = edict()\n",
        "\n",
        "    # train\n",
        "    cfg.train = edict()\n",
        "\n",
        "    # test\n",
        "    cfg.test = edict()\n",
        "\n",
        "    # loss\n",
        "    cfg.loss = edict()\n",
        "    cfg.loss.params = edict()\n",
        "\n",
        "    # optimizer\n",
        "    cfg.optimizer = edict()\n",
        "    cfg.optimizer.params = edict()\n",
        "\n",
        "    # scheduler\n",
        "    cfg.scheduler = edict()\n",
        "    cfg.scheduler.params = edict()\n",
        "\n",
        "    # transforms:\n",
        "    cfg.transforms = edict()\n",
        "    cfg.transforms.HorizontalFlip = False\n",
        "    cfg.transforms.VerticalFlip = False\n",
        "    cfg.transforms.Noise = False\n",
        "    cfg.transforms.Contrast = False\n",
        "    cfg.transforms.Cutout = edict()\n",
        "    cfg.transforms.Cutout.num_holes = 0\n",
        "    cfg.transforms.mean = [0.485, 0.456, 0.406]\n",
        "    cfg.transforms.std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # val\n",
        "    cfg.val = edict()\n",
        "    cfg.val.params = edict()\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def _merge_config(src: edict, dst: edict):\n",
        "    if not isinstance(src, edict):\n",
        "        return\n",
        "    for k, v in src.items():\n",
        "        if isinstance(v, edict):\n",
        "            _merge_config(src[k], dst[k])\n",
        "        else:\n",
        "            dst[k] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXzDYNKKwol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n",
        "config = _get_default()\n",
        "_merge_config(cfg, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDwtD7_qKwoo",
        "colab_type": "text"
      },
      "source": [
        "## Environmental settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvltP9XNKwor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "e57cc351-7a46-4a3b-819f-d010e731bbb0"
      },
      "source": [
        "ct.utils.set_global_seed(config.seed)\n",
        "ct.utils.prepare_cudnn(deterministic=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE-bSL4wKwou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_base_dir = Path(\"output\")\n",
        "output_base_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_images_path = Path(config.data.train_images_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izzn1pfQKwox",
        "colab_type": "text"
      },
      "source": [
        "## Data and utilities preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2g3_Wh2Kwoy",
        "colab_type": "text"
      },
      "source": [
        "### validation utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p56BR9OKwoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def no_fold(df: pd.DataFrame,\n",
        "            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    idx = np.arange(len(df))\n",
        "    trn_idx, val_idx = train_test_split(idx, **params)\n",
        "    return [(trn_idx, val_idx)]\n",
        "\n",
        "\n",
        "def kfold(df: pd.DataFrame,\n",
        "          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    params = config.val.params\n",
        "    kf = KFold(shuffle=True, **params)\n",
        "    splits = list(kf.split(df))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def get_validation(df: pd.DataFrame,\n",
        "                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    name: str = config.val.name\n",
        "\n",
        "    func = globals().get(name)\n",
        "    if func is None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return func(df, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7OiqfkKwo1",
        "colab_type": "text"
      },
      "source": [
        "### transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qer87L9pKwo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_transforms(config: edict):\n",
        "    list_transforms = []\n",
        "    if config.transforms.HorizontalFlip:\n",
        "        list_transforms.append(A.HorizontalFrip())\n",
        "    if config.transforms.VerticalFlip:\n",
        "        list_transforms.append(A.VerticalFlip())\n",
        "    if config.transforms.Noise:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n",
        "    if config.transforms.Contrast:\n",
        "        list_transforms.append(\n",
        "            A.OneOf(\n",
        "                [A.RandomContrast(0.5),\n",
        "                 A.RandomGamma(),\n",
        "                 A.RandomBrightness()],\n",
        "                p=0.5))\n",
        "    if config.transforms.Cutout.num_holes > 0:\n",
        "        list_transforms.append(A.Cutout(**config.Cutout))\n",
        "\n",
        "    list_transforms.append(\n",
        "        A.Normalize(\n",
        "            mean=config.transforms.mean, std=config.transforms.std, p=1))\n",
        "\n",
        "    return A.Compose(list_transforms, p=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muCpRi55Kwo4",
        "colab_type": "text"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEdk1aCZKwo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(config.data.train_df_path)\n",
        "splits = get_validation(df, config)\n",
        "transforms = get_transforms(config)\n",
        "\n",
        "cls_levels = {\n",
        "    \"grapheme\": df.grapheme_root.nunique(),\n",
        "    \"vowel\": df.vowel_diacritic.nunique(),\n",
        "    \"consonant\": df.consonant_diacritic.nunique()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7tkhAAjKwo8",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR70FZllKwo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_image(image: np.ndarray, threshold=5. / 255.) -> np.ndarray:\n",
        "    assert image.ndim == 2\n",
        "    is_black = image > threshold\n",
        "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
        "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
        "\n",
        "    left = np.argmax(is_black_horizontal)\n",
        "    right = np.argmax(is_black_horizontal[::-1])\n",
        "    top = np.argmax(is_black_vertical)\n",
        "    bottom = np.argmax(is_black_vertical[::-1])\n",
        "    height, width = image.shape\n",
        "    cropped_image = image[left:height - right, top:width - bottom]\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def resize(image, size=(128, 128)) -> np.ndarray:\n",
        "    return cv2.resize(image, size)\n",
        "\n",
        "\n",
        "def crop_and_embed(image: np.ndarray, size=(128, 128), threshold=20. / 255.):\n",
        "    cropped = crop_image(image, threshold)\n",
        "    height, width = cropped.shape\n",
        "    aspect_ratio = height / width\n",
        "    embedded = np.zeros(size)\n",
        "    if aspect_ratio > 1.0:\n",
        "        if height > size[0]:\n",
        "            new_height = size[0]\n",
        "            new_width = int(size[0] * 1 / aspect_ratio)\n",
        "            image = resize(cropped, size=(new_width, new_height))\n",
        "\n",
        "            margin = size[1] - new_width\n",
        "            head = margin // 2\n",
        "            embedded[:, head:head + new_width] = image\n",
        "        else:\n",
        "            margin = size[0] - height\n",
        "\n",
        "            new_height = height + np.random.randint(0, margin)\n",
        "            new_width = int(new_height * 1 / aspect_ratio)\n",
        "            image = resize(cropped, size=(new_width, new_height))\n",
        "\n",
        "            margin_height = size[0] - new_height\n",
        "            margin_width = size[1] - new_width\n",
        "\n",
        "            head_height = margin_height // 2\n",
        "            head_width = margin_width // 2\n",
        "            embedded[head_height:head_height +\n",
        "                     new_height, head_width:head_width + new_width] = image\n",
        "    else:\n",
        "        if width > size[1]:\n",
        "            new_width = size[1]\n",
        "            new_height = int(size[1] * aspect_ratio)\n",
        "            image = resize(cropped, size=(new_width, new_height))\n",
        "\n",
        "            margin = size[0] - new_height\n",
        "            head = margin // 2\n",
        "            embedded[head:head + new_height, :] = image\n",
        "        else:\n",
        "            margin = size[1] - width\n",
        "\n",
        "            new_width = width + np.random.randint(0, margin)\n",
        "            new_height = int(new_width * aspect_ratio)\n",
        "            image = resize(cropped, size=(new_width, new_height))\n",
        "\n",
        "            margin_height = size[0] - new_height\n",
        "            margin_width = size[1] - new_width\n",
        "\n",
        "            head_height = margin_height // 2\n",
        "            head_width = margin_width // 2\n",
        "            embedded[head_height:head_height +\n",
        "                     new_height, head_width:head_width + new_width] = image\n",
        "\n",
        "    return embedded\n",
        "\n",
        "\n",
        "def normalize(image: np.ndarray):\n",
        "    if image.ndim == 3:\n",
        "        image = image[:, :, 0]\n",
        "    image = (255 - image).astype(np.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def to_image(image: np.ndarray):\n",
        "    if image.ndim == 2:\n",
        "        image = np.stack([image, image, image])\n",
        "        image = np.moveaxis(image, 0, -1)\n",
        "    image = (255 - image * 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "\n",
        "def affine_image(image: np.ndarray):\n",
        "    assert image.ndim == 2\n",
        "    min_scale = 0.8\n",
        "    max_scale = 1.2\n",
        "    sx = np.random.uniform(min_scale, max_scale)\n",
        "    sy = np.random.uniform(min_scale, max_scale)\n",
        "\n",
        "    max_rot_angle = 10\n",
        "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
        "\n",
        "    max_shear_angle = 10\n",
        "    shear_angle = np.random.uniform(-max_shear_angle,\n",
        "                                    max_shear_angle) * np.pi / 180.\n",
        "\n",
        "    max_translation = 4\n",
        "    tx = np.random.randint(-max_translation, max_translation)\n",
        "    ty = np.random.randint(-max_translation, max_translation)\n",
        "\n",
        "    tform = AffineTransform(\n",
        "        scale=(sx, sy),\n",
        "        rotation=rot_angle,\n",
        "        shear=shear_angle,\n",
        "        translation=(tx, ty))\n",
        "    transformed_image = warp(image, tform)\n",
        "    return transformed_image\n",
        "\n",
        "\n",
        "def random_erosion_or_dilation(image: np.ndarray):\n",
        "    dice = np.random.randint(0, 3)\n",
        "    if dice == 0:\n",
        "        return image\n",
        "    elif dice == 1:\n",
        "        kernel = np.ones((3, 3), dtype=np.uint8)\n",
        "        return cv2.erode(image, kernel, iterations=1)\n",
        "    else:\n",
        "        kernel = np.ones((3, 3), dtype=np.uint8)\n",
        "        return cv2.dilate(image, kernel, iterations=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xvp6ssDKwpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainDataset(torchdata.Dataset):\n",
        "    def __init__(self,\n",
        "                 image_dir: Path,\n",
        "                 df: pd.DataFrame,\n",
        "                 transforms,\n",
        "                 size: Tuple[int, int],\n",
        "                 cls_levels: Dict[str, int] = None,\n",
        "                 affine=True,\n",
        "                 morphology=True,\n",
        "                 onehot=True):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.size = size\n",
        "        self.onehot = onehot\n",
        "        self.cls_levels = cls_levels\n",
        "        self.affine = affine\n",
        "        self.morphology = morphology\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df.loc[idx, \"image_id\"]\n",
        "        image_path = self.image_dir / f\"{image_id}.png\"\n",
        "\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image = normalize(image)\n",
        "        image = crop_and_embed(image, size=self.size, threshold=5. / 255.)\n",
        "        if self.affine:\n",
        "            image = affine_image(image)\n",
        "        if self.morphology:\n",
        "            image = random_erosion_or_dilation(image)\n",
        "        image = to_image(image)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)[\"image\"]\n",
        "        if image.shape[2] == 3:\n",
        "            image = np.moveaxis(image, -1, 0)\n",
        "        grapheme = self.df.loc[idx, \"grapheme_root\"]\n",
        "        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n",
        "        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n",
        "\n",
        "        if self.onehot:\n",
        "            grapheme_levels = self.cls_levels[\"grapheme\"]\n",
        "            vowel_levels = self.cls_levels[\"vowel\"]\n",
        "            consonant_levels = self.cls_levels[\"consonant\"]\n",
        "            total_n_levels = grapheme_levels + vowel_levels + consonant_levels\n",
        "            label = np.zeros(total_n_levels, dtype=np.float32)\n",
        "            label[grapheme] = 1.0\n",
        "            label[grapheme_levels + vowel] = 1.0\n",
        "            label[grapheme_levels + vowel_levels + consonant] = 1.0\n",
        "\n",
        "        else:\n",
        "            label = np.zeros(3, dtype=int)\n",
        "            label[0] = grapheme\n",
        "            label[1] = vowel\n",
        "            label[2] = consonant\n",
        "        return {\"images\": image, \"targets\": label}\n",
        "\n",
        "\n",
        "class TestDataset(torchdata.Dataset):\n",
        "    def __init__(self,\n",
        "                 image_dir: Path,\n",
        "                 df: pd.DataFrame,\n",
        "                 transforms,\n",
        "                 size: Tuple[int, int],\n",
        "                 affine=True,\n",
        "                 morphology=True):\n",
        "        self.image_dir = image_dir\n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "        self.size = size\n",
        "        self.affine = affine\n",
        "        self.morphology = morphology\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df.loc[idx, \"image_id\"]\n",
        "        image_path = self.image_dir / f\"{image_id}.png\"\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = normalize(image)\n",
        "        image = crop_and_embed(image, size=self.size, threshold=5. / 255.)\n",
        "        if self.affine:\n",
        "            image = affine_image(image)\n",
        "        if self.morphology:\n",
        "            image = random_erosion_or_dilation(image)\n",
        "        image = to_image(image)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)[\"image\"]\n",
        "        if image.shape[2] == 3:\n",
        "            image = np.moveaxis(image, -1, 0)\n",
        "        return image\n",
        "\n",
        "\n",
        "def get_loader(df: pd.DataFrame,\n",
        "               image_dir: Path,\n",
        "               phase: str = \"train\",\n",
        "               size: Tuple[int, int] = (128, 128),\n",
        "               batch_size=256,\n",
        "               num_workers=2,\n",
        "               transforms=None,\n",
        "               cls_levels=None,\n",
        "               affine=True,\n",
        "               morphology=True,\n",
        "               onehot=None):\n",
        "    assert phase in [\"train\", \"valid\", \"test\"]\n",
        "    if phase == \"test\":\n",
        "        dataset = TestDataset(image_dir, df, transforms, size, affine,\n",
        "                              morphology)\n",
        "        is_shuffle = False\n",
        "        drop_last = False\n",
        "    else:\n",
        "        if phase == \"train\":\n",
        "            is_shuffle = True\n",
        "            drop_last = True\n",
        "        else:\n",
        "            is_shuffle = False\n",
        "            drop_last = False\n",
        "        if onehot is not None:\n",
        "            if cls_levels is None:\n",
        "                raise ValueError(\n",
        "                    \"if 'onehot' is set to None, cls_levels must be set\")\n",
        "            else:\n",
        "                dataset = TrainDataset(  # type: ignore\n",
        "                    image_dir,\n",
        "                    df,\n",
        "                    transforms,\n",
        "                    size,\n",
        "                    cls_levels,\n",
        "                    affine=affine,\n",
        "                    morphology=morphology,\n",
        "                    onehot=onehot)\n",
        "        else:\n",
        "            dataset = TrainDataset(  # type: ignore\n",
        "                image_dir,\n",
        "                df,\n",
        "                transforms,\n",
        "                size,\n",
        "                affine=affine,\n",
        "                morphology=morphology)\n",
        "    return torchdata.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=drop_last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRSPrkp_KwpD",
        "colab_type": "text"
      },
      "source": [
        "## Model and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt8H0kDqKwpD",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey32J5_BKwpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengaliClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str, num_classes: int, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "        self.num_classes = num_classes\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        if \"se_resnext\" in self.model_name:\n",
        "            self.base = getattr(pretrainedmodels,\n",
        "                                self.model_name)(pretrained=pretrained)\n",
        "            self.base.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "            self.base.last_linear = nn.Linear(\n",
        "                self.base.last_linear.in_features, self.num_classes)\n",
        "        elif \"resnet\" in self.model_name:\n",
        "            self.base = getattr(pretrainedmodels,\n",
        "                                self.model_name)(pretrained=pretrained)\n",
        "            self.base.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "            self.base.fc = nn.Linear(self.base.fc.in_features,\n",
        "                                     self.num_classes)\n",
        "        elif \"efficientnet\" in self.model_name:\n",
        "            if pretrained:\n",
        "                self.base = EfficientNet.from_pretrained(self.model_name)\n",
        "            else:\n",
        "                self.base = EfficientNet.from_name(self.model_name)\n",
        "            self.base._fc = nn.Linear(self.base._fc.in_features,\n",
        "                                      self.num_classes)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def fresh_params(self):\n",
        "        if \"se_resnext\" in self.model_name:\n",
        "            return self.base.last_linear.parameters()\n",
        "        elif \"resnet\" in self.model_name:\n",
        "            return self.base.fc.parameters()\n",
        "        elif \"efficientnet\" in self.model_name:\n",
        "            return self.base._fc.parameters()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def base_params(self):\n",
        "        params = []\n",
        "        if \"se_resnext\" in self.model_name:\n",
        "            fc_name = \"last_linear\"\n",
        "        elif \"resnet\" in self.model_name:\n",
        "            fc_name = \"fc\"\n",
        "        elif \"efficientnet\" in self.model_name:\n",
        "            fc_name = \"_fc\"\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        for name, param in self.net.named_parameters():\n",
        "            if fc_name not in name:\n",
        "                params.append(param)\n",
        "        return params\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yGn8bXpKwpG",
        "colab_type": "text"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG4H1Z04KwpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengaliCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, 0]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, 1]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, 2]\n",
        "\n",
        "        return self.cross_entropy(grapheme_pred, grapheme_true) + \\\n",
        "            self.cross_entropy(vowel_pred, vowel_true) + \\\n",
        "            self.cross_entropy(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "class BengaliBCELoss(nn.Module):\n",
        "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
        "        super().__init__()\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme_pred = pred[:, head:tail]\n",
        "        grapheme_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel_pred = pred[:, head:tail]\n",
        "        vowel_true = true[:, head:tail]\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant_pred = pred[:, head:tail]\n",
        "        consonant_true = true[:, head:tail]\n",
        "\n",
        "        return self.bce(grapheme_pred, grapheme_true) + \\\n",
        "            self.bce(vowel_pred, vowel_true) + \\\n",
        "            self.bce(consonant_pred, consonant_true)\n",
        "\n",
        "\n",
        "def get_loss(config: edict):\n",
        "    name = config.loss.name\n",
        "    params = config.loss.params\n",
        "    if name == \"bce\":\n",
        "        criterion = BengaliBCELoss(**params)\n",
        "    elif name == \"cross_entropy\":\n",
        "        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VRL8e21KwpK",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJiWlNg5KwpK",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmBA7SsEKwpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Optimizer = Union[Adam, SGD]\n",
        "\n",
        "\n",
        "def get_optimizer(model, config: edict) -> Optimizer:\n",
        "    name = config.optimizer.name\n",
        "    params = config.optimizer.params\n",
        "    if name == \"Adam\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    elif name == \"SGD\":\n",
        "        optimizer = Adam(model.parameters(), **params)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UsyO8GKwpO",
        "colab_type": "text"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjotHZyDKwpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Scheduler = Optional[\n",
        "    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, config: edict) -> Scheduler:\n",
        "    params = config.scheduler.params\n",
        "    name = config.scheduler.name\n",
        "    scheduler: Scheduler = None\n",
        "    if name == \"plateau\":\n",
        "        scheduler = ReduceLROnPlateau(optimizer, **params)\n",
        "    elif name == \"cosine\":\n",
        "        scheduler = CosineAnnealingLR(optimizer, **params)\n",
        "    elif name == \"cosine_warmup\":\n",
        "        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n",
        "\n",
        "    return scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_KIlxPKwpR",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW3x-uJ6KwpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MacroAverageRecall(Callback):\n",
        "    def __init__(self,\n",
        "                 n_grapheme=168,\n",
        "                 n_vowel=11,\n",
        "                 n_consonant=7,\n",
        "                 prefix: str = \"mar\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 target_key: str = \"targets\"):\n",
        "        self.prefix = prefix\n",
        "        self.output_key = output_key\n",
        "        self.target_key = target_key\n",
        "        self.n_grapheme = n_grapheme\n",
        "        self.n_vowel = n_vowel\n",
        "        self.n_consonant = n_consonant\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "    def on_batch_end(self, state: RunnerState):\n",
        "        targ = state.input[self.target_key].detach()\n",
        "        out = state.output[self.output_key]\n",
        "        head = 0\n",
        "        tail = self.n_grapheme\n",
        "        grapheme = torch.sigmoid(out[:, head:tail])\n",
        "        grapheme_np = torch.argmax(grapheme, dim=1).detach().cpu().numpy()\n",
        "        grapheme_target = torch.argmax(targ[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_vowel\n",
        "        vowel = torch.sigmoid(out[:, head:tail])\n",
        "        vowel_np = torch.argmax(vowel, dim=1).detach().cpu().numpy()\n",
        "        vowel_target = torch.argmax(targ[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "        head = tail\n",
        "        tail = head + self.n_consonant\n",
        "        consonant = torch.sigmoid(out[:, head:tail])\n",
        "        consonant_np = torch.argmax(consonant, dim=1).detach().cpu().numpy()\n",
        "        consonant_target = torch.argmax(\n",
        "            targ[:, head:tail], dim=1).cpu().numpy()\n",
        "\n",
        "        scores = []\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                grapheme_target, grapheme_np, average=\"macro\",\n",
        "                zero_division=0))\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                vowel_target, vowel_np, average=\"macro\", zero_division=0))\n",
        "        scores.append(\n",
        "            recall_score(\n",
        "                consonant_target,\n",
        "                consonant_np,\n",
        "                average=\"macro\",\n",
        "                zero_division=0))\n",
        "        final_score = np.average(scores, weights=[2, 1, 1])\n",
        "        state.metrics.add_batch_value(name=self.prefix, value=final_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HN1iGwXKwpU",
        "colab_type": "text"
      },
      "source": [
        "## KFold Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osNWYzH_KwpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a07f3928-3264-4e5e-9d24-a1b172a9f6d3"
      },
      "source": [
        "trn_idx, val_idx = splits[i]\n",
        "\n",
        "print(f\"Fold: {i}\")\n",
        "\n",
        "output_dir = output_base_dir / f\"fold{i}\"\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n",
        "val_df = df.loc[val_idx, :].reset_index(drop=True)\n",
        "data_loaders = {\n",
        "    phase: get_loader(\n",
        "        df,\n",
        "        train_images_path,\n",
        "        phase=phase,\n",
        "        size=(config.img_size, config.img_size),\n",
        "        batch_size=config.train.batch_size,\n",
        "        num_workers=config.num_workers,\n",
        "        transforms=transforms,\n",
        "        cls_levels=cls_levels,\n",
        "        affine=config.dataset.affine,\n",
        "        morphology=config.dataset.morphology,\n",
        "        onehot=config.loss.name == \"bce\")\n",
        "    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
        "}\n",
        "model = BengaliClassifier(**config.model)\n",
        "criterion = get_loss(config)\n",
        "optimizer = get_optimizer(model, config)\n",
        "scheduler = get_scheduler(optimizer, config)\n",
        "\n",
        "runner = SupervisedRunner(\n",
        "    device=ct.utils.get_device(),\n",
        "    input_key=\"images\",\n",
        "    input_target_key=\"targets\",\n",
        "    output_key=\"logits\")\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    loaders=data_loaders,\n",
        "    scheduler=scheduler,\n",
        "    logdir=output_dir,\n",
        "    num_epochs=config.train.num_epochs,\n",
        "    callbacks=[MacroAverageRecall()],\n",
        "    main_metric=\"mar\",\n",
        "    minimize_metric=False,\n",
        "    monitoring_params=None,\n",
        "    verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n",
            "100%|██████████| 105M/105M [05:10<00:00, 356kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2020-01-27 07:41:56,651] \n",
            "1/50 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1044.9882 | _timers/batch_time=0.0312 | _timers/data_time=0.0010 | _timers/model_time=0.0302 | loss=0.2833 | mar=0.3581\n",
            "1/50 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=629.3426 | _timers/batch_time=0.0618 | _timers/data_time=0.0207 | _timers/model_time=0.0411 | loss=0.2195 | mar=0.4085\n",
            "[2020-01-27 07:54:37,501] \n",
            "2/50 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=996.8369 | _timers/batch_time=0.0330 | _timers/data_time=0.0014 | _timers/model_time=0.0316 | loss=0.2146 | mar=0.4282\n",
            "2/50 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=653.3421 | _timers/batch_time=0.0744 | _timers/data_time=0.0447 | _timers/model_time=0.0296 | loss=0.1994 | mar=0.4582\n",
            "[2020-01-27 08:07:23,697] \n",
            "3/50 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=978.5123 | _timers/batch_time=0.0331 | _timers/data_time=0.0010 | _timers/model_time=0.0320 | loss=0.1919 | mar=0.4705\n",
            "3/50 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=623.6802 | _timers/batch_time=0.0606 | _timers/data_time=0.0186 | _timers/model_time=0.0419 | loss=0.1779 | mar=0.4943\n",
            "[2020-01-27 08:20:04,176] \n",
            "4/50 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=991.4298 | _timers/batch_time=0.0327 | _timers/data_time=0.0010 | _timers/model_time=0.0317 | loss=0.1780 | mar=0.5004\n",
            "4/50 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=595.0792 | _timers/batch_time=0.0627 | _timers/data_time=0.0189 | _timers/model_time=0.0438 | loss=0.1672 | mar=0.5193\n",
            "[2020-01-27 08:32:34,479] \n",
            "5/50 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1002.3746 | _timers/batch_time=0.0323 | _timers/data_time=0.0010 | _timers/model_time=0.0313 | loss=0.1669 | mar=0.5272\n",
            "5/50 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=606.2935 | _timers/batch_time=0.0622 | _timers/data_time=0.0190 | _timers/model_time=0.0432 | loss=0.1584 | mar=0.5510\n",
            "[2020-01-27 08:44:49,223] \n",
            "6/50 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1024.5635 | _timers/batch_time=0.0317 | _timers/data_time=0.0010 | _timers/model_time=0.0306 | loss=0.1598 | mar=0.5440\n",
            "6/50 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=609.0373 | _timers/batch_time=0.0608 | _timers/data_time=0.0180 | _timers/model_time=0.0427 | loss=0.1539 | mar=0.5585\n",
            "[2020-01-27 08:57:02,332] \n",
            "7/50 * Epoch 7 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1028.5845 | _timers/batch_time=0.0315 | _timers/data_time=0.0010 | _timers/model_time=0.0305 | loss=0.1552 | mar=0.5567\n",
            "7/50 * Epoch 7 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=630.6764 | _timers/batch_time=0.0607 | _timers/data_time=0.0194 | _timers/model_time=0.0413 | loss=0.1502 | mar=0.5726\n",
            "[2020-01-27 09:09:13,079] \n",
            "8/50 * Epoch 8 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1036.1710 | _timers/batch_time=0.0313 | _timers/data_time=0.0009 | _timers/model_time=0.0303 | loss=0.1479 | mar=0.5733\n",
            "8/50 * Epoch 8 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=632.7409 | _timers/batch_time=0.0602 | _timers/data_time=0.0193 | _timers/model_time=0.0408 | loss=0.1470 | mar=0.5855\n",
            "[2020-01-27 09:21:20,313] \n",
            "9/50 * Epoch 9 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1042.2883 | _timers/batch_time=0.0311 | _timers/data_time=0.0009 | _timers/model_time=0.0302 | loss=0.1453 | mar=0.5838\n",
            "9/50 * Epoch 9 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=621.7201 | _timers/batch_time=0.0614 | _timers/data_time=0.0194 | _timers/model_time=0.0419 | loss=0.1393 | mar=0.6005\n",
            "[2020-01-27 09:33:59,567] \n",
            "10/50 * Epoch 10 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=986.4768 | _timers/batch_time=0.0328 | _timers/data_time=0.0011 | _timers/model_time=0.0317 | loss=0.1414 | mar=0.5948\n",
            "10/50 * Epoch 10 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=585.7642 | _timers/batch_time=0.0637 | _timers/data_time=0.0184 | _timers/model_time=0.0453 | loss=0.1389 | mar=0.6085\n",
            "[2020-01-27 09:47:01,101] \n",
            "11/50 * Epoch 11 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=954.3391 | _timers/batch_time=0.0339 | _timers/data_time=0.0012 | _timers/model_time=0.0326 | loss=0.1389 | mar=0.6028\n",
            "11/50 * Epoch 11 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=571.2553 | _timers/batch_time=0.0653 | _timers/data_time=0.0190 | _timers/model_time=0.0463 | loss=0.1410 | mar=0.6085\n",
            "[2020-01-27 09:59:59,928] \n",
            "12/50 * Epoch 12 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=960.4484 | _timers/batch_time=0.0337 | _timers/data_time=0.0011 | _timers/model_time=0.0325 | loss=0.1352 | mar=0.6125\n",
            "12/50 * Epoch 12 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=582.7710 | _timers/batch_time=0.0633 | _timers/data_time=0.0180 | _timers/model_time=0.0453 | loss=0.1317 | mar=0.6305\n",
            "[2020-01-27 10:12:44,284] \n",
            "13/50 * Epoch 13 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=982.8934 | _timers/batch_time=0.0330 | _timers/data_time=0.0011 | _timers/model_time=0.0319 | loss=0.1335 | mar=0.6198\n",
            "13/50 * Epoch 13 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=593.9749 | _timers/batch_time=0.0625 | _timers/data_time=0.0183 | _timers/model_time=0.0441 | loss=0.1286 | mar=0.6336\n",
            "[2020-01-27 10:25:16,295] \n",
            "14/50 * Epoch 14 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=998.7619 | _timers/batch_time=0.0324 | _timers/data_time=0.0011 | _timers/model_time=0.0313 | loss=0.1298 | mar=0.6273\n",
            "14/50 * Epoch 14 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=602.1019 | _timers/batch_time=0.0623 | _timers/data_time=0.0186 | _timers/model_time=0.0437 | loss=0.1305 | mar=0.6375\n",
            "[2020-01-27 10:38:08,184] \n",
            "15/50 * Epoch 15 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=974.2979 | _timers/batch_time=0.0333 | _timers/data_time=0.0011 | _timers/model_time=0.0321 | loss=0.1281 | mar=0.6324\n",
            "15/50 * Epoch 15 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=564.7281 | _timers/batch_time=0.0656 | _timers/data_time=0.0185 | _timers/model_time=0.0471 | loss=0.1303 | mar=0.6375\n",
            "[2020-01-27 10:50:58,845] \n",
            "16/50 * Epoch 16 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=965.9426 | _timers/batch_time=0.0335 | _timers/data_time=0.0011 | _timers/model_time=0.0324 | loss=0.1267 | mar=0.6366\n",
            "16/50 * Epoch 16 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=610.7519 | _timers/batch_time=0.0612 | _timers/data_time=0.0177 | _timers/model_time=0.0434 | loss=0.1261 | mar=0.6483\n",
            "[2020-01-27 11:02:50,725] \n",
            "17/50 * Epoch 17 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1047.7287 | _timers/batch_time=0.0309 | _timers/data_time=0.0010 | _timers/model_time=0.0298 | loss=0.1248 | mar=0.6432\n",
            "17/50 * Epoch 17 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=624.8572 | _timers/batch_time=0.0588 | _timers/data_time=0.0167 | _timers/model_time=0.0421 | loss=0.1276 | mar=0.6482\n",
            "[2020-01-27 11:14:43,392] \n",
            "18/50 * Epoch 18 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1051.7129 | _timers/batch_time=0.0308 | _timers/data_time=0.0011 | _timers/model_time=0.0297 | loss=0.1217 | mar=0.6483\n",
            "18/50 * Epoch 18 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.0161 | _timers/batch_time=0.0592 | _timers/data_time=0.0172 | _timers/model_time=0.0419 | loss=0.1219 | mar=0.6601\n",
            "[2020-01-27 11:26:39,472] \n",
            "19/50 * Epoch 19 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1046.3133 | _timers/batch_time=0.0310 | _timers/data_time=0.0011 | _timers/model_time=0.0299 | loss=0.1208 | mar=0.6532\n",
            "19/50 * Epoch 19 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.3629 | _timers/batch_time=0.0591 | _timers/data_time=0.0172 | _timers/model_time=0.0419 | loss=0.1198 | mar=0.6630\n",
            "[2020-01-27 11:38:32,590] \n",
            "20/50 * Epoch 20 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1051.1215 | _timers/batch_time=0.0308 | _timers/data_time=0.0011 | _timers/model_time=0.0297 | loss=0.1190 | mar=0.6573\n",
            "20/50 * Epoch 20 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=628.1505 | _timers/batch_time=0.0590 | _timers/data_time=0.0168 | _timers/model_time=0.0421 | loss=0.1199 | mar=0.6669\n",
            "[2020-01-27 11:50:27,386] \n",
            "21/50 * Epoch 21 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1047.2251 | _timers/batch_time=0.0310 | _timers/data_time=0.0011 | _timers/model_time=0.0298 | loss=0.1182 | mar=0.6601\n",
            "21/50 * Epoch 21 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=628.4007 | _timers/batch_time=0.0590 | _timers/data_time=0.0165 | _timers/model_time=0.0424 | loss=0.1194 | mar=0.6651\n",
            "[2020-01-27 12:02:20,532] \n",
            "22/50 * Epoch 22 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1055.3752 | _timers/batch_time=0.0307 | _timers/data_time=0.0010 | _timers/model_time=0.0296 | loss=0.1174 | mar=0.6631\n",
            "22/50 * Epoch 22 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=630.8140 | _timers/batch_time=0.0587 | _timers/data_time=0.0168 | _timers/model_time=0.0418 | loss=0.1168 | mar=0.6724\n",
            "[2020-01-27 12:14:13,453] \n",
            "23/50 * Epoch 23 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1054.4818 | _timers/batch_time=0.0307 | _timers/data_time=0.0011 | _timers/model_time=0.0296 | loss=0.1164 | mar=0.6663\n",
            "23/50 * Epoch 23 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=629.9910 | _timers/batch_time=0.0582 | _timers/data_time=0.0164 | _timers/model_time=0.0418 | loss=0.1180 | mar=0.6762\n",
            "[2020-01-27 12:25:55,946] \n",
            "24/50 * Epoch 24 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1069.6946 | _timers/batch_time=0.0303 | _timers/data_time=0.0011 | _timers/model_time=0.0292 | loss=0.1149 | mar=0.6712\n",
            "24/50 * Epoch 24 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=636.2182 | _timers/batch_time=0.0578 | _timers/data_time=0.0166 | _timers/model_time=0.0412 | loss=0.1250 | mar=0.6591\n",
            "Fold: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n",
            "100%|██████████| 105M/105M [05:10<00:00, 356kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2020-01-27 07:41:56,651] \n",
            "1/50 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1044.9882 | _timers/batch_time=0.0312 | _timers/data_time=0.0010 | _timers/model_time=0.0302 | loss=0.2833 | mar=0.3581\n",
            "1/50 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=629.3426 | _timers/batch_time=0.0618 | _timers/data_time=0.0207 | _timers/model_time=0.0411 | loss=0.2195 | mar=0.4085\n",
            "[2020-01-27 07:54:37,501] \n",
            "2/50 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=996.8369 | _timers/batch_time=0.0330 | _timers/data_time=0.0014 | _timers/model_time=0.0316 | loss=0.2146 | mar=0.4282\n",
            "2/50 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=653.3421 | _timers/batch_time=0.0744 | _timers/data_time=0.0447 | _timers/model_time=0.0296 | loss=0.1994 | mar=0.4582\n",
            "[2020-01-27 08:07:23,697] \n",
            "3/50 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=978.5123 | _timers/batch_time=0.0331 | _timers/data_time=0.0010 | _timers/model_time=0.0320 | loss=0.1919 | mar=0.4705\n",
            "3/50 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=623.6802 | _timers/batch_time=0.0606 | _timers/data_time=0.0186 | _timers/model_time=0.0419 | loss=0.1779 | mar=0.4943\n",
            "[2020-01-27 08:20:04,176] \n",
            "4/50 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=991.4298 | _timers/batch_time=0.0327 | _timers/data_time=0.0010 | _timers/model_time=0.0317 | loss=0.1780 | mar=0.5004\n",
            "4/50 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=595.0792 | _timers/batch_time=0.0627 | _timers/data_time=0.0189 | _timers/model_time=0.0438 | loss=0.1672 | mar=0.5193\n",
            "[2020-01-27 08:32:34,479] \n",
            "5/50 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1002.3746 | _timers/batch_time=0.0323 | _timers/data_time=0.0010 | _timers/model_time=0.0313 | loss=0.1669 | mar=0.5272\n",
            "5/50 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=606.2935 | _timers/batch_time=0.0622 | _timers/data_time=0.0190 | _timers/model_time=0.0432 | loss=0.1584 | mar=0.5510\n",
            "[2020-01-27 08:44:49,223] \n",
            "6/50 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1024.5635 | _timers/batch_time=0.0317 | _timers/data_time=0.0010 | _timers/model_time=0.0306 | loss=0.1598 | mar=0.5440\n",
            "6/50 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=609.0373 | _timers/batch_time=0.0608 | _timers/data_time=0.0180 | _timers/model_time=0.0427 | loss=0.1539 | mar=0.5585\n",
            "[2020-01-27 08:57:02,332] \n",
            "7/50 * Epoch 7 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1028.5845 | _timers/batch_time=0.0315 | _timers/data_time=0.0010 | _timers/model_time=0.0305 | loss=0.1552 | mar=0.5567\n",
            "7/50 * Epoch 7 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=630.6764 | _timers/batch_time=0.0607 | _timers/data_time=0.0194 | _timers/model_time=0.0413 | loss=0.1502 | mar=0.5726\n",
            "[2020-01-27 09:09:13,079] \n",
            "8/50 * Epoch 8 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1036.1710 | _timers/batch_time=0.0313 | _timers/data_time=0.0009 | _timers/model_time=0.0303 | loss=0.1479 | mar=0.5733\n",
            "8/50 * Epoch 8 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=632.7409 | _timers/batch_time=0.0602 | _timers/data_time=0.0193 | _timers/model_time=0.0408 | loss=0.1470 | mar=0.5855\n",
            "[2020-01-27 09:21:20,313] \n",
            "9/50 * Epoch 9 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1042.2883 | _timers/batch_time=0.0311 | _timers/data_time=0.0009 | _timers/model_time=0.0302 | loss=0.1453 | mar=0.5838\n",
            "9/50 * Epoch 9 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=621.7201 | _timers/batch_time=0.0614 | _timers/data_time=0.0194 | _timers/model_time=0.0419 | loss=0.1393 | mar=0.6005\n",
            "[2020-01-27 09:33:59,567] \n",
            "10/50 * Epoch 10 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=986.4768 | _timers/batch_time=0.0328 | _timers/data_time=0.0011 | _timers/model_time=0.0317 | loss=0.1414 | mar=0.5948\n",
            "10/50 * Epoch 10 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=585.7642 | _timers/batch_time=0.0637 | _timers/data_time=0.0184 | _timers/model_time=0.0453 | loss=0.1389 | mar=0.6085\n",
            "[2020-01-27 09:47:01,101] \n",
            "11/50 * Epoch 11 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=954.3391 | _timers/batch_time=0.0339 | _timers/data_time=0.0012 | _timers/model_time=0.0326 | loss=0.1389 | mar=0.6028\n",
            "11/50 * Epoch 11 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=571.2553 | _timers/batch_time=0.0653 | _timers/data_time=0.0190 | _timers/model_time=0.0463 | loss=0.1410 | mar=0.6085\n",
            "[2020-01-27 09:59:59,928] \n",
            "12/50 * Epoch 12 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=960.4484 | _timers/batch_time=0.0337 | _timers/data_time=0.0011 | _timers/model_time=0.0325 | loss=0.1352 | mar=0.6125\n",
            "12/50 * Epoch 12 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=582.7710 | _timers/batch_time=0.0633 | _timers/data_time=0.0180 | _timers/model_time=0.0453 | loss=0.1317 | mar=0.6305\n",
            "[2020-01-27 10:12:44,284] \n",
            "13/50 * Epoch 13 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=982.8934 | _timers/batch_time=0.0330 | _timers/data_time=0.0011 | _timers/model_time=0.0319 | loss=0.1335 | mar=0.6198\n",
            "13/50 * Epoch 13 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=593.9749 | _timers/batch_time=0.0625 | _timers/data_time=0.0183 | _timers/model_time=0.0441 | loss=0.1286 | mar=0.6336\n",
            "[2020-01-27 10:25:16,295] \n",
            "14/50 * Epoch 14 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=998.7619 | _timers/batch_time=0.0324 | _timers/data_time=0.0011 | _timers/model_time=0.0313 | loss=0.1298 | mar=0.6273\n",
            "14/50 * Epoch 14 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=602.1019 | _timers/batch_time=0.0623 | _timers/data_time=0.0186 | _timers/model_time=0.0437 | loss=0.1305 | mar=0.6375\n",
            "[2020-01-27 10:38:08,184] \n",
            "15/50 * Epoch 15 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=974.2979 | _timers/batch_time=0.0333 | _timers/data_time=0.0011 | _timers/model_time=0.0321 | loss=0.1281 | mar=0.6324\n",
            "15/50 * Epoch 15 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=564.7281 | _timers/batch_time=0.0656 | _timers/data_time=0.0185 | _timers/model_time=0.0471 | loss=0.1303 | mar=0.6375\n",
            "[2020-01-27 10:50:58,845] \n",
            "16/50 * Epoch 16 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=965.9426 | _timers/batch_time=0.0335 | _timers/data_time=0.0011 | _timers/model_time=0.0324 | loss=0.1267 | mar=0.6366\n",
            "16/50 * Epoch 16 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=610.7519 | _timers/batch_time=0.0612 | _timers/data_time=0.0177 | _timers/model_time=0.0434 | loss=0.1261 | mar=0.6483\n",
            "[2020-01-27 11:02:50,725] \n",
            "17/50 * Epoch 17 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1047.7287 | _timers/batch_time=0.0309 | _timers/data_time=0.0010 | _timers/model_time=0.0298 | loss=0.1248 | mar=0.6432\n",
            "17/50 * Epoch 17 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=624.8572 | _timers/batch_time=0.0588 | _timers/data_time=0.0167 | _timers/model_time=0.0421 | loss=0.1276 | mar=0.6482\n",
            "[2020-01-27 11:14:43,392] \n",
            "18/50 * Epoch 18 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1051.7129 | _timers/batch_time=0.0308 | _timers/data_time=0.0011 | _timers/model_time=0.0297 | loss=0.1217 | mar=0.6483\n",
            "18/50 * Epoch 18 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.0161 | _timers/batch_time=0.0592 | _timers/data_time=0.0172 | _timers/model_time=0.0419 | loss=0.1219 | mar=0.6601\n",
            "[2020-01-27 11:26:39,472] \n",
            "19/50 * Epoch 19 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1046.3133 | _timers/batch_time=0.0310 | _timers/data_time=0.0011 | _timers/model_time=0.0299 | loss=0.1208 | mar=0.6532\n",
            "19/50 * Epoch 19 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.3629 | _timers/batch_time=0.0591 | _timers/data_time=0.0172 | _timers/model_time=0.0419 | loss=0.1198 | mar=0.6630\n",
            "[2020-01-27 11:38:32,590] \n",
            "20/50 * Epoch 20 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1051.1215 | _timers/batch_time=0.0308 | _timers/data_time=0.0011 | _timers/model_time=0.0297 | loss=0.1190 | mar=0.6573\n",
            "20/50 * Epoch 20 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=628.1505 | _timers/batch_time=0.0590 | _timers/data_time=0.0168 | _timers/model_time=0.0421 | loss=0.1199 | mar=0.6669\n",
            "[2020-01-27 11:50:27,386] \n",
            "21/50 * Epoch 21 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1047.2251 | _timers/batch_time=0.0310 | _timers/data_time=0.0011 | _timers/model_time=0.0298 | loss=0.1182 | mar=0.6601\n",
            "21/50 * Epoch 21 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=628.4007 | _timers/batch_time=0.0590 | _timers/data_time=0.0165 | _timers/model_time=0.0424 | loss=0.1194 | mar=0.6651\n",
            "[2020-01-27 12:02:20,532] \n",
            "22/50 * Epoch 22 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1055.3752 | _timers/batch_time=0.0307 | _timers/data_time=0.0010 | _timers/model_time=0.0296 | loss=0.1174 | mar=0.6631\n",
            "22/50 * Epoch 22 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=630.8140 | _timers/batch_time=0.0587 | _timers/data_time=0.0168 | _timers/model_time=0.0418 | loss=0.1168 | mar=0.6724\n",
            "[2020-01-27 12:14:13,453] \n",
            "23/50 * Epoch 23 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1054.4818 | _timers/batch_time=0.0307 | _timers/data_time=0.0011 | _timers/model_time=0.0296 | loss=0.1164 | mar=0.6663\n",
            "23/50 * Epoch 23 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=629.9910 | _timers/batch_time=0.0582 | _timers/data_time=0.0164 | _timers/model_time=0.0418 | loss=0.1180 | mar=0.6762\n",
            "[2020-01-27 12:25:55,946] \n",
            "24/50 * Epoch 24 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1069.6946 | _timers/batch_time=0.0303 | _timers/data_time=0.0011 | _timers/model_time=0.0292 | loss=0.1149 | mar=0.6712\n",
            "24/50 * Epoch 24 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=636.2182 | _timers/batch_time=0.0578 | _timers/data_time=0.0166 | _timers/model_time=0.0412 | loss=0.1250 | mar=0.6591\n",
            "[2020-01-27 12:37:35,926] \n",
            "25/50 * Epoch 25 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1086.4882 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1147 | mar=0.6712\n",
            "25/50 * Epoch 25 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.2556 | _timers/batch_time=0.0583 | _timers/data_time=0.0166 | _timers/model_time=0.0417 | loss=0.1165 | mar=0.6784\n",
            "[2020-01-27 12:37:35,926] \n",
            "25/50 * Epoch 25 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1086.4882 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1147 | mar=0.6712\n",
            "25/50 * Epoch 25 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=634.2556 | _timers/batch_time=0.0583 | _timers/data_time=0.0166 | _timers/model_time=0.0417 | loss=0.1165 | mar=0.6784\n",
            "[2020-01-27 12:49:15,967] \n",
            "26/50 * Epoch 26 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1087.8496 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0289 | loss=0.1119 | mar=0.6772\n",
            "26/50 * Epoch 26 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=642.5594 | _timers/batch_time=0.0578 | _timers/data_time=0.0171 | _timers/model_time=0.0407 | loss=0.1157 | mar=0.6827\n",
            "[2020-01-27 12:49:15,967] \n",
            "26/50 * Epoch 26 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1087.8496 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0289 | loss=0.1119 | mar=0.6772\n",
            "26/50 * Epoch 26 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=642.5594 | _timers/batch_time=0.0578 | _timers/data_time=0.0171 | _timers/model_time=0.0407 | loss=0.1157 | mar=0.6827\n",
            "[2020-01-27 13:00:54,485] \n",
            "27/50 * Epoch 27 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1088.6847 | _timers/batch_time=0.0298 | _timers/data_time=0.0011 | _timers/model_time=0.0287 | loss=0.1125 | mar=0.6781\n",
            "27/50 * Epoch 27 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=651.5106 | _timers/batch_time=0.0571 | _timers/data_time=0.0169 | _timers/model_time=0.0401 | loss=0.1175 | mar=0.6841\n",
            "[2020-01-27 13:00:54,485] \n",
            "27/50 * Epoch 27 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1088.6847 | _timers/batch_time=0.0298 | _timers/data_time=0.0011 | _timers/model_time=0.0287 | loss=0.1125 | mar=0.6781\n",
            "27/50 * Epoch 27 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=651.5106 | _timers/batch_time=0.0571 | _timers/data_time=0.0169 | _timers/model_time=0.0401 | loss=0.1175 | mar=0.6841\n",
            "[2020-01-27 13:12:27,990] \n",
            "28/50 * Epoch 28 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1096.3519 | _timers/batch_time=0.0296 | _timers/data_time=0.0010 | _timers/model_time=0.0286 | loss=0.1116 | mar=0.6807\n",
            "28/50 * Epoch 28 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=640.5896 | _timers/batch_time=0.0581 | _timers/data_time=0.0168 | _timers/model_time=0.0412 | loss=0.1162 | mar=0.6827\n",
            "[2020-01-27 13:12:27,990] \n",
            "28/50 * Epoch 28 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1096.3519 | _timers/batch_time=0.0296 | _timers/data_time=0.0010 | _timers/model_time=0.0286 | loss=0.1116 | mar=0.6807\n",
            "28/50 * Epoch 28 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=640.5896 | _timers/batch_time=0.0581 | _timers/data_time=0.0168 | _timers/model_time=0.0412 | loss=0.1162 | mar=0.6827\n",
            "[2020-01-27 13:24:15,698] \n",
            "29/50 * Epoch 29 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1074.3087 | _timers/batch_time=0.0302 | _timers/data_time=0.0009 | _timers/model_time=0.0293 | loss=0.1103 | mar=0.6811\n",
            "29/50 * Epoch 29 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=638.1914 | _timers/batch_time=0.0583 | _timers/data_time=0.0174 | _timers/model_time=0.0409 | loss=0.1145 | mar=0.6877\n",
            "[2020-01-27 13:24:15,698] \n",
            "29/50 * Epoch 29 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1074.3087 | _timers/batch_time=0.0302 | _timers/data_time=0.0009 | _timers/model_time=0.0293 | loss=0.1103 | mar=0.6811\n",
            "29/50 * Epoch 29 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=638.1914 | _timers/batch_time=0.0583 | _timers/data_time=0.0174 | _timers/model_time=0.0409 | loss=0.1145 | mar=0.6877\n",
            "[2020-01-27 13:35:57,763] \n",
            "30/50 * Epoch 30 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1082.3981 | _timers/batch_time=0.0300 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1088 | mar=0.6859\n",
            "30/50 * Epoch 30 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=656.2418 | _timers/batch_time=0.0578 | _timers/data_time=0.0182 | _timers/model_time=0.0395 | loss=0.1094 | mar=0.6952\n",
            "[2020-01-27 13:35:57,763] \n",
            "30/50 * Epoch 30 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1082.3981 | _timers/batch_time=0.0300 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1088 | mar=0.6859\n",
            "30/50 * Epoch 30 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=656.2418 | _timers/batch_time=0.0578 | _timers/data_time=0.0182 | _timers/model_time=0.0395 | loss=0.1094 | mar=0.6952\n",
            "[2020-01-27 13:47:35,240] \n",
            "31/50 * Epoch 31 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1084.6946 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1085 | mar=0.6870\n",
            "31/50 * Epoch 31 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=657.8513 | _timers/batch_time=0.0579 | _timers/data_time=0.0183 | _timers/model_time=0.0395 | loss=0.1138 | mar=0.6937\n",
            "[2020-01-27 13:47:35,240] \n",
            "31/50 * Epoch 31 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1084.6946 | _timers/batch_time=0.0299 | _timers/data_time=0.0009 | _timers/model_time=0.0290 | loss=0.1085 | mar=0.6870\n",
            "31/50 * Epoch 31 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=657.8513 | _timers/batch_time=0.0579 | _timers/data_time=0.0183 | _timers/model_time=0.0395 | loss=0.1138 | mar=0.6937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTukaQrzNW8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}