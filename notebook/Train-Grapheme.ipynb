{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/koukyo1994/kaggle-bengali-ai/blob/master/notebook/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-LYW6ekKQ-x"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyICnC_QKQ-0"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install albumentations==0.4.3 catalyst==20.1.1 easydict==1.9.0 >> /dev/null\n",
    "pip install efficientnet-pytorch==0.6.1 PyYAML==5.3 >> /dev/null\n",
    "pip install pretrainedmodels==0.7.4 >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2m_PlwpKQ-5"
   },
   "source": [
    "## Integration with Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jsPLSeVuKQ-6",
    "outputId": "e1320f1b-675b-403b-e994-0117a256394e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3FN8jiWKQ--"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir input\n",
    "cp -r /content/gdrive/My\\ Drive/kaggle-bengali ./input/bengaliai-cv19\n",
    "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/train_images.zip\n",
    "unzip -qq -d input/bengaliai-cv19/ input/bengaliai-cv19/test_images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24Iv5BnEKQ_B"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qYrCK0t6KQ_C",
    "outputId": "46e5348d-5ba6-423a-de46-9cf9593b42b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import catalyst as ct\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "import torchvision.models as models\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Union, Optional, List\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
    "from catalyst.dl.callbacks import CriterionCallback\n",
    "from catalyst.utils import get_device\n",
    "from easydict import EasyDict as edict\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from fastprogress import progress_bar\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import (ReduceLROnPlateau, \n",
    "                                      CosineAnnealingLR,\n",
    "                                      CosineAnnealingWarmRestarts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tszhN7oGKQ_H"
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqfUxJd6KQ_I"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "trial = \"resnet34_size128_90epoch_grapheme\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXUZcRAGKQ_L"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S16TliO4KQ_M"
   },
   "outputs": [],
   "source": [
    "conf_string = '''\n",
    "dataset:\n",
    "  train:\n",
    "    affine: True\n",
    "    morphology: False\n",
    "  val:\n",
    "    affine: False\n",
    "    morphology: False\n",
    "  test:\n",
    "    affine: False\n",
    "    morphology: False\n",
    "\n",
    "data:\n",
    "  train_df_path: input/bengaliai-cv19/train.csv\n",
    "  train_images_path: input/bengaliai-cv19/train_images\n",
    "  test_images_path: input/bengaliai-cv19/test_images\n",
    "  sample_submission_path: input/bengaliai-cv19/sample_submission.csv\n",
    "\n",
    "model:\n",
    "  model_name: resnet34\n",
    "  pretrained: imagenet\n",
    "  num_classes: 186\n",
    "  head: custom\n",
    "  in_channels: 3\n",
    "  outputs:\n",
    "    - grapheme\n",
    "\n",
    "train:\n",
    "  batch_size: 128\n",
    "  num_epochs: 90\n",
    "\n",
    "test:\n",
    "  batch_size: 128\n",
    "\n",
    "loss:\n",
    "  name: grapheme\n",
    "  params:\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.0001\n",
    "\n",
    "scheduler:\n",
    "  name: cosine\n",
    "  params:\n",
    "    T_max: 10\n",
    "\n",
    "transforms:\n",
    "  train:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: True\n",
    "    RandomScale: True\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "  val:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: False\n",
    "    RandomScale: False\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "  test:\n",
    "    Noise: False\n",
    "    Contrast: False\n",
    "    Rotate: False\n",
    "    RandomScale: False\n",
    "    Cutout:\n",
    "      num_holes: 0\n",
    "\n",
    "val:\n",
    "  name: kfold\n",
    "  params:\n",
    "    random_state: 42\n",
    "    n_splits: 5\n",
    "\n",
    "callbacks:\n",
    "  - AverageRecall:\n",
    "      index: 0\n",
    "      offset: 0\n",
    "      n_classes: 168\n",
    "      prefix: grapheme_recall\n",
    "      loss_type: cross_entroy\n",
    "  - SaveWeightsCallback:\n",
    "      to: /content/gdrive/My Drive/kaggle-bengali/checkpoints/fold{}/\n",
    "      name: {}\n",
    "      is_larger_better: True\n",
    "      main_metric: tar\n",
    "\n",
    "log_dir: log/\n",
    "num_workers: 2\n",
    "seed: 1213\n",
    "img_size: 128\n",
    "main_metric: grapheme_recall\n",
    "'''.format(i, trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piePmxjjKQ_P"
   },
   "outputs": [],
   "source": [
    "def _get_default():\n",
    "    cfg = edict()\n",
    "\n",
    "    # dataset\n",
    "    cfg.dataset = edict()\n",
    "    cfg.dataset.train = edict()\n",
    "    cfg.dataset.val = edict()\n",
    "    cfg.dataset.test = edict()\n",
    "    cfg.dataset.train.affine = False\n",
    "    cfg.dataset.train.morphology = False\n",
    "    cfg.dataset.val.affine = False\n",
    "    cfg.dataset.val.morphology = False\n",
    "    cfg.dataset.test.affine = False\n",
    "    cfg.dataset.test.morphology = False\n",
    "\n",
    "    # dataset\n",
    "    cfg.data = edict()\n",
    "\n",
    "    # model\n",
    "    cfg.model = edict()\n",
    "    cfg.model.model_name = \"resnet18\"\n",
    "    cfg.model.num_classes = 186\n",
    "    cfg.model.pretrained = True\n",
    "    cfg.model.head = \"linear\"\n",
    "    cfg.model.in_channels = 3\n",
    "    cfg.model.outputs = [\"grapheme\", \"vowel\", \"consonant\"]\n",
    "\n",
    "    # train\n",
    "    cfg.train = edict()\n",
    "\n",
    "    # test\n",
    "    cfg.test = edict()\n",
    "\n",
    "    # loss\n",
    "    cfg.loss = edict()\n",
    "    cfg.loss.params = edict()\n",
    "\n",
    "    # optimizer\n",
    "    cfg.optimizer = edict()\n",
    "    cfg.optimizer.params = edict()\n",
    "\n",
    "    # scheduler\n",
    "    cfg.scheduler = edict()\n",
    "    cfg.scheduler.params = edict()\n",
    "\n",
    "    # transforms:\n",
    "    cfg.transforms = edict()\n",
    "    cfg.transforms.train = edict()\n",
    "    cfg.transforms.train.HorizontalFlip = False\n",
    "    cfg.transforms.train.VerticalFlip = False\n",
    "    cfg.transforms.train.Noise = False\n",
    "    cfg.transforms.train.Contrast = False\n",
    "    cfg.transforms.train.Rotate = False\n",
    "    cfg.transforms.train.RandomScale = False\n",
    "    cfg.transforms.train.Cutout = edict()\n",
    "    cfg.transforms.train.Cutout.num_holes = 0\n",
    "    cfg.transforms.val = edict()\n",
    "    cfg.transforms.val.HorizontalFlip = False\n",
    "    cfg.transforms.val.VerticalFlip = False\n",
    "    cfg.transforms.val.Noise = False\n",
    "    cfg.transforms.val.Contrast = False\n",
    "    cfg.transforms.val.Rotate = False\n",
    "    cfg.transforms.val.RandomScale = False\n",
    "    cfg.transforms.val.Cutout = edict()\n",
    "    cfg.transforms.val.Cutout.num_holes = 0\n",
    "    cfg.transforms.test = edict()\n",
    "    cfg.transforms.test.HorizontalFlip = False\n",
    "    cfg.transforms.test.VerticalFlip = False\n",
    "    cfg.transforms.test.Noise = False\n",
    "    cfg.transforms.test.Contrast = False\n",
    "    cfg.transforms.test.Rotate = False\n",
    "    cfg.transforms.test.RandomScale = False\n",
    "    cfg.transforms.test.Cutout = edict()\n",
    "    cfg.transforms.test.Cutout.num_holes = 0\n",
    "    cfg.transforms.mean = [0.485, 0.456, 0.406]\n",
    "    cfg.transforms.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # val\n",
    "    cfg.val = edict()\n",
    "    cfg.val.params = edict()\n",
    "\n",
    "    cfg.callbacks = []\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def _merge_config(src: edict, dst: edict):\n",
    "    if not isinstance(src, edict):\n",
    "        return\n",
    "    for k, v in src.items():\n",
    "        if isinstance(v, edict):\n",
    "            _merge_config(src[k], dst[k])\n",
    "        else:\n",
    "            dst[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOq2Hol4KQ_S"
   },
   "outputs": [],
   "source": [
    "cfg = edict(yaml.load(conf_string, Loader=yaml.SafeLoader))\n",
    "config = _get_default()\n",
    "_merge_config(cfg, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iinSUuVEKQ_V"
   },
   "source": [
    "## Environmental settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Mo5V5VT5KQ_W",
    "outputId": "fe1ec4c1-8343-4862-a557-85df54a52ed7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ct.utils.set_global_seed(config.seed)\n",
    "ct.utils.prepare_cudnn(deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHv73-KuKQ_Y"
   },
   "outputs": [],
   "source": [
    "output_base_dir = Path(\"output\")\n",
    "output_base_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "train_images_path = Path(config.data.train_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nowCCU9GKQ_b",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data and utilities preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAy9mKC1KQ_c"
   },
   "source": [
    "### validation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38wcJQJEKQ_c"
   },
   "outputs": [],
   "source": [
    "def no_fold(df: pd.DataFrame,\n",
    "            config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    params = config.val.params\n",
    "    idx = np.arange(len(df))\n",
    "    trn_idx, val_idx = train_test_split(idx, **params)\n",
    "    return [(trn_idx, val_idx)]\n",
    "\n",
    "\n",
    "def kfold(df: pd.DataFrame,\n",
    "          config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    params = config.val.params\n",
    "    kf = KFold(shuffle=True, **params)\n",
    "    splits = list(kf.split(df))\n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_validation(df: pd.DataFrame,\n",
    "                   config: edict) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    name: str = config.val.name\n",
    "\n",
    "    func = globals().get(name)\n",
    "    if func is None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return func(df, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE5iD2HAKQ_f"
   },
   "source": [
    "### transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvCvJ5ScKQ_f"
   },
   "outputs": [],
   "source": [
    "def get_transforms(config: edict, phase: str = \"train\"):\n",
    "    assert phase in [\"train\", \"valid\", \"test\"]\n",
    "    if phase == \"train\":\n",
    "        cfg = config.transforms.train\n",
    "    elif phase == \"valid\":\n",
    "        cfg = config.transforms.val\n",
    "    elif phase == \"test\":\n",
    "        cfg = config.transforms.test\n",
    "    list_transforms = []\n",
    "    if cfg.HorizontalFlip:\n",
    "        list_transforms.append(A.HorizontalFrip())\n",
    "    if cfg.VerticalFlip:\n",
    "        list_transforms.append(A.VerticalFlip())\n",
    "    if cfg.Rotate:\n",
    "        list_transforms.append(A.Rotate(limit=15))\n",
    "    if cfg.RandomScale:\n",
    "        list_transforms.append(A.RandomScale())\n",
    "    if cfg.Noise:\n",
    "        list_transforms.append(\n",
    "            A.OneOf(\n",
    "                [A.GaussNoise(), A.IAAAdditiveGaussianNoise()], p=0.5))\n",
    "    if cfg.Contrast:\n",
    "        list_transforms.append(\n",
    "            A.OneOf(\n",
    "                [A.RandomContrast(0.5),\n",
    "                 A.RandomGamma(),\n",
    "                 A.RandomBrightness()],\n",
    "                p=0.5))\n",
    "    if cfg.Cutout.num_holes > 0:\n",
    "        list_transforms.append(A.Cutout(**cfg.Cutout))\n",
    "\n",
    "    list_transforms.append(\n",
    "        A.Normalize(\n",
    "            mean=config.transforms.mean,\n",
    "            std=config.transforms.std,\n",
    "            p=1,\n",
    "            always_apply=True))\n",
    "\n",
    "    return A.Compose(list_transforms, p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mQCOAtuLtV3"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdTnGd0aLu-8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.data.train_df_path)\n",
    "splits = get_validation(df, config)\n",
    "\n",
    "transforms_dict = {\n",
    "    phase: get_transforms(config, phase)\n",
    "    for phase in [\"train\", \"valid\"]\n",
    "}\n",
    "\n",
    "cls_levels = {\n",
    "    \"grapheme\": df.grapheme_root.nunique(),\n",
    "    \"vowel\": df.vowel_diacritic.nunique(),\n",
    "    \"consonant\": df.consonant_diacritic.nunique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3X2245OKQ_j"
   },
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hj6MHrqXKQ_j"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(torchdata.Dataset):\n",
    "    def __init__(self, image_dir: Path, df: pd.DataFrame, transforms,\n",
    "                 size: Tuple[int, int]):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.df.loc[idx, \"image_id\"]\n",
    "        image_path = self.image_dir / f\"{image_id}.png\"\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "        longer_side = image.shape[1]\n",
    "        if image.ndim == 2:\n",
    "            new_image = np.ones(\n",
    "                (longer_side, longer_side), dtype=np.uint8) * 255\n",
    "        else:\n",
    "            new_image = np.ones(\n",
    "                (longer_side, longer_side, 3), dtype=np.uint8) * 255\n",
    "        offset = np.random.randint(0, longer_side - image.shape[0])\n",
    "        new_image[offset:offset + image.shape[0], :] = image\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=new_image)[\"image\"]\n",
    "        image = cv2.resize(image, self.size)\n",
    "        if image.shape[2] == 3:\n",
    "            image = np.moveaxis(image, -1, 0)\n",
    "        grapheme = self.df.loc[idx, \"grapheme_root\"]\n",
    "        vowel = self.df.loc[idx, \"vowel_diacritic\"]\n",
    "        consonant = self.df.loc[idx, \"consonant_diacritic\"]\n",
    "        label = np.zeros(3, dtype=int)\n",
    "        label[0] = grapheme\n",
    "        label[1] = vowel\n",
    "        label[2] = consonant\n",
    "        return {\"images\": image, \"targets\": label}\n",
    "    \n",
    "    \n",
    "def get_base_loader(df: pd.DataFrame,\n",
    "                    image_dir: Path,\n",
    "                    phase: str = \"train\",\n",
    "                    size: Tuple[int, int] = (128, 128),\n",
    "                    batch_size=256,\n",
    "                    num_workers=2,\n",
    "                    transforms=None):\n",
    "    assert phase in [\"train\", \"valid\"]\n",
    "    if phase == \"train\":\n",
    "        is_shuffle = True\n",
    "        drop_last = True\n",
    "    else:\n",
    "        is_shuffle = False\n",
    "        drop_last = False\n",
    "\n",
    "    dataset = BaseDataset(  # type: ignore\n",
    "        image_dir, df, transforms, size)\n",
    "    return torchdata.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=is_shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc6F3Pu5KQ_m",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjBhyu98KQ_n"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wABhZZ9LKQ_o"
   },
   "outputs": [],
   "source": [
    "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p),\n",
    "                        (x.size(-2), x.size(-1))).pow(1. / p)\n",
    "\n",
    "\n",
    "def mish(input):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    See additional documentation for mish class.\n",
    "    '''\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    Examples:\n",
    "        >>> m = Mish()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return mish(input)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(\n",
    "            self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class SpatialAttention2d(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(SpatialAttention2d, self).__init__()\n",
    "        self.squeeze = nn.Conv2d(channel, 1, kernel_size=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.squeeze(x)\n",
    "        z = self.sigmoid(z)\n",
    "        return x * z\n",
    "\n",
    "\n",
    "class GAB(nn.Module):\n",
    "    def __init__(self, input_dim, reduction=4):\n",
    "        super(GAB, self).__init__()\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_dim, input_dim // reduction, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            input_dim // reduction, input_dim, kernel_size=1, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.global_avgpool(x)\n",
    "        z = self.relu(self.conv1(z))\n",
    "        z = self.sigmoid(self.conv2(z))\n",
    "        return x * z\n",
    "\n",
    "\n",
    "class SCse(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SCse, self).__init__()\n",
    "        self.satt = SpatialAttention2d(dim)\n",
    "        self.catt = GAB(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.satt(x) + self.catt(x)\n",
    "    \n",
    "    \n",
    "class SEResNext(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model_name: str,\n",
    "                 num_classes: int,\n",
    "                 pretrained=None,\n",
    "                 head=\"linear\",\n",
    "                 in_channels=3,\n",
    "                 outputs=[\"grapheme\", \"vowel\", \"consonant\"]):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.base = getattr(pretrainedmodels.models,\n",
    "                            model_name)(pretrained=pretrained)\n",
    "        self.head = head\n",
    "        assert in_channels in [1, 3]\n",
    "        assert head in [\"linear\", \"custom\", \"scse\"]\n",
    "        for out in outputs:\n",
    "            assert out in {\"grapheme\", \"vowel\", \"consonant\"}\n",
    "        self.outputs = outputs\n",
    "        if in_channels == 1:\n",
    "            if pretrained == \"imagenet\":\n",
    "                weight = self.base.layer0.conv1.weight\n",
    "                self.base.layer0.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                self.base.layer0.conv1.weight = nn.Parameter(\n",
    "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
    "                    requires_grad=True)\n",
    "            else:\n",
    "                self.base.layer0.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if head == \"linear\":\n",
    "            n_in_features = self.base.last_linear.in_features\n",
    "            self.base.last_linear = nn.Linear(n_in_features, self.num_classes)\n",
    "        elif head == \"custom\":\n",
    "            n_in_features = self.base.last_linear.in_features\n",
    "            arch = list(self.base.children())\n",
    "            for _ in range(2):\n",
    "                arch.pop()\n",
    "            self.base = nn.Sequential(*arch)\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                self.grapheme_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 168))\n",
    "            if \"vowel\" in self.outputs:\n",
    "                self.vowel_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 11))\n",
    "            if \"consonant\" in self.outputs:\n",
    "                self.consonant_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 7))\n",
    "        elif head == \"scse\":\n",
    "            n_in_features = self.base.last_linear.in_features\n",
    "            arch = list(self.base.children())\n",
    "            for _ in range(2):\n",
    "                arch.pop()\n",
    "            self.base = nn.Sequential(*arch)\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                self.grapheme_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 168))\n",
    "            if \"vowel\" in self.outputs:\n",
    "                self.vowel_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 11))\n",
    "            if \"consonant\" in self.outputs:\n",
    "                self.consonant_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 7))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.head == \"linear\":\n",
    "            return self.base(x)\n",
    "        elif self.head == \"custom\" or self.head == \"scse\":\n",
    "            x = self.base(x)\n",
    "            outputs = []\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                grapheme = self.grapheme_head(x)\n",
    "                outputs.append(grapheme)\n",
    "            if \"vowel\" in self.outputs:\n",
    "                vowel = self.vowel_head(x)\n",
    "                outputs.append(vowel)\n",
    "            if \"consonant\" in self.outputs:\n",
    "                consonant = self.consonant_head(x)\n",
    "                outputs.append(consonant)\n",
    "            return torch.cat(outputs, dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model_name: str,\n",
    "                 num_classes: int,\n",
    "                 pretrained=False,\n",
    "                 head=\"linear\",\n",
    "                 in_channels=3,\n",
    "                 outputs=[\"grapheme\", \"vowel\", \"consonant\"]):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.base = getattr(models, model_name)(pretrained=pretrained)\n",
    "        self.head = head\n",
    "        assert in_channels in [1, 3]\n",
    "        assert head in [\"linear\", \"custom\", \"scse\"]\n",
    "        for out in outputs:\n",
    "            assert out in {\"grapheme\", \"vowel\", \"consonant\"}\n",
    "        self.outputs = outputs\n",
    "        if in_channels == 1:\n",
    "            if pretrained:\n",
    "                weight = self.base.conv1.weight\n",
    "                self.base.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                self.base.conv1.weight = nn.Parameter(\n",
    "                    data=torch.mean(weight, dim=1, keepdim=True),\n",
    "                    requires_grad=True)\n",
    "            else:\n",
    "                self.base.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if head == \"linear\":\n",
    "            n_in_features = self.base.fc.in_features\n",
    "            self.base.fc = nn.Linear(n_in_features, self.num_classes)\n",
    "        elif head == \"custom\":\n",
    "            n_in_features = self.base.fc.in_features\n",
    "            arch = list(self.base.children())\n",
    "            for _ in range(2):\n",
    "                arch.pop()\n",
    "            self.base = nn.Sequential(*arch)\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                self.grapheme_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 168))\n",
    "            if \"vowel\" in self.outputs:\n",
    "                self.vowel_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 11))\n",
    "            if \"consonant\" in self.outputs:\n",
    "                self.consonant_head = nn.Sequential(\n",
    "                    Mish(), nn.Conv2d(n_in_features, 512, kernel_size=3),\n",
    "                    nn.BatchNorm2d(512), GeM(), nn.Linear(512, 7))\n",
    "        elif head == \"scse\":\n",
    "            n_in_features = self.base.fc.in_features\n",
    "            arch = list(self.base.children())\n",
    "            for _ in range(2):\n",
    "                arch.pop()\n",
    "            self.base = nn.Sequential(*arch)\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                self.grapheme_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 168))\n",
    "            if \"vowel\" in self.outputs:\n",
    "                self.vowel_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 11))\n",
    "            if \"consonant\" in self.outputs:\n",
    "                self.consonant_head = nn.Sequential(\n",
    "                    SCse(n_in_features), Mish(), nn.BatchNorm2d(512), GeM(),\n",
    "                    nn.Dropout(0.3), nn.Linear(512, 7))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.head == \"linear\":\n",
    "            return self.base(x)\n",
    "        elif self.head == \"custom\" or self.head == \"scse\":\n",
    "            x = self.base(x)\n",
    "            outputs = []\n",
    "            if \"grapheme\" in self.outputs:\n",
    "                grapheme = self.grapheme_head(x)\n",
    "                outputs.append(grapheme)\n",
    "            if \"vowel\" in self.outputs:\n",
    "                vowel = self.vowel_head(x)\n",
    "                outputs.append(vowel)\n",
    "            if \"consonant\" in self.outputs:\n",
    "                consonant = self.consonant_head(x)\n",
    "                outputs.append(consonant)\n",
    "            return torch.cat(outputs, dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "def get_model(config: edict):\n",
    "    params = config.model\n",
    "    if \"resnet\" in params.model_name:\n",
    "        return Resnet(**params)\n",
    "    elif \"se_resnext\" in params.model_name:\n",
    "        return SEResNext(**params)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IPNqFE5KQ_q"
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXKZUtQdKQ_r"
   },
   "outputs": [],
   "source": [
    "class BengaliCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
    "        super().__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        head = 0\n",
    "        tail = self.n_grapheme\n",
    "        grapheme_pred = pred[:, head:tail]\n",
    "        grapheme_true = true[:, 0]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_vowel\n",
    "        vowel_pred = pred[:, head:tail]\n",
    "        vowel_true = true[:, 1]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_consonant\n",
    "        consonant_pred = pred[:, head:tail]\n",
    "        consonant_true = true[:, 2]\n",
    "\n",
    "        return self.cross_entropy(grapheme_pred, grapheme_true) + \\\n",
    "            self.cross_entropy(vowel_pred, vowel_true) + \\\n",
    "            self.cross_entropy(consonant_pred, consonant_true)\n",
    "\n",
    "\n",
    "class BengaliBCELoss(nn.Module):\n",
    "    def __init__(self, n_grapheme: int, n_vowel: int, n_consonant: int):\n",
    "        super().__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        head = 0\n",
    "        tail = self.n_grapheme\n",
    "        grapheme_pred = pred[:, head:tail]\n",
    "        grapheme_true = true[:, head:tail]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_vowel\n",
    "        vowel_pred = pred[:, head:tail]\n",
    "        vowel_true = true[:, head:tail]\n",
    "\n",
    "        head = tail\n",
    "        tail = head + self.n_consonant\n",
    "        consonant_pred = pred[:, head:tail]\n",
    "        consonant_true = true[:, head:tail]\n",
    "\n",
    "        return self.bce(grapheme_pred, grapheme_true) + \\\n",
    "            self.bce(vowel_pred, vowel_true) + \\\n",
    "            self.bce(consonant_pred, consonant_true)\n",
    "\n",
    "\n",
    "class GraphemeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        return self.loss(pred, true[:, 0])\n",
    "\n",
    "\n",
    "def get_loss(config: edict):\n",
    "    name = config.loss.name\n",
    "    params = config.loss.params\n",
    "    if name == \"bce\":\n",
    "        criterion = BengaliBCELoss(**params)\n",
    "    elif name == \"cross_entropy\":\n",
    "        criterion = BengaliCrossEntropyLoss(**params)  # type: ignore\n",
    "    elif name == \"grapheme\":\n",
    "        criterion = GraphemeLoss()  # type: ignore\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4aJX5V_KQ_t",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thU1KR2NKQ_u"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWo_pBvzKQ_u"
   },
   "outputs": [],
   "source": [
    "Optimizer = Union[Adam, SGD]\n",
    "\n",
    "\n",
    "def get_optimizer(model, config: edict) -> Optimizer:\n",
    "    name = config.optimizer.name\n",
    "    params = config.optimizer.params\n",
    "    if name == \"Adam\":\n",
    "        optimizer = Adam(model.parameters(), **params)\n",
    "    elif name == \"SGD\":\n",
    "        optimizer = Adam(model.parameters(), **params)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmA47o80KQ_z"
   },
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA7gtPiyKQ_0"
   },
   "outputs": [],
   "source": [
    "Scheduler = Optional[\n",
    "    Union[ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts]]\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, config: edict) -> Scheduler:\n",
    "    params = config.scheduler.params\n",
    "    name = config.scheduler.name\n",
    "    scheduler: Scheduler = None\n",
    "    if name == \"plateau\":\n",
    "        scheduler = ReduceLROnPlateau(optimizer, **params)\n",
    "    elif name == \"cosine\":\n",
    "        scheduler = CosineAnnealingLR(optimizer, **params)\n",
    "    elif name == \"cosine_warmup\":\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, **params)\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YB5qDnQIKQ_2"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IwyscXBKQ_3"
   },
   "outputs": [],
   "source": [
    "class AverageRecall(Callback):\n",
    "    def __init__(self,\n",
    "                 index: int,\n",
    "                 offset: int,\n",
    "                 n_classes: int,\n",
    "                 prefix: str,\n",
    "                 loss_type: str = \"bce\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 target_key: str = \"targets\"):\n",
    "        self.index = index\n",
    "        self.offset = offset\n",
    "        self.n_classes = n_classes\n",
    "        self.prefix = prefix\n",
    "        self.loss_type = loss_type\n",
    "        self.output_key = output_key\n",
    "        self.target_key = target_key\n",
    "        self.recall = 0.0\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "\n",
    "    def on_loader_start(self, state: RunnerState):\n",
    "        self.prediction: List[int] = []\n",
    "        self.target: List[int] = []\n",
    "\n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        targ = state.input[self.target_key].detach()\n",
    "        out = state.output[self.output_key].detach()\n",
    "        head = self.offset\n",
    "        tail = self.offset + self.n_classes\n",
    "        if self.loss_type == \"bce\":\n",
    "            pred_np = torch.argmax(\n",
    "                torch.sigmoid(out[:, head:tail]), dim=1).cpu().numpy()\n",
    "            target_np = torch.argmax(targ[:, head:tail], dim=1).cpu().numpy()\n",
    "        else:\n",
    "            pred_np = torch.argmax(out[:, head:tail], dim=1).cpu().numpy()\n",
    "            target_np = targ[:, self.index].cpu().numpy()\n",
    "        self.prediction.extend(pred_np)\n",
    "        self.target.extend(target_np)\n",
    "        score = recall_score(\n",
    "            target_np, pred_np, average=\"macro\", zero_division=0)\n",
    "        state.metrics.add_batch_value(name=\"batch_\" + self.prefix, value=score)\n",
    "\n",
    "    def on_loader_end(self, state: RunnerState):\n",
    "        metric_name = self.prefix\n",
    "        y_true = np.asarray(self.target)\n",
    "        y_pred = np.asarray(self.prediction)\n",
    "\n",
    "        metric = recall_score(y_true, y_pred, average=\"macro\")\n",
    "        state.metrics.epoch_values[state.loader_name][metric_name] = float(\n",
    "            metric)\n",
    "        self.recall = metric\n",
    "\n",
    "\n",
    "class TotalAverageRecall(Callback):\n",
    "    def __init__(self,\n",
    "                 n_grapheme=168,\n",
    "                 n_vowel=11,\n",
    "                 n_consonant=7,\n",
    "                 loss_type: str = \"bce\",\n",
    "                 prefix: str = \"tar\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 target_key: str = \"targets\"):\n",
    "        self.prefix = prefix\n",
    "        self.grapheme_callback = AverageRecall(\n",
    "            index=0,\n",
    "            offset=0,\n",
    "            n_classes=n_grapheme,\n",
    "            prefix=\"grapheme_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        self.vowel_callback = AverageRecall(\n",
    "            index=1,\n",
    "            offset=n_grapheme,\n",
    "            n_classes=n_vowel,\n",
    "            prefix=\"vowel_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        self.consonant_callback = AverageRecall(\n",
    "            index=2,\n",
    "            offset=n_grapheme + n_vowel,\n",
    "            n_classes=n_consonant,\n",
    "            prefix=\"consonant_recall\",\n",
    "            loss_type=loss_type,\n",
    "            output_key=output_key,\n",
    "            target_key=target_key)\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "\n",
    "    def on_loader_start(self, state):\n",
    "        self.grapheme_callback.on_loader_start(state)\n",
    "        self.vowel_callback.on_loader_start(state)\n",
    "        self.consonant_callback.on_loader_start(state)\n",
    "\n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        self.grapheme_callback.on_batch_end(state)\n",
    "        self.vowel_callback.on_batch_end(state)\n",
    "        self.consonant_callback.on_batch_end(state)\n",
    "\n",
    "    def on_loader_end(self, state: RunnerState):\n",
    "        self.grapheme_callback.on_loader_end(state)\n",
    "        self.vowel_callback.on_loader_end(state)\n",
    "        self.consonant_callback.on_loader_end(state)\n",
    "\n",
    "        grapheme_recall = self.grapheme_callback.recall\n",
    "        vowel_recall = self.vowel_callback.recall\n",
    "        consonant_recall = self.consonant_callback.recall\n",
    "        final_score = np.average(\n",
    "            [grapheme_recall, vowel_recall, consonant_recall],\n",
    "            weights=[2, 1, 1])\n",
    "        state.metrics.epoch_values[state.loader_name][self.\n",
    "                                                      prefix] = final_score\n",
    "\n",
    "\n",
    "\n",
    "class SaveWeightsCallback(Callback):\n",
    "    def __init__(self,\n",
    "                 to: Optional[Path] = None,\n",
    "                 name: str = \"\",\n",
    "                 is_larger_better=True,\n",
    "                 main_metric=\"tar\"):\n",
    "        self.to = to\n",
    "        if isinstance(self.to, str):\n",
    "            self.to = Path(to)\n",
    "        self.name = name\n",
    "        self.best = -np.inf if is_larger_better else np.inf\n",
    "        self.is_larger_better = is_larger_better\n",
    "        self.main_metric = main_metric\n",
    "        super().__init__(CallbackOrder.External)\n",
    "\n",
    "    def on_epoch_end(self, state: RunnerState):\n",
    "        val_metric = state.metrics.epoch_values[\"valid\"][self.main_metric]\n",
    "        to_save = False\n",
    "        if self.is_larger_better and self.best < val_metric:\n",
    "            to_save = True\n",
    "            self.best = val_metric\n",
    "        elif not self.is_larger_better and self.best > val_metric:\n",
    "            to_save = True\n",
    "            self.best = val_metric\n",
    "        if to_save:\n",
    "            weights = state.model.state_dict()\n",
    "            epoch = state.epoch\n",
    "            optimizer_state = state.optimizer.state_dict()\n",
    "            state_dict = {\n",
    "                \"model_state_dict\": weights,\n",
    "                \"epoch\": epoch,\n",
    "                \"optimizer_state_dict\": optimizer_state\n",
    "            }\n",
    "\n",
    "            logdir = state.logdir / \"checkpoints\"\n",
    "            logdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            if self.name == \"\":\n",
    "                torch.save(state_dict, logdir / \"temp.pth\")\n",
    "            else:\n",
    "                torch.save(state_dict, logdir / f\"{self.name}.pth\")\n",
    "\n",
    "            if self.to is not None:\n",
    "                if self.name == \"\":\n",
    "                    torch.save(state_dict, self.to / \"temp.pth\")\n",
    "                else:\n",
    "                    torch.save(state_dict, self.to / f\"{self.name}.pth\")\n",
    "                    \n",
    "                    \n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class MixupOrCutmixCallback(CriterionCallback):\n",
    "    def __init__(self,\n",
    "                 fields: List[str] = [\n",
    "                     \"images\",\n",
    "                 ],\n",
    "                 alpha=1.0,\n",
    "                 on_train_only=True,\n",
    "                 mixup_prob=0.5,\n",
    "                 cutmix_prob=0.5,\n",
    "                 **kwargs):\n",
    "        assert len(fields) > 0, \\\n",
    "            \"At least one field is required\"\n",
    "        assert alpha >= 0, \"alpha must be>=0\"\n",
    "        assert 1 >= mixup_prob >= 0, \"mixup_prob must be within 1 and 0\"\n",
    "        assert 1 >= cutmix_prob >= 0, \"cutmix_prob must be within 1 and 0\"\n",
    "        assert 1 >= mixup_prob + cutmix_prob, \\\n",
    "            \"sum of mixup_prob and cutmix_prob must be lower than 1\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.on_train_only = on_train_only\n",
    "        self.fields = fields\n",
    "        self.alpha = alpha\n",
    "        self.lam = 1\n",
    "        self.index = None\n",
    "        self.is_needed = True\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "        self.no_action_prob = 1 - (mixup_prob + cutmix_prob)\n",
    "\n",
    "    def on_loader_start(self, state: RunnerState):\n",
    "        self.is_needed = not self.on_train_only or \\\n",
    "            state.loader_name.startswith(\"train\")\n",
    "\n",
    "    def on_batch_start(self, state: RunnerState):\n",
    "        if not self.is_needed:\n",
    "            return\n",
    "\n",
    "        dice = np.random.choice(\n",
    "            [0, 1, 2],\n",
    "            p=[self.mixup_prob, self.cutmix_prob, self.no_action_prob])\n",
    "        self.dice = dice\n",
    "        if dice == 0:\n",
    "            if self.alpha > 0:\n",
    "                self.lam = np.random.beta(self.alpha, self.alpha)\n",
    "            else:\n",
    "                self.lam = 1\n",
    "            self.index = torch.randperm(state.input[self.fields[0]].shape[0])\n",
    "            self.index.to(state.device)\n",
    "\n",
    "            for f in self.fields:\n",
    "                state.input[f] = self.lam * state.input[f] + \\\n",
    "                    (1 - self.lam) * state.input[f][self.index]\n",
    "        elif dice == 1:\n",
    "            self.index = torch.randperm(state.input[self.fields[0]].shape[0])\n",
    "            self.index.to(state.device)\n",
    "\n",
    "            if self.alpha > 0:\n",
    "                lam = np.random.beta(self.alpha, self.alpha)\n",
    "            else:\n",
    "                lam = 1\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(\n",
    "                    state.input[self.fields[0]].size(), lam)\n",
    "                for f in self.fields:\n",
    "                    state.input[f][:, :, bbx1:bbx2, bby1:bby2] = \\\n",
    "                        state.input[f][self.index, :, bbx1:bbx2, bby1:bby2]\n",
    "                self.lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) /\n",
    "                                (state.input[self.fields[0]].size()[-1] *\n",
    "                                 state.input[self.fields[0]].size()[-2]))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _compute_loss(self, state: RunnerState, criterion):\n",
    "        if not self.is_needed:\n",
    "            return super()._compute_loss(state, criterion)\n",
    "\n",
    "        if self.dice == 0 or self.dice == 1:\n",
    "            pred = state.output[self.output_key]\n",
    "            y_a = state.input[self.input_key]\n",
    "            y_b = state.input[self.input_key][self.index]\n",
    "            loss = self.lam * criterion(pred, y_a) + \\\n",
    "                (1 - self.lam) * criterion(pred, y_b)\n",
    "            return loss\n",
    "        else:\n",
    "            return super()._compute_loss(state, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHvFfq-C3NGk"
   },
   "outputs": [],
   "source": [
    "def get_callbacks(config: edict):\n",
    "    callbacks = []\n",
    "    for callback in config.callbacks:\n",
    "        name = list(callback.keys())[0]\n",
    "        params = callback[name]\n",
    "        if globals().get(name) is not None:\n",
    "            if params is not None:\n",
    "                callbacks.append(globals().get(name)(**params))  # type: ignore\n",
    "            else:\n",
    "                callbacks.append(globals().get(name)())  # type: ignore\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChYS5rgoKQ_5"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "15a4d311247a43b8a5187e05220a6d3f",
      "4964624530ba4ce2be3798a373e911c7",
      "ed9cde30a93e4a6499a4166b9cfddafd",
      "6097786ba0104b82b46eb9311ff64b74",
      "a8a0190126c74f86b2daf730df40e91c",
      "9f801915cb274386a0b73d8036ee3793",
      "db95632c413c4f3da17de9578b14c8be",
      "0315c671a5104b95b3dd8138c7cdb715"
     ]
    },
    "colab_type": "code",
    "id": "M-QhaJoMKQ_6",
    "outputId": "473d89ca-fa16-4b33-a38d-fa1d1163cb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a4d311247a43b8a5187e05220a6d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-02-03 18:54:00,233] \n",
      "1/30 * Epoch 1 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3281.8940 | _timers/batch_time=0.1715 | _timers/data_time=0.1521 | _timers/model_time=0.0194 | batch_consonant_recall=0.8696 | batch_grapheme_recall=0.5503 | batch_vowel_recall=0.8824 | consonant_recall=0.8487 | grapheme_recall=0.5214 | loss=1.9690 | tar=0.6939 | vowel_recall=0.8840\n",
      "1/30 * Epoch 1 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=4244.4152 | _timers/batch_time=0.1731 | _timers/data_time=0.1599 | _timers/model_time=0.0132 | batch_consonant_recall=0.9316 | batch_grapheme_recall=0.7744 | batch_vowel_recall=0.9347 | consonant_recall=0.9349 | grapheme_recall=0.7964 | loss=0.7981 | tar=0.8662 | vowel_recall=0.9373\n",
      "[2020-02-03 19:01:46,972] \n",
      "2/30 * Epoch 2 (train): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=3736.2761 | _timers/batch_time=0.1836 | _timers/data_time=0.1662 | _timers/model_time=0.0173 | batch_consonant_recall=0.9465 | batch_grapheme_recall=0.8137 | batch_vowel_recall=0.9581 | consonant_recall=0.9420 | grapheme_recall=0.8505 | loss=0.6234 | tar=0.9004 | vowel_recall=0.9585\n",
      "2/30 * Epoch 2 (valid): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2022.6907 | _timers/batch_time=0.1815 | _timers/data_time=0.1704 | _timers/model_time=0.0110 | batch_consonant_recall=0.9582 | batch_grapheme_recall=0.8390 | batch_vowel_recall=0.9600 | consonant_recall=0.9551 | grapheme_recall=0.8747 | loss=0.5299 | tar=0.9169 | vowel_recall=0.9630\n",
      "[2020-02-03 19:08:59,788] \n",
      "3/30 * Epoch 3 (train): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=3407.1726 | _timers/batch_time=0.1620 | _timers/data_time=0.1419 | _timers/model_time=0.0199 | batch_consonant_recall=0.9594 | batch_grapheme_recall=0.8629 | batch_vowel_recall=0.9707 | consonant_recall=0.9582 | grapheme_recall=0.8982 | loss=0.4410 | tar=0.9314 | vowel_recall=0.9710\n",
      "3/30 * Epoch 3 (valid): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=3424.1425 | _timers/batch_time=0.1549 | _timers/data_time=0.1410 | _timers/model_time=0.0138 | batch_consonant_recall=0.9651 | batch_grapheme_recall=0.8623 | batch_vowel_recall=0.9643 | consonant_recall=0.9653 | grapheme_recall=0.8976 | loss=0.4630 | tar=0.9315 | vowel_recall=0.9654\n",
      "[2020-02-03 19:16:17,518] \n",
      "4/30 * Epoch 4 (train): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2751.1804 | _timers/batch_time=0.1657 | _timers/data_time=0.1460 | _timers/model_time=0.0196 | batch_consonant_recall=0.9688 | batch_grapheme_recall=0.8929 | batch_vowel_recall=0.9773 | consonant_recall=0.9679 | grapheme_recall=0.9220 | loss=0.3405 | tar=0.9472 | vowel_recall=0.9770\n",
      "4/30 * Epoch 4 (valid): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=3372.9362 | _timers/batch_time=0.1538 | _timers/data_time=0.1401 | _timers/model_time=0.0137 | batch_consonant_recall=0.9664 | batch_grapheme_recall=0.8761 | batch_vowel_recall=0.9636 | consonant_recall=0.9611 | grapheme_recall=0.9087 | loss=0.4136 | tar=0.9361 | vowel_recall=0.9656\n",
      "[2020-02-03 19:23:33,773] \n",
      "5/30 * Epoch 5 (train): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=3041.7604 | _timers/batch_time=0.1601 | _timers/data_time=0.1403 | _timers/model_time=0.0197 | batch_consonant_recall=0.9762 | batch_grapheme_recall=0.9146 | batch_vowel_recall=0.9818 | consonant_recall=0.9743 | grapheme_recall=0.9393 | loss=0.2627 | tar=0.9589 | vowel_recall=0.9828\n",
      "5/30 * Epoch 5 (valid): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=4094.9647 | _timers/batch_time=0.1543 | _timers/data_time=0.1406 | _timers/model_time=0.0137 | batch_consonant_recall=0.9691 | batch_grapheme_recall=0.8867 | batch_vowel_recall=0.9728 | consonant_recall=0.9678 | grapheme_recall=0.9208 | loss=0.3771 | tar=0.9460 | vowel_recall=0.9744\n",
      "[2020-02-03 19:30:38,104] \n",
      "6/30 * Epoch 6 (train): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3012.5774 | _timers/batch_time=0.1550 | _timers/data_time=0.1346 | _timers/model_time=0.0202 | batch_consonant_recall=0.9814 | batch_grapheme_recall=0.9349 | batch_vowel_recall=0.9854 | consonant_recall=0.9804 | grapheme_recall=0.9542 | loss=0.1991 | tar=0.9688 | vowel_recall=0.9862\n",
      "6/30 * Epoch 6 (valid): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3648.4216 | _timers/batch_time=0.1542 | _timers/data_time=0.1402 | _timers/model_time=0.0139 | batch_consonant_recall=0.9704 | batch_grapheme_recall=0.8993 | batch_vowel_recall=0.9747 | consonant_recall=0.9693 | grapheme_recall=0.9275 | loss=0.3463 | tar=0.9503 | vowel_recall=0.9770\n",
      "[2020-02-03 19:37:41,635] \n",
      "7/30 * Epoch 7 (train): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=3027.8446 | _timers/batch_time=0.1547 | _timers/data_time=0.1343 | _timers/model_time=0.0203 | batch_consonant_recall=0.9855 | batch_grapheme_recall=0.9496 | batch_vowel_recall=0.9901 | consonant_recall=0.9846 | grapheme_recall=0.9653 | loss=0.1465 | tar=0.9763 | vowel_recall=0.9901\n",
      "7/30 * Epoch 7 (valid): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=4023.7511 | _timers/batch_time=0.1516 | _timers/data_time=0.1375 | _timers/model_time=0.0141 | batch_consonant_recall=0.9733 | batch_grapheme_recall=0.9048 | batch_vowel_recall=0.9772 | consonant_recall=0.9753 | grapheme_recall=0.9322 | loss=0.3337 | tar=0.9546 | vowel_recall=0.9787\n",
      "[2020-02-03 19:44:38,259] \n",
      "8/30 * Epoch 8 (train): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=2881.4416 | _timers/batch_time=0.1458 | _timers/data_time=0.1258 | _timers/model_time=0.0199 | batch_consonant_recall=0.9894 | batch_grapheme_recall=0.9638 | batch_vowel_recall=0.9932 | consonant_recall=0.9882 | grapheme_recall=0.9748 | loss=0.1053 | tar=0.9828 | vowel_recall=0.9934\n",
      "8/30 * Epoch 8 (valid): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=3543.3747 | _timers/batch_time=0.1517 | _timers/data_time=0.1377 | _timers/model_time=0.0138 | batch_consonant_recall=0.9762 | batch_grapheme_recall=0.9135 | batch_vowel_recall=0.9777 | consonant_recall=0.9773 | grapheme_recall=0.9380 | loss=0.3055 | tar=0.9582 | vowel_recall=0.9795\n",
      "[2020-02-03 19:51:33,021] \n",
      "9/30 * Epoch 9 (train): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2988.8886 | _timers/batch_time=0.1473 | _timers/data_time=0.1267 | _timers/model_time=0.0205 | batch_consonant_recall=0.9930 | batch_grapheme_recall=0.9729 | batch_vowel_recall=0.9946 | consonant_recall=0.9924 | grapheme_recall=0.9815 | loss=0.0781 | tar=0.9876 | vowel_recall=0.9949\n",
      "9/30 * Epoch 9 (valid): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=3113.3199 | _timers/batch_time=0.1491 | _timers/data_time=0.1356 | _timers/model_time=0.0135 | batch_consonant_recall=0.9765 | batch_grapheme_recall=0.9174 | batch_vowel_recall=0.9782 | consonant_recall=0.9780 | grapheme_recall=0.9400 | loss=0.3013 | tar=0.9595 | vowel_recall=0.9799\n",
      "[2020-02-03 19:58:21,583] \n",
      "10/30 * Epoch 10 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2867.8980 | _timers/batch_time=0.1436 | _timers/data_time=0.1226 | _timers/model_time=0.0210 | batch_consonant_recall=0.9944 | batch_grapheme_recall=0.9779 | batch_vowel_recall=0.9962 | consonant_recall=0.9940 | grapheme_recall=0.9845 | loss=0.0638 | tar=0.9898 | vowel_recall=0.9961\n",
      "10/30 * Epoch 10 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=3385.9865 | _timers/batch_time=0.1470 | _timers/data_time=0.1332 | _timers/model_time=0.0137 | batch_consonant_recall=0.9765 | batch_grapheme_recall=0.9178 | batch_vowel_recall=0.9796 | consonant_recall=0.9781 | grapheme_recall=0.9413 | loss=0.2965 | tar=0.9605 | vowel_recall=0.9812\n",
      "[2020-02-03 20:05:06,967] \n",
      "11/30 * Epoch 11 (train): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=2735.3611 | _timers/batch_time=0.1396 | _timers/data_time=0.1181 | _timers/model_time=0.0214 | batch_consonant_recall=0.9950 | batch_grapheme_recall=0.9803 | batch_vowel_recall=0.9961 | consonant_recall=0.9946 | grapheme_recall=0.9866 | loss=0.0586 | tar=0.9911 | vowel_recall=0.9963\n",
      "11/30 * Epoch 11 (valid): _base/lr=0.000e+00 | _base/momentum=0.9000 | _timers/_fps=3831.9058 | _timers/batch_time=0.1497 | _timers/data_time=0.1353 | _timers/model_time=0.0143 | batch_consonant_recall=0.9783 | batch_grapheme_recall=0.9197 | batch_vowel_recall=0.9797 | consonant_recall=0.9794 | grapheme_recall=0.9429 | loss=0.2917 | tar=0.9617 | vowel_recall=0.9814\n",
      "[2020-02-03 20:11:37,498] \n",
      "12/30 * Epoch 12 (train): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=2608.0985 | _timers/batch_time=0.1407 | _timers/data_time=0.1194 | _timers/model_time=0.0213 | batch_consonant_recall=0.9948 | batch_grapheme_recall=0.9791 | batch_vowel_recall=0.9959 | consonant_recall=0.9940 | grapheme_recall=0.9856 | loss=0.0602 | tar=0.9903 | vowel_recall=0.9960\n",
      "12/30 * Epoch 12 (valid): _base/lr=4.894e-06 | _base/momentum=0.9000 | _timers/_fps=3849.1078 | _timers/batch_time=0.1501 | _timers/data_time=0.1364 | _timers/model_time=0.0136 | batch_consonant_recall=0.9792 | batch_grapheme_recall=0.9182 | batch_vowel_recall=0.9799 | consonant_recall=0.9801 | grapheme_recall=0.9415 | loss=0.2942 | tar=0.9612 | vowel_recall=0.9818\n",
      "[2020-02-03 20:18:07,800] \n",
      "13/30 * Epoch 13 (train): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=2831.9755 | _timers/batch_time=0.1408 | _timers/data_time=0.1193 | _timers/model_time=0.0214 | batch_consonant_recall=0.9940 | batch_grapheme_recall=0.9783 | batch_vowel_recall=0.9958 | consonant_recall=0.9933 | grapheme_recall=0.9847 | loss=0.0630 | tar=0.9897 | vowel_recall=0.9960\n",
      "13/30 * Epoch 13 (valid): _base/lr=3.726e-05 | _base/momentum=0.9000 | _timers/_fps=3363.0708 | _timers/batch_time=0.1503 | _timers/data_time=0.1367 | _timers/model_time=0.0136 | batch_consonant_recall=0.9794 | batch_grapheme_recall=0.9181 | batch_vowel_recall=0.9792 | consonant_recall=0.9801 | grapheme_recall=0.9408 | loss=0.3005 | tar=0.9607 | vowel_recall=0.9811\n",
      "[2020-02-03 20:24:36,249] \n",
      "14/30 * Epoch 14 (train): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=2416.3952 | _timers/batch_time=0.1401 | _timers/data_time=0.1182 | _timers/model_time=0.0218 | batch_consonant_recall=0.9934 | batch_grapheme_recall=0.9723 | batch_vowel_recall=0.9942 | consonant_recall=0.9927 | grapheme_recall=0.9802 | loss=0.0781 | tar=0.9869 | vowel_recall=0.9944\n",
      "14/30 * Epoch 14 (valid): _base/lr=4.449e-05 | _base/momentum=0.9000 | _timers/_fps=3838.2267 | _timers/batch_time=0.1464 | _timers/data_time=0.1330 | _timers/model_time=0.0134 | batch_consonant_recall=0.9766 | batch_grapheme_recall=0.9107 | batch_vowel_recall=0.9782 | consonant_recall=0.9786 | grapheme_recall=0.9358 | loss=0.3303 | tar=0.9577 | vowel_recall=0.9805\n",
      "[2020-02-03 20:30:58,837] \n",
      "15/30 * Epoch 15 (train): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=2797.5285 | _timers/batch_time=0.1345 | _timers/data_time=0.1136 | _timers/model_time=0.0208 | batch_consonant_recall=0.9900 | batch_grapheme_recall=0.9649 | batch_vowel_recall=0.9935 | consonant_recall=0.9893 | grapheme_recall=0.9763 | loss=0.0970 | tar=0.9839 | vowel_recall=0.9936\n",
      "15/30 * Epoch 15 (valid): _base/lr=5.791e-05 | _base/momentum=0.9000 | _timers/_fps=3887.5970 | _timers/batch_time=0.1508 | _timers/data_time=0.1368 | _timers/model_time=0.0140 | batch_consonant_recall=0.9748 | batch_grapheme_recall=0.9082 | batch_vowel_recall=0.9769 | consonant_recall=0.9754 | grapheme_recall=0.9352 | loss=0.3547 | tar=0.9562 | vowel_recall=0.9789\n",
      "[2020-02-03 20:37:26,246] \n",
      "16/30 * Epoch 16 (train): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2751.3817 | _timers/batch_time=0.1390 | _timers/data_time=0.1175 | _timers/model_time=0.0214 | batch_consonant_recall=0.9886 | batch_grapheme_recall=0.9573 | batch_vowel_recall=0.9911 | consonant_recall=0.9891 | grapheme_recall=0.9707 | loss=0.1205 | tar=0.9805 | vowel_recall=0.9913\n",
      "16/30 * Epoch 16 (valid): _base/lr=7.236e-05 | _base/momentum=0.9000 | _timers/_fps=2845.0547 | _timers/batch_time=0.1471 | _timers/data_time=0.1337 | _timers/model_time=0.0133 | batch_consonant_recall=0.9681 | batch_grapheme_recall=0.8999 | batch_vowel_recall=0.9758 | consonant_recall=0.9684 | grapheme_recall=0.9276 | loss=0.3753 | tar=0.9505 | vowel_recall=0.9785\n",
      "[2020-02-03 20:43:52,411] \n",
      "17/30 * Epoch 17 (train): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=2718.3098 | _timers/batch_time=0.1380 | _timers/data_time=0.1164 | _timers/model_time=0.0216 | batch_consonant_recall=0.9860 | batch_grapheme_recall=0.9506 | batch_vowel_recall=0.9897 | consonant_recall=0.9844 | grapheme_recall=0.9652 | loss=0.1401 | tar=0.9761 | vowel_recall=0.9898\n",
      "17/30 * Epoch 17 (valid): _base/lr=8.568e-05 | _base/momentum=0.9000 | _timers/_fps=3579.1336 | _timers/batch_time=0.1479 | _timers/data_time=0.1344 | _timers/model_time=0.0134 | batch_consonant_recall=0.9710 | batch_grapheme_recall=0.8953 | batch_vowel_recall=0.9725 | consonant_recall=0.9740 | grapheme_recall=0.9252 | loss=0.3885 | tar=0.9497 | vowel_recall=0.9743\n",
      "[2020-02-03 20:50:20,169] \n",
      "18/30 * Epoch 18 (train): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=2626.6516 | _timers/batch_time=0.1388 | _timers/data_time=0.1173 | _timers/model_time=0.0214 | batch_consonant_recall=0.9849 | batch_grapheme_recall=0.9475 | batch_vowel_recall=0.9886 | consonant_recall=0.9840 | grapheme_recall=0.9632 | loss=0.1533 | tar=0.9748 | vowel_recall=0.9886\n",
      "18/30 * Epoch 18 (valid): _base/lr=9.630e-05 | _base/momentum=0.9000 | _timers/_fps=3405.0835 | _timers/batch_time=0.1494 | _timers/data_time=0.1359 | _timers/model_time=0.0135 | batch_consonant_recall=0.9731 | batch_grapheme_recall=0.8931 | batch_vowel_recall=0.9761 | consonant_recall=0.9733 | grapheme_recall=0.9204 | loss=0.4155 | tar=0.9480 | vowel_recall=0.9780\n",
      "[2020-02-03 20:56:49,144] \n",
      "19/30 * Epoch 19 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2861.2961 | _timers/batch_time=0.1398 | _timers/data_time=0.1184 | _timers/model_time=0.0214 | batch_consonant_recall=0.9831 | batch_grapheme_recall=0.9434 | batch_vowel_recall=0.9876 | consonant_recall=0.9819 | grapheme_recall=0.9610 | loss=0.1618 | tar=0.9730 | vowel_recall=0.9879\n",
      "19/30 * Epoch 19 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3423.8367 | _timers/batch_time=0.1495 | _timers/data_time=0.1359 | _timers/model_time=0.0135 | batch_consonant_recall=0.9707 | batch_grapheme_recall=0.8973 | batch_vowel_recall=0.9758 | consonant_recall=0.9695 | grapheme_recall=0.9251 | loss=0.3704 | tar=0.9491 | vowel_recall=0.9766\n",
      "[2020-02-03 21:03:17,525] \n",
      "20/30 * Epoch 20 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2715.9454 | _timers/batch_time=0.1397 | _timers/data_time=0.1179 | _timers/model_time=0.0218 | batch_consonant_recall=0.9828 | batch_grapheme_recall=0.9450 | batch_vowel_recall=0.9874 | consonant_recall=0.9832 | grapheme_recall=0.9618 | loss=0.1585 | tar=0.9737 | vowel_recall=0.9881\n",
      "20/30 * Epoch 20 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=3416.5207 | _timers/batch_time=0.1488 | _timers/data_time=0.1349 | _timers/model_time=0.0139 | batch_consonant_recall=0.9651 | batch_grapheme_recall=0.8878 | batch_vowel_recall=0.9657 | consonant_recall=0.9669 | grapheme_recall=0.9228 | loss=0.4053 | tar=0.9450 | vowel_recall=0.9675\n",
      "[2020-02-03 21:09:47,065] \n",
      "21/30 * Epoch 21 (train): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=2936.6603 | _timers/batch_time=0.1408 | _timers/data_time=0.1193 | _timers/model_time=0.0214 | batch_consonant_recall=0.9848 | batch_grapheme_recall=0.9499 | batch_vowel_recall=0.9880 | consonant_recall=0.9849 | grapheme_recall=0.9653 | loss=0.1457 | tar=0.9760 | vowel_recall=0.9882\n",
      "21/30 * Epoch 21 (valid): _base/lr=0.0001 | _base/momentum=0.9000 | _timers/_fps=4236.6622 | _timers/batch_time=0.1477 | _timers/data_time=0.1337 | _timers/model_time=0.0140 | batch_consonant_recall=0.9751 | batch_grapheme_recall=0.8895 | batch_vowel_recall=0.9706 | consonant_recall=0.9777 | grapheme_recall=0.9173 | loss=0.4050 | tar=0.9465 | vowel_recall=0.9737\n",
      "[2020-02-03 21:16:10,162] \n",
      "22/30 * Epoch 22 (train): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=2874.6446 | _timers/batch_time=0.1361 | _timers/data_time=0.1154 | _timers/model_time=0.0206 | batch_consonant_recall=0.9862 | batch_grapheme_recall=0.9533 | batch_vowel_recall=0.9895 | consonant_recall=0.9854 | grapheme_recall=0.9678 | loss=0.1295 | tar=0.9777 | vowel_recall=0.9899\n",
      "22/30 * Epoch 22 (valid): _base/lr=9.517e-05 | _base/momentum=0.9000 | _timers/_fps=3162.7558 | _timers/batch_time=0.1437 | _timers/data_time=0.1308 | _timers/model_time=0.0128 | batch_consonant_recall=0.9721 | batch_grapheme_recall=0.8982 | batch_vowel_recall=0.9740 | consonant_recall=0.9785 | grapheme_recall=0.9275 | loss=0.3828 | tar=0.9527 | vowel_recall=0.9773\n",
      "[2020-02-03 21:22:32,028] \n",
      "23/30 * Epoch 23 (train): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=3030.5115 | _timers/batch_time=0.1358 | _timers/data_time=0.1150 | _timers/model_time=0.0207 | batch_consonant_recall=0.9889 | batch_grapheme_recall=0.9621 | batch_vowel_recall=0.9919 | consonant_recall=0.9881 | grapheme_recall=0.9744 | loss=0.1086 | tar=0.9822 | vowel_recall=0.9918\n",
      "23/30 * Epoch 23 (valid): _base/lr=8.387e-05 | _base/momentum=0.9000 | _timers/_fps=2862.5587 | _timers/batch_time=0.1437 | _timers/data_time=0.1307 | _timers/model_time=0.0130 | batch_consonant_recall=0.9709 | batch_grapheme_recall=0.9051 | batch_vowel_recall=0.9769 | consonant_recall=0.9729 | grapheme_recall=0.9339 | loss=0.3683 | tar=0.9548 | vowel_recall=0.9788\n",
      "[2020-02-03 21:28:52,525] \n",
      "24/30 * Epoch 24 (train): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=2849.1521 | _timers/batch_time=0.1345 | _timers/data_time=0.1137 | _timers/model_time=0.0207 | batch_consonant_recall=0.9917 | batch_grapheme_recall=0.9682 | batch_vowel_recall=0.9936 | consonant_recall=0.9916 | grapheme_recall=0.9785 | loss=0.0877 | tar=0.9856 | vowel_recall=0.9938\n",
      "24/30 * Epoch 24 (valid): _base/lr=6.968e-05 | _base/momentum=0.9000 | _timers/_fps=3453.7213 | _timers/batch_time=0.1443 | _timers/data_time=0.1312 | _timers/model_time=0.0130 | batch_consonant_recall=0.9725 | batch_grapheme_recall=0.9025 | batch_vowel_recall=0.9748 | consonant_recall=0.9749 | grapheme_recall=0.9301 | loss=0.3816 | tar=0.9532 | vowel_recall=0.9775\n",
      "[2020-02-03 21:35:11,617] \n",
      "25/30 * Epoch 25 (train): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=2798.8739 | _timers/batch_time=0.1345 | _timers/data_time=0.1132 | _timers/model_time=0.0212 | batch_consonant_recall=0.9936 | batch_grapheme_recall=0.9743 | batch_vowel_recall=0.9951 | consonant_recall=0.9942 | grapheme_recall=0.9823 | loss=0.0674 | tar=0.9885 | vowel_recall=0.9951\n",
      "25/30 * Epoch 25 (valid): _base/lr=5.396e-05 | _base/momentum=0.9000 | _timers/_fps=3592.1645 | _timers/batch_time=0.1447 | _timers/data_time=0.1319 | _timers/model_time=0.0128 | batch_consonant_recall=0.9710 | batch_grapheme_recall=0.9018 | batch_vowel_recall=0.9760 | consonant_recall=0.9736 | grapheme_recall=0.9323 | loss=0.3979 | tar=0.9540 | vowel_recall=0.9778\n",
      "[2020-02-03 21:41:31,505] \n",
      "26/30 * Epoch 26 (train): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=2817.7917 | _timers/batch_time=0.1354 | _timers/data_time=0.1140 | _timers/model_time=0.0213 | batch_consonant_recall=0.9957 | batch_grapheme_recall=0.9836 | batch_vowel_recall=0.9963 | consonant_recall=0.9954 | grapheme_recall=0.9888 | loss=0.0457 | tar=0.9924 | vowel_recall=0.9966\n",
      "26/30 * Epoch 26 (valid): _base/lr=3.820e-05 | _base/momentum=0.9000 | _timers/_fps=3038.6027 | _timers/batch_time=0.1437 | _timers/data_time=0.1308 | _timers/model_time=0.0129 | batch_consonant_recall=0.9770 | batch_grapheme_recall=0.9189 | batch_vowel_recall=0.9787 | consonant_recall=0.9785 | grapheme_recall=0.9419 | loss=0.3347 | tar=0.9607 | vowel_recall=0.9804\n",
      "[2020-02-03 21:48:07,678] \n",
      "27/30 * Epoch 27 (train): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=2709.2656 | _timers/batch_time=0.1349 | _timers/data_time=0.1136 | _timers/model_time=0.0213 | batch_consonant_recall=0.9967 | batch_grapheme_recall=0.9893 | batch_vowel_recall=0.9978 | consonant_recall=0.9963 | grapheme_recall=0.9927 | loss=0.0301 | tar=0.9949 | vowel_recall=0.9979\n",
      "27/30 * Epoch 27 (valid): _base/lr=2.387e-05 | _base/momentum=0.9000 | _timers/_fps=3645.6991 | _timers/batch_time=0.1436 | _timers/data_time=0.1300 | _timers/model_time=0.0135 | batch_consonant_recall=0.9766 | batch_grapheme_recall=0.9211 | batch_vowel_recall=0.9804 | consonant_recall=0.9770 | grapheme_recall=0.9458 | loss=0.3392 | tar=0.9628 | vowel_recall=0.9824\n",
      "[2020-02-03 21:54:45,752] \n",
      "28/30 * Epoch 28 (train): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=2786.3261 | _timers/batch_time=0.1358 | _timers/data_time=0.1142 | _timers/model_time=0.0216 | batch_consonant_recall=0.9985 | batch_grapheme_recall=0.9931 | batch_vowel_recall=0.9984 | consonant_recall=0.9985 | grapheme_recall=0.9954 | loss=0.0203 | tar=0.9969 | vowel_recall=0.9985\n",
      "28/30 * Epoch 28 (valid): _base/lr=1.230e-05 | _base/momentum=0.9000 | _timers/_fps=3823.3791 | _timers/batch_time=0.1450 | _timers/data_time=0.1314 | _timers/model_time=0.0135 | batch_consonant_recall=0.9781 | batch_grapheme_recall=0.9260 | batch_vowel_recall=0.9803 | consonant_recall=0.9763 | grapheme_recall=0.9483 | loss=0.3227 | tar=0.9639 | vowel_recall=0.9827\n",
      "[2020-02-03 22:01:29,008] \n",
      "29/30 * Epoch 29 (train): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=2652.0177 | _timers/batch_time=0.1360 | _timers/data_time=0.1146 | _timers/model_time=0.0213 | batch_consonant_recall=0.9989 | batch_grapheme_recall=0.9955 | batch_vowel_recall=0.9990 | consonant_recall=0.9988 | grapheme_recall=0.9970 | loss=0.0145 | tar=0.9979 | vowel_recall=0.9989\n",
      "29/30 * Epoch 29 (valid): _base/lr=4.424e-06 | _base/momentum=0.9000 | _timers/_fps=3408.5031 | _timers/batch_time=0.1500 | _timers/data_time=0.1376 | _timers/model_time=0.0124 | batch_consonant_recall=0.9800 | batch_grapheme_recall=0.9290 | batch_vowel_recall=0.9798 | consonant_recall=0.9815 | grapheme_recall=0.9492 | loss=0.3199 | tar=0.9657 | vowel_recall=0.9828\n",
      "[2020-02-03 22:08:07,731] \n",
      "30/30 * Epoch 30 (train): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=2728.7360 | _timers/batch_time=0.1350 | _timers/data_time=0.1141 | _timers/model_time=0.0208 | batch_consonant_recall=0.9994 | batch_grapheme_recall=0.9964 | batch_vowel_recall=0.9994 | consonant_recall=0.9992 | grapheme_recall=0.9979 | loss=0.0109 | tar=0.9986 | vowel_recall=0.9993\n",
      "30/30 * Epoch 30 (valid): _base/lr=6.271e-07 | _base/momentum=0.9000 | _timers/_fps=3343.7822 | _timers/batch_time=0.1429 | _timers/data_time=0.1301 | _timers/model_time=0.0127 | batch_consonant_recall=0.9786 | batch_grapheme_recall=0.9297 | batch_vowel_recall=0.9824 | consonant_recall=0.9777 | grapheme_recall=0.9518 | loss=0.3188 | tar=0.9663 | vowel_recall=0.9841\n",
      "Top best models:\n",
      "output/fold0/checkpoints/train.30.pth\t0.9663\n"
     ]
    }
   ],
   "source": [
    "trn_idx, val_idx = splits[i]\n",
    "\n",
    "print(f\"Fold: {i}\")\n",
    "\n",
    "output_dir = output_base_dir / f\"fold{i}\"\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "trn_df = df.loc[trn_idx, :].reset_index(drop=True)\n",
    "val_df = df.loc[val_idx, :].reset_index(drop=True)\n",
    "data_loaders = {\n",
    "    phase: get_base_loader(\n",
    "        df,\n",
    "        train_images_path,\n",
    "        phase=phase,\n",
    "        size=(config.img_size, config.img_size),\n",
    "        batch_size=config.train.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        transforms=transforms_dict[phase])\n",
    "    for phase, df in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
    "}\n",
    "model = get_model(config)\n",
    "criterion = get_loss(config)\n",
    "optimizer = get_optimizer(model, config)\n",
    "scheduler = get_scheduler(optimizer, config)\n",
    "callbacks = get_callbacks(config)\n",
    "\n",
    "runner = SupervisedRunner(\n",
    "    device=ct.utils.get_device(),\n",
    "    input_key=\"images\",\n",
    "    input_target_key=\"targets\",\n",
    "    output_key=\"logits\")\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=data_loaders,\n",
    "    logdir=output_dir,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=config.train.num_epochs,\n",
    "    callbacks=callbacks,\n",
    "    main_metric=config.main_metric,\n",
    "    minimize_metric=False,\n",
    "    monitoring_params=None,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhArTZXhDEdO"
   },
   "source": [
    "## Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF64LRYqK1l6"
   },
   "outputs": [],
   "source": [
    "!cp output/fold0/checkpoints/best.pth /content/gdrive/My\\ Drive/kaggle-bengali/checkpoints/fold0/resnet34_90epoch_size128_grapheme.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf7pT23OU1X1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Resnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0315c671a5104b95b3dd8138c7cdb715": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15a4d311247a43b8a5187e05220a6d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed9cde30a93e4a6499a4166b9cfddafd",
       "IPY_MODEL_6097786ba0104b82b46eb9311ff64b74"
      ],
      "layout": "IPY_MODEL_4964624530ba4ce2be3798a373e911c7"
     }
    },
    "4964624530ba4ce2be3798a373e911c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6097786ba0104b82b46eb9311ff64b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0315c671a5104b95b3dd8138c7cdb715",
      "placeholder": "​",
      "style": "IPY_MODEL_db95632c413c4f3da17de9578b14c8be",
      "value": " 83.3M/83.3M [00:00&lt;00:00, 132MB/s]"
     }
    },
    "9f801915cb274386a0b73d8036ee3793": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8a0190126c74f86b2daf730df40e91c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db95632c413c4f3da17de9578b14c8be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed9cde30a93e4a6499a4166b9cfddafd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f801915cb274386a0b73d8036ee3793",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8a0190126c74f86b2daf730df40e91c",
      "value": 87306240
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
